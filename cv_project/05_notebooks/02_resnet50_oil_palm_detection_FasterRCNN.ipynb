{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip /home/jupyter-st124895/cv_project/04_experiments.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/cv_project\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 20 04:33:38 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:84:00.0 Off |                  N/A |\n",
      "| 45%   75C    P2            241W /  250W |    9258MiB /  11264MiB |     89%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:85:00.0 Off |                  N/A |\n",
      "| 22%   38C    P8             19W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:88:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8              6W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:89:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8              4W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   1523389      C   /opt/tljh/user/bin/python                    7768MiB |\n",
      "|    0   N/A  N/A   1616170      C   /opt/tljh/user/bin/python                    1482MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgXaPROPYHNP",
    "outputId": "7155d924-73a6-4fb0-cb7f-bbf6f9dc1f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 20 04:33:42 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:84:00.0 Off |                  N/A |\n",
      "| 45%   70C    P2            102W /  250W |    9258MiB /  11264MiB |     67%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:85:00.0 Off |                  N/A |\n",
      "| 22%   38C    P8             19W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:88:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8              6W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:89:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8              4W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   1523389      C   /opt/tljh/user/bin/python                    7768MiB |\n",
      "|    0   N/A  N/A   1616170      C   /opt/tljh/user/bin/python                    1482MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] PyTorch: 2.8.0+cu128\n",
      "[OK] Torchvision: 0.23.0+cu128\n",
      "[OK] CUDA available: True\n",
      "[OK] GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 1: Mount Google Drive & GPU Check\n",
    "# ==============================================================================\n",
    "\n",
    "# Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Check GPU\n",
    "import subprocess\n",
    "subprocess.run(['nvidia-smi'])\n",
    "\n",
    "# Install dependencies\n",
    "subprocess.run(['pip', 'install', 'torch', 'torchvision', 'pandas', 'matplotlib',\n",
    "                'seaborn', 'pycocotools', 'albumentations', '-q'])\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "print(f\"[OK] PyTorch: {torch.__version__}\")\n",
    "print(f\"[OK] Torchvision: {torchvision.__version__}\")\n",
    "print(f\"[OK] CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"[OK] GPU: {torch.cuda.get_device_name(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "A1k2S35gYmD9"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 2: Dataset & Model Classes\n",
    "# ==============================================================================\n",
    "\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import cv2\n",
    "# import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "class COCODataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading COCO format annotations with Albumentations support.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, annotation_file, transforms=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: Path to images directory\n",
    "            annotation_file: Path to COCO JSON annotation file\n",
    "            transforms: Optional Albumentations transforms to apply\n",
    "        \"\"\"\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transforms = transforms\n",
    "\n",
    "        # Load COCO annotations\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "\n",
    "        # Create image id to annotations mapping\n",
    "        self.image_id_to_anns = {}\n",
    "        for ann in self.coco_data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.image_id_to_anns:\n",
    "                self.image_id_to_anns[img_id] = []\n",
    "            self.image_id_to_anns[img_id].append(ann)\n",
    "\n",
    "        # Get list of images\n",
    "        self.images = self.coco_data['images']\n",
    "\n",
    "        print(f\"[OK] Loaded {len(self.images)} images\")\n",
    "        print(f\"[OK] Loaded {len(self.coco_data['annotations'])} annotations\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image info\n",
    "        img_info = self.images[idx]\n",
    "        img_id = img_info['id']\n",
    "        img_path = self.root_dir / img_info['file_name']\n",
    "\n",
    "        # Load image as numpy array (for Albumentations)\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get annotations for this image\n",
    "        anns = self.image_id_to_anns.get(img_id, [])\n",
    "\n",
    "        # Prepare boxes and labels for Albumentations\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        areas = []\n",
    "\n",
    "        for ann in anns:\n",
    "            # COCO format: [x, y, width, height]\n",
    "            x, y, w, h = ann['bbox']\n",
    "            # Convert to [x1, y1, x2, y2] for Albumentations\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(ann['category_id'])\n",
    "            areas.append(ann['area'])\n",
    "\n",
    "        # Apply Albumentations transforms\n",
    "        if self.transforms and len(boxes) > 0:\n",
    "            try:\n",
    "                transformed = self.transforms(\n",
    "                    image=image,\n",
    "                    bboxes=boxes,\n",
    "                    labels=labels\n",
    "                )\n",
    "                image = transformed['image']\n",
    "                boxes = transformed['bboxes']\n",
    "                labels = transformed['labels']\n",
    "            except Exception as e:\n",
    "                # If transformation fails, use original data\n",
    "                print(f\"[WARNING] Transform failed for image {img_id}: {e}\")\n",
    "\n",
    "        # Always convert image to tensor at the end\n",
    "        if not isinstance(image, torch.Tensor):\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        # Convert to tensors\n",
    "        if len(boxes) > 0:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "            # Recalculate areas after transforms\n",
    "            if len(boxes) > 0:\n",
    "                areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "            else:\n",
    "                areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        else:\n",
    "            # Empty annotations\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "            areas = torch.zeros((0,), dtype=torch.float32)\n",
    "\n",
    "        image_id = torch.tensor([img_id])\n",
    "\n",
    "        # Create target dict\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = areas\n",
    "        target[\"iscrowd\"] = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "def get_train_transforms(config):\n",
    "    \"\"\"\n",
    "    Create training transforms with augmentation based on config.\n",
    "\n",
    "    Args:\n",
    "        config: Experiment configuration dict with augmentation parameters\n",
    "\n",
    "    Returns:\n",
    "        Albumentations Compose object\n",
    "    \"\"\"\n",
    "    transforms_list = []\n",
    "\n",
    "    # Color augmentation\n",
    "    if config.get('hsv_h', 0) > 0 or config.get('hsv_s', 0) > 0 or config.get('hsv_v', 0) > 0:\n",
    "        transforms_list.append(\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=int(config.get('hsv_h', 0) * 100),\n",
    "                sat_shift_limit=int(config.get('hsv_s', 0) * 100),\n",
    "                val_shift_limit=int(config.get('hsv_v', 0) * 100),\n",
    "                p=0.9\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Geometric augmentation\n",
    "    if config.get('degrees', 0) > 0 or config.get('translate', 0) > 0 or config.get('scale', 0) > 0:\n",
    "        transforms_list.append(\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=config.get('translate', 0.0),\n",
    "                scale_limit=config.get('scale', 0.0),\n",
    "                rotate_limit=config.get('degrees', 0),\n",
    "                border_mode=cv2.BORDER_CONSTANT,\n",
    "                p=0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Horizontal flip\n",
    "    if config.get('horizontal_flip', 0.0) > 0:\n",
    "        transforms_list.append(\n",
    "            A.HorizontalFlip(p=config.get('horizontal_flip', 0.0))\n",
    "        )\n",
    "\n",
    "    # Vertical flip\n",
    "    if config.get('vertical_flip', 0.0) > 0:\n",
    "        transforms_list.append(\n",
    "            A.VerticalFlip(p=config.get('vertical_flip', 0.0))\n",
    "        )\n",
    "\n",
    "    # Blur\n",
    "    if config.get('blur', False):\n",
    "        transforms_list.append(\n",
    "            A.Blur(blur_limit=3, p=0.1)\n",
    "        )\n",
    "\n",
    "    # Brightness/Contrast\n",
    "    if config.get('brightness_contrast', False):\n",
    "        transforms_list.append(\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.2,\n",
    "                contrast_limit=0.2,\n",
    "                p=0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Create compose with bbox parameters\n",
    "    return A.Compose(\n",
    "        transforms_list,\n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',  # [x1, y1, x2, y2]\n",
    "            label_fields=['labels'],\n",
    "            min_visibility=0.3,  # Keep boxes with at least 30% visible\n",
    "            min_area=100.0  # Keep boxes with at least 100 pixels area\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def get_val_transforms():\n",
    "    \"\"\"\n",
    "    Create validation transforms (no augmentation, just normalization).\n",
    "\n",
    "    Returns:\n",
    "        Albumentations Compose object\n",
    "    \"\"\"\n",
    "    return A.Compose(\n",
    "        [],  # No augmentation for validation\n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def get_model(num_classes, backbone='resnet50', pretrained=True,\n",
    "              # Configurable architecture parameters (Opción A):\n",
    "              box_score_thresh=None,\n",
    "              box_nms_thresh=None,\n",
    "              box_detections_per_img=None,\n",
    "              rpn_fg_iou_thresh=None,\n",
    "              rpn_bg_iou_thresh=None,\n",
    "              box_positive_fraction=None):\n",
    "    \"\"\"\n",
    "    Create Faster R-CNN model with configurable architecture parameters.\n",
    "\n",
    "    Args:\n",
    "        num_classes: Number of classes (including background)\n",
    "        backbone: Backbone architecture ('resnet50' or 'resnet101')\n",
    "        pretrained: Whether to use pretrained weights\n",
    "\n",
    "        # Configurable parameters (None = use torchvision defaults):\n",
    "        box_score_thresh: Minimum confidence for detection (default: 0.05)\n",
    "        box_nms_thresh: NMS IoU threshold (default: 0.5)\n",
    "        box_detections_per_img: Max detections per image (default: 100)\n",
    "        rpn_fg_iou_thresh: RPN foreground IoU threshold (default: 0.7)\n",
    "        rpn_bg_iou_thresh: RPN background IoU threshold (default: 0.3)\n",
    "        box_positive_fraction: Positive sample ratio in ROI head (default: 0.25)\n",
    "\n",
    "    Returns:\n",
    "        model: Faster R-CNN model\n",
    "\n",
    "    Example usage in experiments_config:\n",
    "        {\n",
    "            'name': 'score_thresh_010',\n",
    "            'box_score_thresh': 0.10,  # Test higher confidence threshold\n",
    "            'box_nms_thresh': 0.5,     # Keep default\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Set defaults for configurable parameters (match torchvision defaults)\n",
    "    box_score_thresh = box_score_thresh if box_score_thresh is not None else 0.05\n",
    "    box_nms_thresh = box_nms_thresh if box_nms_thresh is not None else 0.5\n",
    "    box_detections_per_img = box_detections_per_img if box_detections_per_img is not None else 100\n",
    "    rpn_fg_iou_thresh = rpn_fg_iou_thresh if rpn_fg_iou_thresh is not None else 0.7\n",
    "    rpn_bg_iou_thresh = rpn_bg_iou_thresh if rpn_bg_iou_thresh is not None else 0.3\n",
    "    box_positive_fraction = box_positive_fraction if box_positive_fraction is not None else 0.25\n",
    "\n",
    "    # Load pretrained model\n",
    "    if backbone == 'resnet50':\n",
    "        if pretrained:\n",
    "            model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "        else:\n",
    "            model = fasterrcnn_resnet50_fpn(weights=None)\n",
    "    else:\n",
    "        raise ValueError(f\"Backbone {backbone} not supported\")\n",
    "\n",
    "    # Replace the classifier head\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # Apply configurable parameters to the model\n",
    "    model.roi_heads.score_thresh = box_score_thresh\n",
    "    model.roi_heads.nms_thresh = box_nms_thresh\n",
    "    model.roi_heads.detections_per_img = box_detections_per_img\n",
    "    model.roi_heads.fg_iou_thresh = rpn_fg_iou_thresh\n",
    "    model.roi_heads.bg_iou_thresh = rpn_bg_iou_thresh\n",
    "    model.roi_heads.positive_fraction = box_positive_fraction\n",
    "\n",
    "    # Also update RPN thresholds\n",
    "    model.rpn.fg_iou_thresh = rpn_fg_iou_thresh\n",
    "    model.rpn.bg_iou_thresh = rpn_bg_iou_thresh\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8eN3TzyTYsNH"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 3: ExperimentTrainer Class\n",
    "# ==============================================================================\n",
    "\n",
    "class FasterRCNNTrainer:\n",
    "    \"\"\"\n",
    "    Manages Faster R-CNN training experiments with automatic logging and tracking.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, experiment_name: str, model_family_dir: str = '02_faster_rcnn'):\n",
    "        \"\"\"\n",
    "        Initialize experiment trainer.\n",
    "\n",
    "        Args:\n",
    "            experiment_name: Name for this experiment\n",
    "            model_family_dir: Directory name for model family (e.g., '02_faster_rcnn')\n",
    "        \"\"\"\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model_family_dir = Path(EXPERIMENTS_PATH) / model_family_dir\n",
    "        self.model_family_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Auto-increment experiment ID\n",
    "        self.experiment_id = self._get_next_experiment_id()\n",
    "        self.experiment_dir = self.model_family_dir / self.experiment_id\n",
    "        self.experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Create subdirectories\n",
    "        self.weights_dir = self.experiment_dir / 'weights'\n",
    "        self.plots_dir = self.experiment_dir / 'plots'\n",
    "        self.weights_dir.mkdir(exist_ok=True)\n",
    "        self.plots_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"  EXPERIMENT: {self.experiment_id}\")\n",
    "        print(f\"  Family: {model_family_dir}\")\n",
    "        print(f\"  Directory: {self.experiment_dir}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "    def _get_next_experiment_id(self) -> str:\n",
    "        \"\"\"Auto-increment experiment number\"\"\"\n",
    "        existing_experiments = list(self.model_family_dir.glob('exp_*'))\n",
    "\n",
    "        if not existing_experiments:\n",
    "            exp_num = 1\n",
    "        else:\n",
    "            numbers = []\n",
    "            for exp_path in existing_experiments:\n",
    "                try:\n",
    "                    num_str = exp_path.name.split('_')[1]\n",
    "                    numbers.append(int(num_str))\n",
    "                except (IndexError, ValueError):\n",
    "                    continue\n",
    "\n",
    "            exp_num = max(numbers) + 1 if numbers else 1\n",
    "\n",
    "        return f\"exp_{exp_num:03d}_{self.experiment_name}\"\n",
    "\n",
    "    def _get_dataset_info(self, train_ann_file: str, val_ann_file: str) -> Dict:\n",
    "        \"\"\"Extract dataset information from COCO JSON files\"\"\"\n",
    "        dataset_info = {\n",
    "            'num_train_images': 0,\n",
    "            'num_val_images': 0,\n",
    "            'num_train_boxes': 0,\n",
    "            'num_val_boxes': 0\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Load train annotations\n",
    "            with open(train_ann_file, 'r') as f:\n",
    "                train_data = json.load(f)\n",
    "            dataset_info['num_train_images'] = len(train_data['images'])\n",
    "            dataset_info['num_train_boxes'] = len(train_data['annotations'])\n",
    "\n",
    "            # Load val annotations\n",
    "            with open(val_ann_file, 'r') as f:\n",
    "                val_data = json.load(f)\n",
    "            dataset_info['num_val_images'] = len(val_data['images'])\n",
    "            dataset_info['num_val_boxes'] = len(val_data['annotations'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Could not extract dataset info: {e}\")\n",
    "\n",
    "        return dataset_info\n",
    "\n",
    "    def train(self, train_loader, val_loader, model, optimizer, lr_scheduler,\n",
    "              num_epochs, device, config):\n",
    "        \"\"\"\n",
    "        Train Faster R-CNN model.\n",
    "\n",
    "        Args:\n",
    "            train_loader: Training data loader\n",
    "            val_loader: Validation data loader\n",
    "            model: Faster R-CNN model\n",
    "            optimizer: Optimizer\n",
    "            lr_scheduler: Learning rate scheduler\n",
    "            num_epochs: Number of epochs\n",
    "            device: Device to train on\n",
    "            config: Experiment configuration dict\n",
    "        \"\"\"\n",
    "        print(f\"[INFO] Starting training for {num_epochs} epochs...\")\n",
    "        print(f\"[INFO] Device: {device}\")\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        # Training history\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'learning_rate': []\n",
    "        }\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_epoch = 0\n",
    "        patience_counter = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_start = time.time()\n",
    "\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            print(f\"\\n[EPOCH {epoch+1}/{num_epochs}]\")\n",
    "\n",
    "            for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "                # Move to device\n",
    "                images = [img.to(device) for img in images]\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "                # Forward pass\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += losses.item()\n",
    "\n",
    "                if (batch_idx + 1) % 10 == 0:\n",
    "                    print(f\"  Batch [{batch_idx+1}/{len(train_loader)}] - Loss: {losses.item():.4f}\")\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            # Validation phase\n",
    "            # Note: Faster R-CNN requires training mode to compute losses\n",
    "            # but we use no_grad() to prevent gradient computation\n",
    "            model.train()  # Keep in train mode to get loss_dict\n",
    "            val_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, targets in val_loader:\n",
    "                    images = [img.to(device) for img in images]\n",
    "                    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "                    # Forward pass - model returns loss_dict when in train mode\n",
    "                    loss_dict = model(images, targets)\n",
    "                    losses = sum(loss for loss in loss_dict.values())\n",
    "                    val_loss += losses.item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            history['val_loss'].append(val_loss)\n",
    "\n",
    "            epoch_time = time.time() - epoch_start\n",
    "\n",
    "            print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"  Time: {epoch_time:.2f}s\")\n",
    "\n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), self.weights_dir / 'best.pt')\n",
    "                print(f\"  ✓ Best model saved (val_loss: {val_loss:.4f})\")\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            # Save last model\n",
    "            torch.save(model.state_dict(), self.weights_dir / 'last.pt')\n",
    "\n",
    "            # Step learning rate scheduler\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            # Early stopping\n",
    "            if config.get('patience', 0) > 0 and patience_counter >= config['patience']:\n",
    "                print(f\"\\n[EARLY STOPPING] No improvement for {config['patience']} epochs\")\n",
    "                break\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        self.training_time = total_time  # Save as instance attribute for later use\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"  TRAINING COMPLETED\")\n",
    "        print(f\"  Best Epoch: {best_epoch}\")\n",
    "        print(f\"  Best Val Loss: {best_val_loss:.4f}\")\n",
    "        print(f\"  Total Time: {total_time/60:.2f} minutes\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "        # Save training history\n",
    "        self._save_history(history, best_epoch, total_time, config)\n",
    "\n",
    "        return history, best_val_loss, best_epoch\n",
    "\n",
    "    def _save_history(self, history, best_epoch, training_time, config):\n",
    "        \"\"\"Save training history and plots with unified style\"\"\"\n",
    "        # Unified plot configuration (matching YOLOv8)\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 10))\n",
    "\n",
    "        # Add suptitle\n",
    "        fig.suptitle(f'Training Results - {self.experiment_id}',\n",
    "                     fontsize=16, fontweight='bold')\n",
    "\n",
    "        # Loss plot (using YOLOv8 color scheme)\n",
    "        axes[0].plot(history['train_loss'], label='Train Loss',\n",
    "                     linewidth=2, color='#3498db')  # Blue\n",
    "        axes[0].plot(history['val_loss'], label='Val Loss',\n",
    "                     linewidth=2, color='#e74c3c')  # Red\n",
    "        axes[0].axvline(x=best_epoch-1, color='#e74c3c', linestyle='--',\n",
    "                       label=f'Best Epoch ({best_epoch})')\n",
    "        axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[0].set_ylabel('Loss', fontsize=12)\n",
    "        axes[0].set_title('Training & Validation Loss', fontsize=14)\n",
    "        axes[0].legend(fontsize=10)\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "        # Learning rate plot (using YOLOv8 color scheme)\n",
    "        axes[1].plot(history['learning_rate'], linewidth=2,\n",
    "                     color='#16a085')  # Teal\n",
    "        axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[1].set_ylabel('Learning Rate', fontsize=12)\n",
    "        axes[1].set_title('Learning Rate Schedule', fontsize=14)\n",
    "        axes[1].set_yscale('log')  # Log scale for LR\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])  # Leave space for suptitle\n",
    "        plt.savefig(self.plots_dir / 'training_history.png',\n",
    "                    dpi=300, bbox_inches='tight')  # High DPI\n",
    "        plt.close()\n",
    "\n",
    "        # Save experiment log (with history for plots)\n",
    "        log = {\n",
    "            'experiment_id': self.experiment_id,\n",
    "            'experiment_name': self.experiment_name,\n",
    "            'best_epoch': best_epoch,\n",
    "            'best_val_loss': history['val_loss'][best_epoch-1],\n",
    "            'final_train_loss': history['train_loss'][-1],\n",
    "            'final_val_loss': history['val_loss'][-1],\n",
    "            'training_time_minutes': training_time / 60,\n",
    "            'config': config,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            # Add history for comprehensive plots in SECTION 6\n",
    "            'train_loss': history['train_loss'],\n",
    "            'val_loss': history['val_loss'],\n",
    "            'learning_rate': history['learning_rate']\n",
    "        }\n",
    "\n",
    "        with open(self.experiment_dir / 'experiment_log.json', 'w') as f:\n",
    "            json.dump(log, f, indent=2)\n",
    "\n",
    "        print(f\"[OK] Training history saved to {self.plots_dir}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Evaluation Functions (COCO Metrics)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import tempfile\n",
    "\n",
    "def evaluate_model_coco(model, data_loader, device, ann_file):\n",
    "    \"\"\"\n",
    "    Evaluate Faster R-CNN model using COCO metrics.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Faster R-CNN model\n",
    "        data_loader: DataLoader for evaluation\n",
    "        device: Device to run evaluation on\n",
    "        ann_file: Path to COCO annotation file\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with mAP metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Collect all predictions\n",
    "    coco_results = []\n",
    "\n",
    "    print(\"[INFO] Running inference for COCO evaluation...\")\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            predictions = model(images)\n",
    "\n",
    "            # Convert predictions to COCO format\n",
    "            for pred, target in zip(predictions, targets):\n",
    "                image_id = target['image_id'].item()\n",
    "                boxes = pred['boxes'].cpu().numpy()\n",
    "                scores = pred['scores'].cpu().numpy()\n",
    "                labels = pred['labels'].cpu().numpy()\n",
    "\n",
    "                # Convert boxes from [x1, y1, x2, y2] to COCO format [x, y, w, h]\n",
    "                for box, score, label in zip(boxes, scores, labels):\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    coco_results.append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': int(label),\n",
    "                        'bbox': [float(x1), float(y1), float(x2 - x1), float(y2 - y1)],\n",
    "                        'score': float(score)\n",
    "                    })\n",
    "\n",
    "    print(f\"[OK] Generated {len(coco_results)} predictions\")\n",
    "\n",
    "    # Load COCO ground truth and evaluate\n",
    "    coco_gt = COCO(str(ann_file))\n",
    "\n",
    "    # Save predictions to temporary file\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:\n",
    "        json.dump(coco_results, f)\n",
    "        results_file = f.name\n",
    "\n",
    "    coco_dt = coco_gt.loadRes(results_file)\n",
    "\n",
    "    # Run COCO evaluation\n",
    "    print(\"\\n[INFO] Running COCO evaluation...\")\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    # Extract metrics\n",
    "    metrics = {\n",
    "        'mAP_50_95': coco_eval.stats[0],\n",
    "        'mAP_50': coco_eval.stats[1],\n",
    "        'mAP_75': coco_eval.stats[2],\n",
    "        'precision': coco_eval.stats[1],  # Use mAP@50 as precision proxy\n",
    "        'recall': coco_eval.stats[8],     # Use AR@100 as recall proxy\n",
    "        'f1_score': 2 * (coco_eval.stats[1] * coco_eval.stats[8]) / (coco_eval.stats[1] + coco_eval.stats[8] + 1e-6)\n",
    "    }\n",
    "\n",
    "    # Measure inference time\n",
    "    print(\"\\n[INFO] Measuring inference time...\")\n",
    "    import time\n",
    "    inference_times = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Warm-up\n",
    "        for images, _ in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            _ = model(images)\n",
    "            break\n",
    "\n",
    "        # Measure\n",
    "        for images, _ in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            start = time.time()\n",
    "            _ = model(images)\n",
    "            end = time.time()\n",
    "            inference_times.append((end - start) * 1000 / len(images))  # ms per image\n",
    "\n",
    "    metrics['inference_time_ms'] = sum(inference_times) / len(inference_times) if inference_times else 0.0\n",
    "\n",
    "    # Calculate total parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    metrics['total_params_M'] = total_params / 1e6\n",
    "\n",
    "    print(f\"[OK] Inference time: {metrics['inference_time_ms']:.2f} ms/image\")\n",
    "    print(f\"[OK] Total parameters: {metrics['total_params_M']:.2f}M\")\n",
    "\n",
    "    # Clean up\n",
    "    import os\n",
    "    os.unlink(results_file)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def save_metrics_to_csv(experiment_dir, experiment_id, experiment_name, config,\n",
    "                        metrics, dataset_info, training_time, best_epoch):\n",
    "    \"\"\"Save experiment metrics to CSV files (master + family).\"\"\"\n",
    "\n",
    "    # Prepare row data (aligned with YOLOv8 format)\n",
    "    row_data = {\n",
    "        'experiment_id': experiment_id,\n",
    "        'experiment_name': experiment_name,  # Renamed from 'name' for consistency\n",
    "        'model_family': '02_faster_rcnn',\n",
    "        'model_variant': config.get('backbone', 'resnet50'),  # Renamed from 'backbone'\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'dataset_version': 'v1',  # Added for consistency\n",
    "        'num_train_images': dataset_info.get('num_train_images', 0),\n",
    "        'num_val_images': dataset_info.get('num_val_images', 0),\n",
    "        'num_train_boxes': dataset_info.get('num_train_boxes', 0),\n",
    "        'num_val_boxes': dataset_info.get('num_val_boxes', 0),\n",
    "        'num_epochs': config.get('num_epochs', 50),\n",
    "        'batch_size': config.get('batch_size', 4),\n",
    "        'img_size': 800,  # Faster R-CNN default input size\n",
    "        'mAP_50': metrics.get('mAP_50', 0.0),\n",
    "        'mAP_50_95': metrics.get('mAP_50_95', 0.0),\n",
    "        'mAP_75': metrics.get('mAP_75', 0.0),\n",
    "        'precision': metrics.get('precision', 0.0),\n",
    "        'recall': metrics.get('recall', 0.0),\n",
    "        'f1_score': metrics.get('f1_score', 0.0),\n",
    "        'best_epoch': best_epoch,  # Added for tracking\n",
    "        'inference_time_ms': metrics.get('inference_time_ms', 0.0),  # Added\n",
    "        'training_time_hours': training_time / 3600,  # Changed from minutes to hours\n",
    "        'total_params_M': metrics.get('total_params_M', 0.0),  # Added\n",
    "        # Hyperparameters (extra info for Faster R-CNN)\n",
    "        'pretrained': config.get('pretrained', True),\n",
    "        'learning_rate': config.get('learning_rate', 0.005),\n",
    "        'momentum': config.get('momentum', 0.9),\n",
    "        'weight_decay': config.get('weight_decay', 0.0005),\n",
    "        'step_size': config.get('step_size', 10),\n",
    "        'gamma': config.get('gamma', 0.1),\n",
    "        'patience': config.get('patience', 10),\n",
    "        # Augmentation params\n",
    "        'hsv_h': config.get('hsv_h', 0.0),\n",
    "        'hsv_s': config.get('hsv_s', 0.0),\n",
    "        'hsv_v': config.get('hsv_v', 0.0),\n",
    "        'degrees': config.get('degrees', 0.0),\n",
    "        'translate': config.get('translate', 0.0),\n",
    "        'scale': config.get('scale', 0.0),\n",
    "        'horizontal_flip': config.get('horizontal_flip', 0.0),\n",
    "        'vertical_flip': config.get('vertical_flip', 0.0),\n",
    "        'blur': config.get('blur', False),\n",
    "        'brightness_contrast': config.get('brightness_contrast', False),\n",
    "        # Architecture params (Opción A)\n",
    "        'box_score_thresh': config.get('box_score_thresh', 0.05),\n",
    "        'box_nms_thresh': config.get('box_nms_thresh', 0.5),\n",
    "        'box_detections_per_img': config.get('box_detections_per_img', 100),\n",
    "        'rpn_fg_iou_thresh': config.get('rpn_fg_iou_thresh', 0.7),\n",
    "        'rpn_bg_iou_thresh': config.get('rpn_bg_iou_thresh', 0.3),\n",
    "        'box_positive_fraction': config.get('box_positive_fraction', 0.25)\n",
    "    }\n",
    "\n",
    "    # Save to family CSV\n",
    "    family_csv = Path(EXPERIMENTS_PATH) / '02_faster_rcnn' / '02_faster_rcnn_experiments.csv'\n",
    "    df_row = pd.DataFrame([row_data])\n",
    "\n",
    "    if family_csv.exists():\n",
    "        df_existing = pd.read_csv(family_csv)\n",
    "        df_combined = pd.concat([df_existing, df_row], ignore_index=True)\n",
    "        df_combined.to_csv(family_csv, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(family_csv, index=False)\n",
    "\n",
    "    print(f\"[OK] Metrics saved to: {family_csv}\")\n",
    "\n",
    "    # Save to master CSV\n",
    "    master_csv = Path(EXPERIMENTS_PATH) / 'all_experiments_log.csv'\n",
    "\n",
    "    if master_csv.exists():\n",
    "        df_existing = pd.read_csv(master_csv)\n",
    "        df_combined = pd.concat([df_existing, df_row], ignore_index=True)\n",
    "        df_combined.to_csv(master_csv, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(master_csv, index=False)\n",
    "\n",
    "    print(f\"[OK] Metrics saved to: {master_csv}\")\n",
    "\n",
    "\n",
    "def update_best_model_tracker(experiment_id, experiment_name, metrics, config):\n",
    "    \"\"\"\n",
    "    Update best model JSON files (overall + family).\n",
    "\n",
    "    Uses mAP@0.5:0.95 as criterion (standard COCO metric), same as YOLOv8.\n",
    "    \"\"\"\n",
    "\n",
    "    family_best = Path(EXPERIMENTS_PATH) / '02_faster_rcnn' / '02_faster_rcnn_best_model.json'\n",
    "\n",
    "    best_data = {\n",
    "        'experiment_id': experiment_id,\n",
    "        'experiment_name': experiment_name,\n",
    "        'mAP_50': metrics['mAP_50'],\n",
    "        'mAP_50_95': metrics['mAP_50_95'],\n",
    "        'config': config,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "    # Update family best (using mAP@0.5:0.95 as criterion)\n",
    "    update_family = True\n",
    "    if family_best.exists():\n",
    "        with open(family_best, 'r') as f:\n",
    "            current_best = json.load(f)\n",
    "        if current_best.get('mAP_50_95', 0.0) >= metrics['mAP_50_95']:\n",
    "            update_family = False\n",
    "\n",
    "    if update_family:\n",
    "        with open(family_best, 'w') as f:\n",
    "            json.dump(best_data, f, indent=2)\n",
    "        print(f\"[OK] Updated best model for 02_faster_rcnn: {experiment_id} (mAP@0.5:0.95 = {metrics['mAP_50_95']:.4f})\")\n",
    "\n",
    "    # Update overall best (using mAP@0.5:0.95 as criterion, same as YOLOv8)\n",
    "    overall_best = Path(EXPERIMENTS_PATH) / 'best_model_overall.json'\n",
    "\n",
    "    update_overall = True\n",
    "    if overall_best.exists():\n",
    "        with open(overall_best, 'r') as f:\n",
    "            current_best = json.load(f)\n",
    "        if current_best.get('mAP_50_95', 0.0) >= metrics['mAP_50_95']:\n",
    "            update_overall = False\n",
    "\n",
    "    if update_overall:\n",
    "        with open(overall_best, 'w') as f:\n",
    "            json.dump(best_data, f, indent=2)\n",
    "        print(f\"[OK] Updated overall best model: {experiment_id} (mAP@0.5:0.95 = {metrics['mAP_50_95']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dJMbU6CpZBAJ"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 4: Helper Functions for Evaluation & Plotting\n",
    "# ==============================================================================\n",
    "\n",
    "def create_comprehensive_plots(experiment_dir, history, metrics, best_epoch, experiment_id):\n",
    "    \"\"\"\n",
    "    Create comprehensive training plots (6 subplots like YOLOv8).\n",
    "\n",
    "    Args:\n",
    "        experiment_dir: Path to experiment directory\n",
    "        history: Training history dict\n",
    "        metrics: Evaluation metrics dict\n",
    "        best_epoch: Best epoch number\n",
    "        experiment_id: Experiment ID string\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Suptitle\n",
    "    fig.suptitle(f'Comprehensive Training Results - {experiment_id}',\n",
    "                 fontsize=16, fontweight='bold')\n",
    "\n",
    "    # 1. Loss curves\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    axes[0].plot(epochs, history['train_loss'], label='Train Loss',\n",
    "                 linewidth=2, color='#3498db')\n",
    "    axes[0].plot(epochs, history['val_loss'], label='Val Loss',\n",
    "                 linewidth=2, color='#e74c3c')\n",
    "    axes[0].axvline(x=best_epoch, color='#e74c3c', linestyle='--',\n",
    "                   label=f'Best Epoch ({best_epoch})', alpha=0.7)\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].set_title('Training & Validation Loss', fontsize=14)\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. mAP metrics (final values as bars)\n",
    "    map_metrics = ['mAP@0.5', 'mAP@0.5:0.95', 'mAP@0.75']\n",
    "    map_values = [metrics.get('mAP_50', 0), metrics.get('mAP_50_95', 0),\n",
    "                  metrics.get('mAP_75', 0)]\n",
    "    colors_map = ['#2ecc71', '#3498db', '#9b59b6']\n",
    "    axes[1].bar(map_metrics, map_values, color=colors_map, alpha=0.8, edgecolor='black')\n",
    "    axes[1].set_ylabel('Score', fontsize=12)\n",
    "    axes[1].set_title('mAP Metrics', fontsize=14)\n",
    "    axes[1].set_ylim([0, 1])\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(map_values):\n",
    "        axes[1].text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # 3. Precision & Recall\n",
    "    pr_metrics = ['Precision', 'Recall']\n",
    "    pr_values = [metrics.get('precision', 0), metrics.get('recall', 0)]\n",
    "    colors_pr = ['#e74c3c', '#9b59b6']\n",
    "    axes[2].bar(pr_metrics, pr_values, color=colors_pr, alpha=0.8, edgecolor='black')\n",
    "    axes[2].set_ylabel('Score', fontsize=12)\n",
    "    axes[2].set_title('Precision & Recall', fontsize=14)\n",
    "    axes[2].set_ylim([0, 1])\n",
    "    axes[2].grid(True, alpha=0.3, axis='y')\n",
    "    for i, v in enumerate(pr_values):\n",
    "        axes[2].text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # 4. F1-Score\n",
    "    f1_score = metrics.get('f1_score', 0)\n",
    "    axes[3].bar(['F1-Score'], [f1_score], color='#f39c12', alpha=0.8, edgecolor='black')\n",
    "    axes[3].set_ylabel('Score', fontsize=12)\n",
    "    axes[3].set_title('F1-Score', fontsize=14)\n",
    "    axes[3].set_ylim([0, 1])\n",
    "    axes[3].grid(True, alpha=0.3, axis='y')\n",
    "    axes[3].text(0, f1_score + 0.02, f'{f1_score:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # 5. Learning Rate Schedule\n",
    "    axes[4].plot(epochs, history['learning_rate'], linewidth=2, color='#16a085')\n",
    "    axes[4].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[4].set_ylabel('Learning Rate', fontsize=12)\n",
    "    axes[4].set_title('Learning Rate Schedule', fontsize=14)\n",
    "    axes[4].set_yscale('log')\n",
    "    axes[4].grid(True, alpha=0.3)\n",
    "\n",
    "    # 6. Summary text\n",
    "    axes[5].axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "EXPERIMENT SUMMARY\n",
    "{'='*35}\n",
    "\n",
    "Model Family: Faster R-CNN\n",
    "Best Epoch: {best_epoch}\n",
    "Best Val Loss: {min(history['val_loss']):.4f}\n",
    "\n",
    "METRICS\n",
    "{'='*35}\n",
    "mAP@0.5:      {metrics.get('mAP_50', 0):.4f}\n",
    "mAP@0.5:0.95: {metrics.get('mAP_50_95', 0):.4f}\n",
    "mAP@0.75:     {metrics.get('mAP_75', 0):.4f}\n",
    "Precision:    {metrics.get('precision', 0):.4f}\n",
    "Recall:       {metrics.get('recall', 0):.4f}\n",
    "F1-Score:     {metrics.get('f1_score', 0):.4f}\n",
    "\n",
    "PERFORMANCE\n",
    "{'='*35}\n",
    "Inference:    {metrics.get('inference_time_ms', 0):.2f} ms/img\n",
    "Parameters:   {metrics.get('total_params_M', 0):.2f}M\n",
    "\"\"\"\n",
    "    axes[5].text(0.1, 0.5, summary_text, fontsize=11, family='monospace',\n",
    "                verticalalignment='center', bbox=dict(boxstyle='round',\n",
    "                facecolor='wheat', alpha=0.3))\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "    # Create plots directory if it doesn't exist\n",
    "    plots_dir = experiment_dir / 'plots'\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plt.savefig(plots_dir / 'comprehensive_results.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"[OK] Comprehensive plots saved to: {plots_dir / 'comprehensive_results.png'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/cv_project\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49E7Gg2dZWuZ",
    "outputId": "81401bfc-27b7-4f3c-92d1-48cbed0fc496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset verification:\n",
      "  Train images: True - /home/jupyter-st124895/cv_project/03_datasets/oil_palm_coco_v1/train\n",
      "  Val images: True - /home/jupyter-st124895/cv_project/03_datasets/oil_palm_coco_v1/val\n",
      "  Train annotations: True - /home/jupyter-st124895/cv_project/03_datasets/oil_palm_coco_v1/annotations/instances_train.json\n",
      "  Val annotations: True - /home/jupyter-st124895/cv_project/03_datasets/oil_palm_coco_v1/annotations/instances_val.json\n",
      "\n",
      "[OK] Dataset ready!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 5: Dataset Paths & Configuration\n",
    "# ==============================================================================\n",
    "\n",
    "# Google Drive paths\n",
    "# EXPERIMENTS_PATH = '/content/drive/MyDrive/cv_project/04_experiments'\n",
    "# DATASET_PATH = '/content/drive/MyDrive/cv_project/03_datasets/oil_palm_coco_v1'\n",
    "# Puffer Paths\n",
    "EXPERIMENTS_PATH = '/home/jupyter-st124895/cv_project/04_experiments'\n",
    "DATASET_PATH =     '/home/jupyter-st124895/cv_project/03_datasets/oil_palm_coco_v1'\n",
    "\n",
    "# Create experiments directory\n",
    "Path(EXPERIMENTS_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Verify dataset paths\n",
    "dataset_path = Path(DATASET_PATH)\n",
    "train_images_dir = dataset_path / 'train'\n",
    "val_images_dir = dataset_path / 'val'\n",
    "train_ann_file = dataset_path / 'annotations' / 'instances_train.json'\n",
    "val_ann_file = dataset_path / 'annotations' / 'instances_val.json'\n",
    "\n",
    "print(f\"[INFO] Dataset verification:\")\n",
    "print(f\"  Train images: {train_images_dir.exists()} - {train_images_dir}\")\n",
    "print(f\"  Val images: {val_images_dir.exists()} - {val_images_dir}\")\n",
    "print(f\"  Train annotations: {train_ann_file.exists()} - {train_ann_file}\")\n",
    "print(f\"  Val annotations: {val_ann_file.exists()} - {val_ann_file}\")\n",
    "\n",
    "if not all([train_images_dir.exists(), val_images_dir.exists(),\n",
    "            train_ann_file.exists(), val_ann_file.exists()]):\n",
    "    print(\"\\n[ERROR] Dataset not found! Please upload dataset to Google Drive.\")\n",
    "else:\n",
    "    print(\"\\n[OK] Dataset ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "DnT3c-fQ2Ydo",
    "outputId": "f693f0e6-f7fc-4aa3-b83f-25a0dd330d6c",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Using device: cuda\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: arch_baseline_repeat\n",
      "  Repeat best config (exp_028) with NO architecture changes\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_047_arch_baseline_repeat\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_047_arch_baseline_repeat\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 52 images\n",
      "[OK] Loaded 2322 annotations\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n",
      "[INFO] Starting training for 110 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/110]\n",
      "  Batch [10/13] - Loss: 1.1638\n",
      "  Train Loss: 1.6959\n",
      "  Val Loss: 1.1329\n",
      "  Time: 12.23s\n",
      "  ✓ Best model saved (val_loss: 1.1329)\n",
      "\n",
      "[EPOCH 2/110]\n",
      "  Batch [10/13] - Loss: 0.7579\n",
      "  Train Loss: 0.8677\n",
      "  Val Loss: 0.8402\n",
      "  Time: 11.27s\n",
      "  ✓ Best model saved (val_loss: 0.8402)\n",
      "\n",
      "[EPOCH 3/110]\n",
      "  Batch [10/13] - Loss: 0.7079\n",
      "  Train Loss: 0.6847\n",
      "  Val Loss: 0.8082\n",
      "  Time: 11.55s\n",
      "  ✓ Best model saved (val_loss: 0.8082)\n",
      "\n",
      "[EPOCH 4/110]\n",
      "  Batch [10/13] - Loss: 0.6724\n",
      "  Train Loss: 0.6564\n",
      "  Val Loss: 0.7177\n",
      "  Time: 11.57s\n",
      "  ✓ Best model saved (val_loss: 0.7177)\n",
      "\n",
      "[EPOCH 5/110]\n",
      "  Batch [10/13] - Loss: 0.5891\n",
      "  Train Loss: 0.6009\n",
      "  Val Loss: 0.7132\n",
      "  Time: 11.12s\n",
      "  ✓ Best model saved (val_loss: 0.7132)\n",
      "\n",
      "[EPOCH 6/110]\n",
      "  Batch [10/13] - Loss: 0.5183\n",
      "  Train Loss: 0.6146\n",
      "  Val Loss: 0.7286\n",
      "  Time: 11.57s\n",
      "\n",
      "[EPOCH 7/110]\n",
      "  Batch [10/13] - Loss: 0.5639\n",
      "  Train Loss: 0.5849\n",
      "  Val Loss: 0.6913\n",
      "  Time: 11.59s\n",
      "  ✓ Best model saved (val_loss: 0.6913)\n",
      "\n",
      "[EPOCH 8/110]\n",
      "  Batch [10/13] - Loss: 0.5515\n",
      "  Train Loss: 0.5571\n",
      "  Val Loss: 0.6671\n",
      "  Time: 11.89s\n",
      "  ✓ Best model saved (val_loss: 0.6671)\n",
      "\n",
      "[EPOCH 9/110]\n",
      "  Batch [10/13] - Loss: 0.4985\n",
      "  Train Loss: 0.5470\n",
      "  Val Loss: 0.6861\n",
      "  Time: 11.31s\n",
      "\n",
      "[EPOCH 10/110]\n",
      "  Batch [10/13] - Loss: 0.5323\n",
      "  Train Loss: 0.5426\n",
      "  Val Loss: 0.6341\n",
      "  Time: 11.70s\n",
      "  ✓ Best model saved (val_loss: 0.6341)\n",
      "\n",
      "[EPOCH 11/110]\n",
      "  Batch [10/13] - Loss: 0.4979\n",
      "  Train Loss: 0.5399\n",
      "  Val Loss: 0.6198\n",
      "  Time: 11.52s\n",
      "  ✓ Best model saved (val_loss: 0.6198)\n",
      "\n",
      "[EPOCH 12/110]\n",
      "  Batch [10/13] - Loss: 0.4831\n",
      "  Train Loss: 0.5106\n",
      "  Val Loss: 0.6516\n",
      "  Time: 11.52s\n",
      "\n",
      "[EPOCH 13/110]\n",
      "  Batch [10/13] - Loss: 0.5000\n",
      "  Train Loss: 0.5242\n",
      "  Val Loss: 0.6180\n",
      "  Time: 11.51s\n",
      "  ✓ Best model saved (val_loss: 0.6180)\n",
      "\n",
      "[EPOCH 14/110]\n",
      "  Batch [10/13] - Loss: 0.5093\n",
      "  Train Loss: 0.5078\n",
      "  Val Loss: 0.6251\n",
      "  Time: 8.55s\n",
      "\n",
      "[EPOCH 15/110]\n",
      "  Batch [10/13] - Loss: 0.4621\n",
      "  Train Loss: 0.4936\n",
      "  Val Loss: 0.6218\n",
      "  Time: 6.33s\n",
      "\n",
      "[EPOCH 16/110]\n",
      "  Batch [10/13] - Loss: 0.5431\n",
      "  Train Loss: 0.4968\n",
      "  Val Loss: 0.6093\n",
      "  Time: 6.23s\n",
      "  ✓ Best model saved (val_loss: 0.6093)\n",
      "\n",
      "[EPOCH 17/110]\n",
      "  Batch [10/13] - Loss: 0.5311\n",
      "  Train Loss: 0.4901\n",
      "  Val Loss: 0.6217\n",
      "  Time: 6.12s\n",
      "\n",
      "[EPOCH 18/110]\n",
      "  Batch [10/13] - Loss: 0.4902\n",
      "  Train Loss: 0.4983\n",
      "  Val Loss: 0.6451\n",
      "  Time: 6.18s\n",
      "\n",
      "[EPOCH 19/110]\n",
      "  Batch [10/13] - Loss: 0.4924\n",
      "  Train Loss: 0.4873\n",
      "  Val Loss: 0.6181\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 20/110]\n",
      "  Batch [10/13] - Loss: 0.4843\n",
      "  Train Loss: 0.4942\n",
      "  Val Loss: 0.6255\n",
      "  Time: 6.05s\n",
      "\n",
      "[EPOCH 21/110]\n",
      "  Batch [10/13] - Loss: 0.4417\n",
      "  Train Loss: 0.4714\n",
      "  Val Loss: 0.6109\n",
      "  Time: 6.18s\n",
      "\n",
      "[EPOCH 22/110]\n",
      "  Batch [10/13] - Loss: 0.4109\n",
      "  Train Loss: 0.4748\n",
      "  Val Loss: 0.5924\n",
      "  Time: 6.17s\n",
      "  ✓ Best model saved (val_loss: 0.5924)\n",
      "\n",
      "[EPOCH 23/110]\n",
      "  Batch [10/13] - Loss: 0.3854\n",
      "  Train Loss: 0.4511\n",
      "  Val Loss: 0.5899\n",
      "  Time: 6.22s\n",
      "  ✓ Best model saved (val_loss: 0.5899)\n",
      "\n",
      "[EPOCH 24/110]\n",
      "  Batch [10/13] - Loss: 0.4432\n",
      "  Train Loss: 0.4590\n",
      "  Val Loss: 0.5942\n",
      "  Time: 6.10s\n",
      "\n",
      "[EPOCH 25/110]\n",
      "  Batch [10/13] - Loss: 0.3952\n",
      "  Train Loss: 0.4488\n",
      "  Val Loss: 0.6048\n",
      "  Time: 6.29s\n",
      "\n",
      "[EPOCH 26/110]\n",
      "  Batch [10/13] - Loss: 0.4578\n",
      "  Train Loss: 0.4496\n",
      "  Val Loss: 0.5837\n",
      "  Time: 6.17s\n",
      "  ✓ Best model saved (val_loss: 0.5837)\n",
      "\n",
      "[EPOCH 27/110]\n",
      "  Batch [10/13] - Loss: 0.3931\n",
      "  Train Loss: 0.4486\n",
      "  Val Loss: 0.5990\n",
      "  Time: 6.19s\n",
      "\n",
      "[EPOCH 28/110]\n",
      "  Batch [10/13] - Loss: 0.4109\n",
      "  Train Loss: 0.4443\n",
      "  Val Loss: 0.6000\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 29/110]\n",
      "  Batch [10/13] - Loss: 0.4103\n",
      "  Train Loss: 0.4531\n",
      "  Val Loss: 0.5929\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 30/110]\n",
      "  Batch [10/13] - Loss: 0.4205\n",
      "  Train Loss: 0.4525\n",
      "  Val Loss: 0.6067\n",
      "  Time: 6.18s\n",
      "\n",
      "[EPOCH 31/110]\n",
      "  Batch [10/13] - Loss: 0.4548\n",
      "  Train Loss: 0.4539\n",
      "  Val Loss: 0.5874\n",
      "  Time: 6.06s\n",
      "\n",
      "[EPOCH 32/110]\n",
      "  Batch [10/13] - Loss: 0.3923\n",
      "  Train Loss: 0.4567\n",
      "  Val Loss: 0.5989\n",
      "  Time: 6.21s\n",
      "\n",
      "[EPOCH 33/110]\n",
      "  Batch [10/13] - Loss: 0.4146\n",
      "  Train Loss: 0.4538\n",
      "  Val Loss: 0.5950\n",
      "  Time: 6.21s\n",
      "\n",
      "[EPOCH 34/110]\n",
      "  Batch [10/13] - Loss: 0.4157\n",
      "  Train Loss: 0.4555\n",
      "  Val Loss: 0.5960\n",
      "  Time: 6.17s\n",
      "\n",
      "[EPOCH 35/110]\n",
      "  Batch [10/13] - Loss: 0.4084\n",
      "  Train Loss: 0.4514\n",
      "  Val Loss: 0.6190\n",
      "  Time: 5.98s\n",
      "\n",
      "[EPOCH 36/110]\n",
      "  Batch [10/13] - Loss: 0.3760\n",
      "  Train Loss: 0.4488\n",
      "  Val Loss: 0.5946\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 37/110]\n",
      "  Batch [10/13] - Loss: 0.4175\n",
      "  Train Loss: 0.4392\n",
      "  Val Loss: 0.6053\n",
      "  Time: 6.26s\n",
      "\n",
      "[EPOCH 38/110]\n",
      "  Batch [10/13] - Loss: 0.4460\n",
      "  Train Loss: 0.4489\n",
      "  Val Loss: 0.5988\n",
      "  Time: 6.18s\n",
      "\n",
      "[EPOCH 39/110]\n",
      "  Batch [10/13] - Loss: 0.4009\n",
      "  Train Loss: 0.4518\n",
      "  Val Loss: 0.6006\n",
      "  Time: 5.95s\n",
      "\n",
      "[EPOCH 40/110]\n",
      "  Batch [10/13] - Loss: 0.4601\n",
      "  Train Loss: 0.4517\n",
      "  Val Loss: 0.6026\n",
      "  Time: 6.23s\n",
      "\n",
      "[EPOCH 41/110]\n",
      "  Batch [10/13] - Loss: 0.4299\n",
      "  Train Loss: 0.4552\n",
      "  Val Loss: 0.6287\n",
      "  Time: 6.18s\n",
      "\n",
      "[EPOCH 42/110]\n",
      "  Batch [10/13] - Loss: 0.4012\n",
      "  Train Loss: 0.4543\n",
      "  Val Loss: 0.6067\n",
      "  Time: 6.29s\n",
      "\n",
      "[EPOCH 43/110]\n",
      "  Batch [10/13] - Loss: 0.4029\n",
      "  Train Loss: 0.4473\n",
      "  Val Loss: 0.6010\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 44/110]\n",
      "  Batch [10/13] - Loss: 0.4659\n",
      "  Train Loss: 0.4526\n",
      "  Val Loss: 0.6058\n",
      "  Time: 6.15s\n",
      "\n",
      "[EPOCH 45/110]\n",
      "  Batch [10/13] - Loss: 0.4066\n",
      "  Train Loss: 0.4440\n",
      "  Val Loss: 0.6098\n",
      "  Time: 6.07s\n",
      "\n",
      "[EPOCH 46/110]\n",
      "  Batch [10/13] - Loss: 0.4621\n",
      "  Train Loss: 0.4408\n",
      "  Val Loss: 0.5915\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 47/110]\n",
      "  Batch [10/13] - Loss: 0.4301\n",
      "  Train Loss: 0.4465\n",
      "  Val Loss: 0.6142\n",
      "  Time: 6.18s\n",
      "\n",
      "[EPOCH 48/110]\n",
      "  Batch [10/13] - Loss: 0.3910\n",
      "  Train Loss: 0.4468\n",
      "  Val Loss: 0.6125\n",
      "  Time: 6.05s\n",
      "\n",
      "[EPOCH 49/110]\n",
      "  Batch [10/13] - Loss: 0.4574\n",
      "  Train Loss: 0.4410\n",
      "  Val Loss: 0.6144\n",
      "  Time: 5.98s\n",
      "\n",
      "[EPOCH 50/110]\n",
      "  Batch [10/13] - Loss: 0.4175\n",
      "  Train Loss: 0.4406\n",
      "  Val Loss: 0.6060\n",
      "  Time: 6.20s\n",
      "\n",
      "[EPOCH 51/110]\n",
      "  Batch [10/13] - Loss: 0.3844\n",
      "  Train Loss: 0.4465\n",
      "  Val Loss: 0.6086\n",
      "  Time: 6.19s\n",
      "\n",
      "[EPOCH 52/110]\n",
      "  Batch [10/13] - Loss: 0.4094\n",
      "  Train Loss: 0.4462\n",
      "  Val Loss: 0.6029\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 53/110]\n",
      "  Batch [10/13] - Loss: 0.4237\n",
      "  Train Loss: 0.4483\n",
      "  Val Loss: 0.6070\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 54/110]\n",
      "  Batch [10/13] - Loss: 0.4559\n",
      "  Train Loss: 0.4404\n",
      "  Val Loss: 0.6130\n",
      "  Time: 6.03s\n",
      "\n",
      "[EPOCH 55/110]\n",
      "  Batch [10/13] - Loss: 0.4119\n",
      "  Train Loss: 0.4344\n",
      "  Val Loss: 0.5872\n",
      "  Time: 6.18s\n",
      "\n",
      "[EPOCH 56/110]\n",
      "  Batch [10/13] - Loss: 0.4822\n",
      "  Train Loss: 0.4492\n",
      "  Val Loss: 0.6107\n",
      "  Time: 6.17s\n",
      "\n",
      "[EPOCH 57/110]\n",
      "  Batch [10/13] - Loss: 0.4099\n",
      "  Train Loss: 0.4469\n",
      "  Val Loss: 0.6112\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 58/110]\n",
      "  Batch [10/13] - Loss: 0.4154\n",
      "  Train Loss: 0.4518\n",
      "  Val Loss: 0.6056\n",
      "  Time: 6.17s\n",
      "\n",
      "[EPOCH 59/110]\n",
      "  Batch [10/13] - Loss: 0.3860\n",
      "  Train Loss: 0.4344\n",
      "  Val Loss: 0.6162\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 60/110]\n",
      "  Batch [10/13] - Loss: 0.4079\n",
      "  Train Loss: 0.4404\n",
      "  Val Loss: 0.6072\n",
      "  Time: 6.16s\n",
      "\n",
      "[EPOCH 61/110]\n",
      "  Batch [10/13] - Loss: 0.4312\n",
      "  Train Loss: 0.4430\n",
      "  Val Loss: 0.5943\n",
      "  Time: 6.18s\n",
      "\n",
      "[EARLY STOPPING] No improvement for 35 epochs\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 26\n",
      "  Best Val Loss: 0.5837\n",
      "  Total Time: 10.02 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_047_arch_baseline_repeat/plots\n",
      "\n",
      "[OK] Training completed for arch_baseline_repeat!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_047_arch_baseline_repeat\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 1181 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.545\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.799\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.701\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.546\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.735\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.736\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 40.17 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Updated best model for 02_faster_rcnn: exp_047_arch_baseline_repeat (mAP@0.5:0.95 = 0.5452)\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_047_arch_baseline_repeat/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7987\n",
      "  mAP@0.5:0.95: 0.5452\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: arch_score_010_v1\n",
      "  Best config + score threshold 0.10\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_048_arch_score_010_v1\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_048_arch_score_010_v1\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 52 images\n",
      "[OK] Loaded 2322 annotations\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training for 110 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/110]\n",
      "  Batch [10/13] - Loss: 1.2740\n",
      "  Train Loss: 1.7889\n",
      "  Val Loss: 1.1330\n",
      "  Time: 6.23s\n",
      "  ✓ Best model saved (val_loss: 1.1330)\n",
      "\n",
      "[EPOCH 2/110]\n",
      "  Batch [10/13] - Loss: 0.7754\n",
      "  Train Loss: 0.8657\n",
      "  Val Loss: 0.9060\n",
      "  Time: 6.12s\n",
      "  ✓ Best model saved (val_loss: 0.9060)\n",
      "\n",
      "[EPOCH 3/110]\n",
      "  Batch [10/13] - Loss: 0.7180\n",
      "  Train Loss: 0.6921\n",
      "  Val Loss: 0.7714\n",
      "  Time: 6.19s\n",
      "  ✓ Best model saved (val_loss: 0.7714)\n",
      "\n",
      "[EPOCH 4/110]\n",
      "  Batch [10/13] - Loss: 0.6425\n",
      "  Train Loss: 0.6560\n",
      "  Val Loss: 0.7329\n",
      "  Time: 6.26s\n",
      "  ✓ Best model saved (val_loss: 0.7329)\n",
      "\n",
      "[EPOCH 5/110]\n",
      "  Batch [10/13] - Loss: 0.6209\n",
      "  Train Loss: 0.6138\n",
      "  Val Loss: 0.7366\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 6/110]\n",
      "  Batch [10/13] - Loss: 0.6216\n",
      "  Train Loss: 0.5855\n",
      "  Val Loss: 0.6536\n",
      "  Time: 6.00s\n",
      "  ✓ Best model saved (val_loss: 0.6536)\n",
      "\n",
      "[EPOCH 7/110]\n",
      "  Batch [10/13] - Loss: 0.5405\n",
      "  Train Loss: 0.5607\n",
      "  Val Loss: 0.6758\n",
      "  Time: 6.19s\n",
      "\n",
      "[EPOCH 8/110]\n",
      "  Batch [10/13] - Loss: 0.5301\n",
      "  Train Loss: 0.5557\n",
      "  Val Loss: 0.6466\n",
      "  Time: 6.25s\n",
      "  ✓ Best model saved (val_loss: 0.6466)\n",
      "\n",
      "[EPOCH 9/110]\n",
      "  Batch [10/13] - Loss: 0.5121\n",
      "  Train Loss: 0.5675\n",
      "  Val Loss: 0.6798\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 10/110]\n",
      "  Batch [10/13] - Loss: 0.6580\n",
      "  Train Loss: 0.5584\n",
      "  Val Loss: 0.6624\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 11/110]\n",
      "  Batch [10/13] - Loss: 0.5314\n",
      "  Train Loss: 0.5284\n",
      "  Val Loss: 0.6642\n",
      "  Time: 6.07s\n",
      "\n",
      "[EPOCH 12/110]\n",
      "  Batch [10/13] - Loss: 0.5318\n",
      "  Train Loss: 0.5117\n",
      "  Val Loss: 0.6421\n",
      "  Time: 6.26s\n",
      "  ✓ Best model saved (val_loss: 0.6421)\n",
      "\n",
      "[EPOCH 13/110]\n",
      "  Batch [10/13] - Loss: 0.5522\n",
      "  Train Loss: 0.5130\n",
      "  Val Loss: 0.6302\n",
      "  Time: 6.06s\n",
      "  ✓ Best model saved (val_loss: 0.6302)\n",
      "\n",
      "[EPOCH 14/110]\n",
      "  Batch [10/13] - Loss: 0.5607\n",
      "  Train Loss: 0.5066\n",
      "  Val Loss: 0.6526\n",
      "  Time: 6.26s\n",
      "\n",
      "[EPOCH 15/110]\n",
      "  Batch [10/13] - Loss: 0.4847\n",
      "  Train Loss: 0.4982\n",
      "  Val Loss: 0.6322\n",
      "  Time: 6.21s\n",
      "\n",
      "[EPOCH 16/110]\n",
      "  Batch [10/13] - Loss: 0.4902\n",
      "  Train Loss: 0.4983\n",
      "  Val Loss: 0.6176\n",
      "  Time: 6.21s\n",
      "  ✓ Best model saved (val_loss: 0.6176)\n",
      "\n",
      "[EPOCH 17/110]\n",
      "  Batch [10/13] - Loss: 0.4823\n",
      "  Train Loss: 0.4865\n",
      "  Val Loss: 0.6413\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 18/110]\n",
      "  Batch [10/13] - Loss: 0.5005\n",
      "  Train Loss: 0.4861\n",
      "  Val Loss: 0.6032\n",
      "  Time: 6.20s\n",
      "  ✓ Best model saved (val_loss: 0.6032)\n",
      "\n",
      "[EPOCH 19/110]\n",
      "  Batch [10/13] - Loss: 0.5009\n",
      "  Train Loss: 0.4765\n",
      "  Val Loss: 0.6080\n",
      "  Time: 6.21s\n",
      "\n",
      "[EPOCH 20/110]\n",
      "  Batch [10/13] - Loss: 0.4563\n",
      "  Train Loss: 0.4925\n",
      "  Val Loss: 0.6491\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 21/110]\n",
      "  Batch [10/13] - Loss: 0.4368\n",
      "  Train Loss: 0.4816\n",
      "  Val Loss: 0.6214\n",
      "  Time: 6.23s\n",
      "\n",
      "[EPOCH 22/110]\n",
      "  Batch [10/13] - Loss: 0.4544\n",
      "  Train Loss: 0.4703\n",
      "  Val Loss: 0.6180\n",
      "  Time: 6.01s\n",
      "\n",
      "[EPOCH 23/110]\n",
      "  Batch [10/13] - Loss: 0.4747\n",
      "  Train Loss: 0.4614\n",
      "  Val Loss: 0.6146\n",
      "  Time: 9.02s\n",
      "\n",
      "[EPOCH 24/110]\n",
      "  Batch [10/13] - Loss: 0.5354\n",
      "  Train Loss: 0.4529\n",
      "  Val Loss: 0.6040\n",
      "  Time: 11.24s\n",
      "\n",
      "[EPOCH 25/110]\n",
      "  Batch [10/13] - Loss: 0.4337\n",
      "  Train Loss: 0.4508\n",
      "  Val Loss: 0.6125\n",
      "  Time: 11.23s\n",
      "\n",
      "[EPOCH 26/110]\n",
      "  Batch [10/13] - Loss: 0.4969\n",
      "  Train Loss: 0.4509\n",
      "  Val Loss: 0.5930\n",
      "  Time: 11.28s\n",
      "  ✓ Best model saved (val_loss: 0.5930)\n",
      "\n",
      "[EPOCH 27/110]\n",
      "  Batch [10/13] - Loss: 0.4986\n",
      "  Train Loss: 0.4434\n",
      "  Val Loss: 0.5977\n",
      "  Time: 11.49s\n",
      "\n",
      "[EPOCH 28/110]\n",
      "  Batch [10/13] - Loss: 0.4428\n",
      "  Train Loss: 0.4523\n",
      "  Val Loss: 0.6069\n",
      "  Time: 10.84s\n",
      "\n",
      "[EPOCH 29/110]\n",
      "  Batch [10/13] - Loss: 0.3977\n",
      "  Train Loss: 0.4459\n",
      "  Val Loss: 0.5998\n",
      "  Time: 11.28s\n",
      "\n",
      "[EPOCH 30/110]\n",
      "  Batch [10/13] - Loss: 0.4551\n",
      "  Train Loss: 0.4493\n",
      "  Val Loss: 0.5961\n",
      "  Time: 11.34s\n",
      "\n",
      "[EPOCH 31/110]\n",
      "  Batch [10/13] - Loss: 0.4787\n",
      "  Train Loss: 0.4483\n",
      "  Val Loss: 0.5978\n",
      "  Time: 11.28s\n",
      "\n",
      "[EPOCH 32/110]\n",
      "  Batch [10/13] - Loss: 0.4631\n",
      "  Train Loss: 0.4544\n",
      "  Val Loss: 0.5958\n",
      "  Time: 11.28s\n",
      "\n",
      "[EPOCH 33/110]\n",
      "  Batch [10/13] - Loss: 0.3751\n",
      "  Train Loss: 0.4447\n",
      "  Val Loss: 0.6120\n",
      "  Time: 11.74s\n",
      "\n",
      "[EPOCH 34/110]\n",
      "  Batch [10/13] - Loss: 0.4891\n",
      "  Train Loss: 0.4506\n",
      "  Val Loss: 0.6060\n",
      "  Time: 11.35s\n",
      "\n",
      "[EPOCH 35/110]\n",
      "  Batch [10/13] - Loss: 0.4956\n",
      "  Train Loss: 0.4553\n",
      "  Val Loss: 0.5849\n",
      "  Time: 11.14s\n",
      "  ✓ Best model saved (val_loss: 0.5849)\n",
      "\n",
      "[EPOCH 36/110]\n",
      "  Batch [10/13] - Loss: 0.4877\n",
      "  Train Loss: 0.4486\n",
      "  Val Loss: 0.5980\n",
      "  Time: 11.49s\n",
      "\n",
      "[EPOCH 37/110]\n",
      "  Batch [10/13] - Loss: 0.4601\n",
      "  Train Loss: 0.4500\n",
      "  Val Loss: 0.6146\n",
      "  Time: 11.30s\n",
      "\n",
      "[EPOCH 38/110]\n",
      "  Batch [10/13] - Loss: 0.4465\n",
      "  Train Loss: 0.4541\n",
      "  Val Loss: 0.6100\n",
      "  Time: 11.49s\n",
      "\n",
      "[EPOCH 39/110]\n",
      "  Batch [10/13] - Loss: 0.4708\n",
      "  Train Loss: 0.4309\n",
      "  Val Loss: 0.6205\n",
      "  Time: 11.47s\n",
      "\n",
      "[EPOCH 40/110]\n",
      "  Batch [10/13] - Loss: 0.4368\n",
      "  Train Loss: 0.4480\n",
      "  Val Loss: 0.6155\n",
      "  Time: 11.70s\n",
      "\n",
      "[EPOCH 41/110]\n",
      "  Batch [10/13] - Loss: 0.4522\n",
      "  Train Loss: 0.4417\n",
      "  Val Loss: 0.6077\n",
      "  Time: 11.43s\n",
      "\n",
      "[EPOCH 42/110]\n",
      "  Batch [10/13] - Loss: 0.4476\n",
      "  Train Loss: 0.4479\n",
      "  Val Loss: 0.6025\n",
      "  Time: 11.37s\n",
      "\n",
      "[EPOCH 43/110]\n",
      "  Batch [10/13] - Loss: 0.4634\n",
      "  Train Loss: 0.4405\n",
      "  Val Loss: 0.6112\n",
      "  Time: 11.53s\n",
      "\n",
      "[EPOCH 44/110]\n",
      "  Batch [10/13] - Loss: 0.4435\n",
      "  Train Loss: 0.4462\n",
      "  Val Loss: 0.6033\n",
      "  Time: 11.60s\n",
      "\n",
      "[EPOCH 45/110]\n",
      "  Batch [10/13] - Loss: 0.4746\n",
      "  Train Loss: 0.4438\n",
      "  Val Loss: 0.6072\n",
      "  Time: 11.43s\n",
      "\n",
      "[EPOCH 46/110]\n",
      "  Batch [10/13] - Loss: 0.4789\n",
      "  Train Loss: 0.4399\n",
      "  Val Loss: 0.6129\n",
      "  Time: 6.99s\n",
      "\n",
      "[EPOCH 47/110]\n",
      "  Batch [10/13] - Loss: 0.4583\n",
      "  Train Loss: 0.4348\n",
      "  Val Loss: 0.5919\n",
      "  Time: 6.30s\n",
      "\n",
      "[EPOCH 48/110]\n",
      "  Batch [10/13] - Loss: 0.4382\n",
      "  Train Loss: 0.4406\n",
      "  Val Loss: 0.6105\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 49/110]\n",
      "  Batch [10/13] - Loss: 0.4797\n",
      "  Train Loss: 0.4406\n",
      "  Val Loss: 0.6111\n",
      "  Time: 6.08s\n",
      "\n",
      "[EPOCH 50/110]\n",
      "  Batch [10/13] - Loss: 0.4755\n",
      "  Train Loss: 0.4548\n",
      "  Val Loss: 0.6118\n",
      "  Time: 6.31s\n",
      "\n",
      "[EPOCH 51/110]\n",
      "  Batch [10/13] - Loss: 0.4778\n",
      "  Train Loss: 0.4411\n",
      "  Val Loss: 0.6064\n",
      "  Time: 6.06s\n",
      "\n",
      "[EPOCH 52/110]\n",
      "  Batch [10/13] - Loss: 0.4596\n",
      "  Train Loss: 0.4406\n",
      "  Val Loss: 0.6059\n",
      "  Time: 6.32s\n",
      "\n",
      "[EPOCH 53/110]\n",
      "  Batch [10/13] - Loss: 0.4605\n",
      "  Train Loss: 0.4490\n",
      "  Val Loss: 0.6056\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 54/110]\n",
      "  Batch [10/13] - Loss: 0.4133\n",
      "  Train Loss: 0.4281\n",
      "  Val Loss: 0.6088\n",
      "  Time: 6.00s\n",
      "\n",
      "[EPOCH 55/110]\n",
      "  Batch [10/13] - Loss: 0.5272\n",
      "  Train Loss: 0.4417\n",
      "  Val Loss: 0.6095\n",
      "  Time: 6.30s\n",
      "\n",
      "[EPOCH 56/110]\n",
      "  Batch [10/13] - Loss: 0.4334\n",
      "  Train Loss: 0.4387\n",
      "  Val Loss: 0.6082\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 57/110]\n",
      "  Batch [10/13] - Loss: 0.4431\n",
      "  Train Loss: 0.4452\n",
      "  Val Loss: 0.5907\n",
      "  Time: 6.28s\n",
      "\n",
      "[EPOCH 58/110]\n",
      "  Batch [10/13] - Loss: 0.4085\n",
      "  Train Loss: 0.4436\n",
      "  Val Loss: 0.6036\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 59/110]\n",
      "  Batch [10/13] - Loss: 0.4945\n",
      "  Train Loss: 0.4358\n",
      "  Val Loss: 0.5987\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 60/110]\n",
      "  Batch [10/13] - Loss: 0.4929\n",
      "  Train Loss: 0.4470\n",
      "  Val Loss: 0.6098\n",
      "  Time: 6.21s\n",
      "\n",
      "[EPOCH 61/110]\n",
      "  Batch [10/13] - Loss: 0.4984\n",
      "  Train Loss: 0.4529\n",
      "  Val Loss: 0.6056\n",
      "  Time: 6.21s\n",
      "\n",
      "[EPOCH 62/110]\n",
      "  Batch [10/13] - Loss: 0.4280\n",
      "  Train Loss: 0.4395\n",
      "  Val Loss: 0.6064\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 63/110]\n",
      "  Batch [10/13] - Loss: 0.4315\n",
      "  Train Loss: 0.4434\n",
      "  Val Loss: 0.5992\n",
      "  Time: 6.19s\n",
      "\n",
      "[EPOCH 64/110]\n",
      "  Batch [10/13] - Loss: 0.4342\n",
      "  Train Loss: 0.4387\n",
      "  Val Loss: 0.6084\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 65/110]\n",
      "  Batch [10/13] - Loss: 0.4631\n",
      "  Train Loss: 0.4423\n",
      "  Val Loss: 0.5982\n",
      "  Time: 6.20s\n",
      "\n",
      "[EPOCH 66/110]\n",
      "  Batch [10/13] - Loss: 0.4535\n",
      "  Train Loss: 0.4394\n",
      "  Val Loss: 0.6172\n",
      "  Time: 6.21s\n",
      "\n",
      "[EPOCH 67/110]\n",
      "  Batch [10/13] - Loss: 0.4460\n",
      "  Train Loss: 0.4439\n",
      "  Val Loss: 0.6136\n",
      "  Time: 6.23s\n",
      "\n",
      "[EPOCH 68/110]\n",
      "  Batch [10/13] - Loss: 0.4271\n",
      "  Train Loss: 0.4446\n",
      "  Val Loss: 0.6190\n",
      "  Time: 6.23s\n",
      "\n",
      "[EPOCH 69/110]\n",
      "  Batch [10/13] - Loss: 0.4056\n",
      "  Train Loss: 0.4380\n",
      "  Val Loss: 0.6061\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 70/110]\n",
      "  Batch [10/13] - Loss: 0.4139\n",
      "  Train Loss: 0.4474\n",
      "  Val Loss: 0.5966\n",
      "  Time: 6.27s\n",
      "\n",
      "[EARLY STOPPING] No improvement for 35 epochs\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 35\n",
      "  Best Val Loss: 0.5849\n",
      "  Total Time: 14.27 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_048_arch_score_010_v1/plots\n",
      "\n",
      "[OK] Training completed for arch_score_010_v1!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_048_arch_score_010_v1\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 1147 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.63s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.786\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.684\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.737\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.738\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 40.11 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_048_arch_score_010_v1/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7856\n",
      "  mAP@0.5:0.95: 0.5342\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: arch_score_015_v1\n",
      "  Best config + score threshold 0.15 (strict)\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_049_arch_score_015_v1\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_049_arch_score_015_v1\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 52 images\n",
      "[OK] Loaded 2322 annotations\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training for 110 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/110]\n",
      "  Batch [10/13] - Loss: 0.9886\n",
      "  Train Loss: 1.7587\n",
      "  Val Loss: 1.0702\n",
      "  Time: 6.30s\n",
      "  ✓ Best model saved (val_loss: 1.0702)\n",
      "\n",
      "[EPOCH 2/110]\n",
      "  Batch [10/13] - Loss: 0.9240\n",
      "  Train Loss: 0.9139\n",
      "  Val Loss: 0.8739\n",
      "  Time: 6.25s\n",
      "  ✓ Best model saved (val_loss: 0.8739)\n",
      "\n",
      "[EPOCH 3/110]\n",
      "  Batch [10/13] - Loss: 0.6615\n",
      "  Train Loss: 0.7295\n",
      "  Val Loss: 0.8270\n",
      "  Time: 6.31s\n",
      "  ✓ Best model saved (val_loss: 0.8270)\n",
      "\n",
      "[EPOCH 4/110]\n",
      "  Batch [10/13] - Loss: 0.6416\n",
      "  Train Loss: 0.6728\n",
      "  Val Loss: 0.7249\n",
      "  Time: 6.45s\n",
      "  ✓ Best model saved (val_loss: 0.7249)\n",
      "\n",
      "[EPOCH 5/110]\n",
      "  Batch [10/13] - Loss: 0.5917\n",
      "  Train Loss: 0.6192\n",
      "  Val Loss: 0.7413\n",
      "  Time: 6.04s\n",
      "\n",
      "[EPOCH 6/110]\n",
      "  Batch [10/13] - Loss: 0.5407\n",
      "  Train Loss: 0.5672\n",
      "  Val Loss: 0.6716\n",
      "  Time: 6.02s\n",
      "  ✓ Best model saved (val_loss: 0.6716)\n",
      "\n",
      "[EPOCH 7/110]\n",
      "  Batch [10/13] - Loss: 0.5103\n",
      "  Train Loss: 0.5599\n",
      "  Val Loss: 0.6540\n",
      "  Time: 6.09s\n",
      "  ✓ Best model saved (val_loss: 0.6540)\n",
      "\n",
      "[EPOCH 8/110]\n",
      "  Batch [10/13] - Loss: 0.5570\n",
      "  Train Loss: 0.5546\n",
      "  Val Loss: 0.6577\n",
      "  Time: 6.20s\n",
      "\n",
      "[EPOCH 9/110]\n",
      "  Batch [10/13] - Loss: 0.5125\n",
      "  Train Loss: 0.5109\n",
      "  Val Loss: 0.6451\n",
      "  Time: 6.25s\n",
      "  ✓ Best model saved (val_loss: 0.6451)\n",
      "\n",
      "[EPOCH 10/110]\n",
      "  Batch [10/13] - Loss: 0.4985\n",
      "  Train Loss: 0.5087\n",
      "  Val Loss: 0.6701\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 11/110]\n",
      "  Batch [10/13] - Loss: 0.5352\n",
      "  Train Loss: 0.5120\n",
      "  Val Loss: 0.6250\n",
      "  Time: 6.20s\n",
      "  ✓ Best model saved (val_loss: 0.6250)\n",
      "\n",
      "[EPOCH 12/110]\n",
      "  Batch [10/13] - Loss: 0.4696\n",
      "  Train Loss: 0.5130\n",
      "  Val Loss: 0.6645\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 13/110]\n",
      "  Batch [10/13] - Loss: 0.4815\n",
      "  Train Loss: 0.5080\n",
      "  Val Loss: 0.6255\n",
      "  Time: 6.20s\n",
      "\n",
      "[EPOCH 14/110]\n",
      "  Batch [10/13] - Loss: 0.5398\n",
      "  Train Loss: 0.5028\n",
      "  Val Loss: 0.6822\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 15/110]\n",
      "  Batch [10/13] - Loss: 0.4749\n",
      "  Train Loss: 0.5077\n",
      "  Val Loss: 0.6634\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 16/110]\n",
      "  Batch [10/13] - Loss: 0.4832\n",
      "  Train Loss: 0.4938\n",
      "  Val Loss: 0.6464\n",
      "  Time: 6.26s\n",
      "\n",
      "[EPOCH 17/110]\n",
      "  Batch [10/13] - Loss: 0.4555\n",
      "  Train Loss: 0.4665\n",
      "  Val Loss: 0.6197\n",
      "  Time: 6.23s\n",
      "  ✓ Best model saved (val_loss: 0.6197)\n",
      "\n",
      "[EPOCH 18/110]\n",
      "  Batch [10/13] - Loss: 0.4762\n",
      "  Train Loss: 0.4874\n",
      "  Val Loss: 0.6481\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 19/110]\n",
      "  Batch [10/13] - Loss: 0.4575\n",
      "  Train Loss: 0.4968\n",
      "  Val Loss: 0.6289\n",
      "  Time: 6.12s\n",
      "\n",
      "[EPOCH 20/110]\n",
      "  Batch [10/13] - Loss: 0.4393\n",
      "  Train Loss: 0.4728\n",
      "  Val Loss: 0.6231\n",
      "  Time: 6.23s\n",
      "\n",
      "[EPOCH 21/110]\n",
      "  Batch [10/13] - Loss: 0.4632\n",
      "  Train Loss: 0.4719\n",
      "  Val Loss: 0.6247\n",
      "  Time: 6.21s\n",
      "\n",
      "[EPOCH 22/110]\n",
      "  Batch [10/13] - Loss: 0.4365\n",
      "  Train Loss: 0.4470\n",
      "  Val Loss: 0.6159\n",
      "  Time: 6.25s\n",
      "  ✓ Best model saved (val_loss: 0.6159)\n",
      "\n",
      "[EPOCH 23/110]\n",
      "  Batch [10/13] - Loss: 0.4275\n",
      "  Train Loss: 0.4471\n",
      "  Val Loss: 0.6179\n",
      "  Time: 6.02s\n",
      "\n",
      "[EPOCH 24/110]\n",
      "  Batch [10/13] - Loss: 0.4229\n",
      "  Train Loss: 0.4384\n",
      "  Val Loss: 0.6165\n",
      "  Time: 6.26s\n",
      "\n",
      "[EPOCH 25/110]\n",
      "  Batch [10/13] - Loss: 0.4048\n",
      "  Train Loss: 0.4399\n",
      "  Val Loss: 0.6139\n",
      "  Time: 6.29s\n",
      "  ✓ Best model saved (val_loss: 0.6139)\n",
      "\n",
      "[EPOCH 26/110]\n",
      "  Batch [10/13] - Loss: 0.3974\n",
      "  Train Loss: 0.4423\n",
      "  Val Loss: 0.6233\n",
      "  Time: 6.23s\n",
      "\n",
      "[EPOCH 27/110]\n",
      "  Batch [10/13] - Loss: 0.4172\n",
      "  Train Loss: 0.4600\n",
      "  Val Loss: 0.6112\n",
      "  Time: 6.25s\n",
      "  ✓ Best model saved (val_loss: 0.6112)\n",
      "\n",
      "[EPOCH 28/110]\n",
      "  Batch [10/13] - Loss: 0.4435\n",
      "  Train Loss: 0.4403\n",
      "  Val Loss: 0.6174\n",
      "  Time: 6.28s\n",
      "\n",
      "[EPOCH 29/110]\n",
      "  Batch [10/13] - Loss: 0.3953\n",
      "  Train Loss: 0.4453\n",
      "  Val Loss: 0.6182\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 30/110]\n",
      "  Batch [10/13] - Loss: 0.4081\n",
      "  Train Loss: 0.4466\n",
      "  Val Loss: 0.6158\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 31/110]\n",
      "  Batch [10/13] - Loss: 0.3926\n",
      "  Train Loss: 0.4379\n",
      "  Val Loss: 0.6348\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 32/110]\n",
      "  Batch [10/13] - Loss: 0.4413\n",
      "  Train Loss: 0.4326\n",
      "  Val Loss: 0.6169\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 33/110]\n",
      "  Batch [10/13] - Loss: 0.4322\n",
      "  Train Loss: 0.4513\n",
      "  Val Loss: 0.6279\n",
      "  Time: 6.02s\n",
      "\n",
      "[EPOCH 34/110]\n",
      "  Batch [10/13] - Loss: 0.4270\n",
      "  Train Loss: 0.4317\n",
      "  Val Loss: 0.6333\n",
      "  Time: 6.23s\n",
      "\n",
      "[EPOCH 35/110]\n",
      "  Batch [10/13] - Loss: 0.4059\n",
      "  Train Loss: 0.4432\n",
      "  Val Loss: 0.6109\n",
      "  Time: 6.25s\n",
      "  ✓ Best model saved (val_loss: 0.6109)\n",
      "\n",
      "[EPOCH 36/110]\n",
      "  Batch [10/13] - Loss: 0.4171\n",
      "  Train Loss: 0.4416\n",
      "  Val Loss: 0.6259\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 37/110]\n",
      "  Batch [10/13] - Loss: 0.4012\n",
      "  Train Loss: 0.4344\n",
      "  Val Loss: 0.6402\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 38/110]\n",
      "  Batch [10/13] - Loss: 0.3860\n",
      "  Train Loss: 0.4405\n",
      "  Val Loss: 0.6156\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 39/110]\n",
      "  Batch [10/13] - Loss: 0.4306\n",
      "  Train Loss: 0.4476\n",
      "  Val Loss: 0.6285\n",
      "  Time: 6.33s\n",
      "\n",
      "[EPOCH 40/110]\n",
      "  Batch [10/13] - Loss: 0.3681\n",
      "  Train Loss: 0.4360\n",
      "  Val Loss: 0.6265\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 41/110]\n",
      "  Batch [10/13] - Loss: 0.4398\n",
      "  Train Loss: 0.4366\n",
      "  Val Loss: 0.6222\n",
      "  Time: 6.26s\n",
      "\n",
      "[EPOCH 42/110]\n",
      "  Batch [10/13] - Loss: 0.4679\n",
      "  Train Loss: 0.4366\n",
      "  Val Loss: 0.6263\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 43/110]\n",
      "  Batch [10/13] - Loss: 0.4190\n",
      "  Train Loss: 0.4334\n",
      "  Val Loss: 0.6206\n",
      "  Time: 6.23s\n",
      "\n",
      "[EPOCH 44/110]\n",
      "  Batch [10/13] - Loss: 0.4491\n",
      "  Train Loss: 0.4392\n",
      "  Val Loss: 0.6239\n",
      "  Time: 6.28s\n",
      "\n",
      "[EPOCH 45/110]\n",
      "  Batch [10/13] - Loss: 0.4189\n",
      "  Train Loss: 0.4361\n",
      "  Val Loss: 0.6297\n",
      "  Time: 6.52s\n",
      "\n",
      "[EPOCH 46/110]\n",
      "  Batch [10/13] - Loss: 0.4055\n",
      "  Train Loss: 0.4533\n",
      "  Val Loss: 0.6226\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 47/110]\n",
      "  Batch [10/13] - Loss: 0.3856\n",
      "  Train Loss: 0.4451\n",
      "  Val Loss: 0.6472\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 48/110]\n",
      "  Batch [10/13] - Loss: 0.3910\n",
      "  Train Loss: 0.4385\n",
      "  Val Loss: 0.6150\n",
      "  Time: 6.10s\n",
      "\n",
      "[EPOCH 49/110]\n",
      "  Batch [10/13] - Loss: 0.4319\n",
      "  Train Loss: 0.4351\n",
      "  Val Loss: 0.6212\n",
      "  Time: 6.30s\n",
      "\n",
      "[EPOCH 50/110]\n",
      "  Batch [10/13] - Loss: 0.4247\n",
      "  Train Loss: 0.4404\n",
      "  Val Loss: 0.6090\n",
      "  Time: 6.45s\n",
      "  ✓ Best model saved (val_loss: 0.6090)\n",
      "\n",
      "[EPOCH 51/110]\n",
      "  Batch [10/13] - Loss: 0.4185\n",
      "  Train Loss: 0.4477\n",
      "  Val Loss: 0.6178\n",
      "  Time: 6.17s\n",
      "\n",
      "[EPOCH 52/110]\n",
      "  Batch [10/13] - Loss: 0.4131\n",
      "  Train Loss: 0.4340\n",
      "  Val Loss: 0.6232\n",
      "  Time: 6.13s\n",
      "\n",
      "[EPOCH 53/110]\n",
      "  Batch [10/13] - Loss: 0.4447\n",
      "  Train Loss: 0.4407\n",
      "  Val Loss: 0.6209\n",
      "  Time: 6.28s\n",
      "\n",
      "[EPOCH 54/110]\n",
      "  Batch [10/13] - Loss: 0.4400\n",
      "  Train Loss: 0.4393\n",
      "  Val Loss: 0.6112\n",
      "  Time: 6.37s\n",
      "\n",
      "[EPOCH 55/110]\n",
      "  Batch [10/13] - Loss: 0.4017\n",
      "  Train Loss: 0.4318\n",
      "  Val Loss: 0.6168\n",
      "  Time: 6.30s\n",
      "\n",
      "[EPOCH 56/110]\n",
      "  Batch [10/13] - Loss: 0.4018\n",
      "  Train Loss: 0.4407\n",
      "  Val Loss: 0.6223\n",
      "  Time: 6.23s\n",
      "\n",
      "[EPOCH 57/110]\n",
      "  Batch [10/13] - Loss: 0.3755\n",
      "  Train Loss: 0.4348\n",
      "  Val Loss: 0.6232\n",
      "  Time: 6.28s\n",
      "\n",
      "[EPOCH 58/110]\n",
      "  Batch [10/13] - Loss: 0.4429\n",
      "  Train Loss: 0.4449\n",
      "  Val Loss: 0.6266\n",
      "  Time: 6.30s\n",
      "\n",
      "[EPOCH 59/110]\n",
      "  Batch [10/13] - Loss: 0.4157\n",
      "  Train Loss: 0.4350\n",
      "  Val Loss: 0.6119\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 60/110]\n",
      "  Batch [10/13] - Loss: 0.4542\n",
      "  Train Loss: 0.4507\n",
      "  Val Loss: 0.6180\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 61/110]\n",
      "  Batch [10/13] - Loss: 0.4881\n",
      "  Train Loss: 0.4383\n",
      "  Val Loss: 0.6245\n",
      "  Time: 6.08s\n",
      "\n",
      "[EPOCH 62/110]\n",
      "  Batch [10/13] - Loss: 0.4046\n",
      "  Train Loss: 0.4324\n",
      "  Val Loss: 0.6293\n",
      "  Time: 6.11s\n",
      "\n",
      "[EPOCH 63/110]\n",
      "  Batch [10/13] - Loss: 0.4332\n",
      "  Train Loss: 0.4340\n",
      "  Val Loss: 0.6299\n",
      "  Time: 6.26s\n",
      "\n",
      "[EPOCH 64/110]\n",
      "  Batch [10/13] - Loss: 0.3608\n",
      "  Train Loss: 0.4306\n",
      "  Val Loss: 0.6168\n",
      "  Time: 6.26s\n",
      "\n",
      "[EPOCH 65/110]\n",
      "  Batch [10/13] - Loss: 0.4143\n",
      "  Train Loss: 0.4334\n",
      "  Val Loss: 0.6260\n",
      "  Time: 6.20s\n",
      "\n",
      "[EPOCH 66/110]\n",
      "  Batch [10/13] - Loss: 0.3822\n",
      "  Train Loss: 0.4432\n",
      "  Val Loss: 0.6344\n",
      "  Time: 6.08s\n",
      "\n",
      "[EPOCH 67/110]\n",
      "  Batch [10/13] - Loss: 0.3891\n",
      "  Train Loss: 0.4270\n",
      "  Val Loss: 0.6188\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 68/110]\n",
      "  Batch [10/13] - Loss: 0.4473\n",
      "  Train Loss: 0.4465\n",
      "  Val Loss: 0.6174\n",
      "  Time: 6.21s\n",
      "\n",
      "[EPOCH 69/110]\n",
      "  Batch [10/13] - Loss: 0.4744\n",
      "  Train Loss: 0.4380\n",
      "  Val Loss: 0.6249\n",
      "  Time: 6.12s\n",
      "\n",
      "[EPOCH 70/110]\n",
      "  Batch [10/13] - Loss: 0.4169\n",
      "  Train Loss: 0.4387\n",
      "  Val Loss: 0.6213\n",
      "  Time: 6.16s\n",
      "\n",
      "[EPOCH 71/110]\n",
      "  Batch [10/13] - Loss: 0.4100\n",
      "  Train Loss: 0.4348\n",
      "  Val Loss: 0.6205\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 72/110]\n",
      "  Batch [10/13] - Loss: 0.4557\n",
      "  Train Loss: 0.4354\n",
      "  Val Loss: 0.6314\n",
      "  Time: 6.37s\n",
      "\n",
      "[EPOCH 73/110]\n",
      "  Batch [10/13] - Loss: 0.4995\n",
      "  Train Loss: 0.4423\n",
      "  Val Loss: 0.6389\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 74/110]\n",
      "  Batch [10/13] - Loss: 0.3981\n",
      "  Train Loss: 0.4364\n",
      "  Val Loss: 0.6301\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 75/110]\n",
      "  Batch [10/13] - Loss: 0.4497\n",
      "  Train Loss: 0.4367\n",
      "  Val Loss: 0.6291\n",
      "  Time: 6.32s\n",
      "\n",
      "[EPOCH 76/110]\n",
      "  Batch [10/13] - Loss: 0.3961\n",
      "  Train Loss: 0.4334\n",
      "  Val Loss: 0.6229\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 77/110]\n",
      "  Batch [10/13] - Loss: 0.3899\n",
      "  Train Loss: 0.4371\n",
      "  Val Loss: 0.6192\n",
      "  Time: 6.15s\n",
      "\n",
      "[EPOCH 78/110]\n",
      "  Batch [10/13] - Loss: 0.4348\n",
      "  Train Loss: 0.4467\n",
      "  Val Loss: 0.6301\n",
      "  Time: 6.32s\n",
      "\n",
      "[EPOCH 79/110]\n",
      "  Batch [10/13] - Loss: 0.4463\n",
      "  Train Loss: 0.4350\n",
      "  Val Loss: 0.6352\n",
      "  Time: 6.09s\n",
      "\n",
      "[EPOCH 80/110]\n",
      "  Batch [10/13] - Loss: 0.4246\n",
      "  Train Loss: 0.4356\n",
      "  Val Loss: 0.6216\n",
      "  Time: 6.31s\n",
      "\n",
      "[EPOCH 81/110]\n",
      "  Batch [10/13] - Loss: 0.4232\n",
      "  Train Loss: 0.4344\n",
      "  Val Loss: 0.6373\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 82/110]\n",
      "  Batch [10/13] - Loss: 0.4435\n",
      "  Train Loss: 0.4398\n",
      "  Val Loss: 0.6256\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 83/110]\n",
      "  Batch [10/13] - Loss: 0.4532\n",
      "  Train Loss: 0.4341\n",
      "  Val Loss: 0.6311\n",
      "  Time: 6.26s\n",
      "\n",
      "[EPOCH 84/110]\n",
      "  Batch [10/13] - Loss: 0.4167\n",
      "  Train Loss: 0.4388\n",
      "  Val Loss: 0.6329\n",
      "  Time: 6.51s\n",
      "\n",
      "[EPOCH 85/110]\n",
      "  Batch [10/13] - Loss: 0.4469\n",
      "  Train Loss: 0.4359\n",
      "  Val Loss: 0.6372\n",
      "  Time: 6.29s\n",
      "\n",
      "[EARLY STOPPING] No improvement for 35 epochs\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 50\n",
      "  Best Val Loss: 0.6090\n",
      "  Total Time: 16.00 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_049_arch_score_015_v1/plots\n",
      "\n",
      "[OK] Training completed for arch_score_015_v1!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_049_arch_score_015_v1\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 1103 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.787\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.700\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.536\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.732\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 40.42 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_049_arch_score_015_v1/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7870\n",
      "  mAP@0.5:0.95: 0.5351\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: arch_rpn_dense_v1\n",
      "  Best config + RPN thresholds optimized for density\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_050_arch_rpn_dense_v1\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_050_arch_rpn_dense_v1\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 52 images\n",
      "[OK] Loaded 2322 annotations\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training for 110 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/110]\n",
      "  Batch [10/13] - Loss: 1.2598\n",
      "  Train Loss: 1.6917\n",
      "  Val Loss: 1.2272\n",
      "  Time: 6.03s\n",
      "  ✓ Best model saved (val_loss: 1.2272)\n",
      "\n",
      "[EPOCH 2/110]\n",
      "  Batch [10/13] - Loss: 0.8176\n",
      "  Train Loss: 0.9080\n",
      "  Val Loss: 0.8907\n",
      "  Time: 6.25s\n",
      "  ✓ Best model saved (val_loss: 0.8907)\n",
      "\n",
      "[EPOCH 3/110]\n",
      "  Batch [10/13] - Loss: 0.8524\n",
      "  Train Loss: 0.7023\n",
      "  Val Loss: 0.7847\n",
      "  Time: 6.23s\n",
      "  ✓ Best model saved (val_loss: 0.7847)\n",
      "\n",
      "[EPOCH 4/110]\n",
      "  Batch [10/13] - Loss: 0.6782\n",
      "  Train Loss: 0.6427\n",
      "  Val Loss: 0.7772\n",
      "  Time: 6.19s\n",
      "  ✓ Best model saved (val_loss: 0.7772)\n",
      "\n",
      "[EPOCH 5/110]\n",
      "  Batch [10/13] - Loss: 0.6209\n",
      "  Train Loss: 0.6214\n",
      "  Val Loss: 0.6890\n",
      "  Time: 6.27s\n",
      "  ✓ Best model saved (val_loss: 0.6890)\n",
      "\n",
      "[EPOCH 6/110]\n",
      "  Batch [10/13] - Loss: 0.6319\n",
      "  Train Loss: 0.5792\n",
      "  Val Loss: 0.6671\n",
      "  Time: 6.33s\n",
      "  ✓ Best model saved (val_loss: 0.6671)\n",
      "\n",
      "[EPOCH 7/110]\n",
      "  Batch [10/13] - Loss: 0.5678\n",
      "  Train Loss: 0.5593\n",
      "  Val Loss: 0.6808\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 8/110]\n",
      "  Batch [10/13] - Loss: 0.6048\n",
      "  Train Loss: 0.5558\n",
      "  Val Loss: 0.6669\n",
      "  Time: 6.29s\n",
      "  ✓ Best model saved (val_loss: 0.6669)\n",
      "\n",
      "[EPOCH 9/110]\n",
      "  Batch [10/13] - Loss: 0.5774\n",
      "  Train Loss: 0.5402\n",
      "  Val Loss: 0.6694\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 10/110]\n",
      "  Batch [10/13] - Loss: 0.5447\n",
      "  Train Loss: 0.5517\n",
      "  Val Loss: 0.6431\n",
      "  Time: 6.37s\n",
      "  ✓ Best model saved (val_loss: 0.6431)\n",
      "\n",
      "[EPOCH 11/110]\n",
      "  Batch [10/13] - Loss: 0.5805\n",
      "  Train Loss: 0.5392\n",
      "  Val Loss: 0.6707\n",
      "  Time: 6.45s\n",
      "\n",
      "[EPOCH 12/110]\n",
      "  Batch [10/13] - Loss: 0.5069\n",
      "  Train Loss: 0.5431\n",
      "  Val Loss: 0.6294\n",
      "  Time: 6.33s\n",
      "  ✓ Best model saved (val_loss: 0.6294)\n",
      "\n",
      "[EPOCH 13/110]\n",
      "  Batch [10/13] - Loss: 0.5449\n",
      "  Train Loss: 0.5109\n",
      "  Val Loss: 0.6278\n",
      "  Time: 6.12s\n",
      "  ✓ Best model saved (val_loss: 0.6278)\n",
      "\n",
      "[EPOCH 14/110]\n",
      "  Batch [10/13] - Loss: 0.5505\n",
      "  Train Loss: 0.5092\n",
      "  Val Loss: 0.6234\n",
      "  Time: 6.29s\n",
      "  ✓ Best model saved (val_loss: 0.6234)\n",
      "\n",
      "[EPOCH 15/110]\n",
      "  Batch [10/13] - Loss: 0.5132\n",
      "  Train Loss: 0.5043\n",
      "  Val Loss: 0.6170\n",
      "  Time: 6.23s\n",
      "  ✓ Best model saved (val_loss: 0.6170)\n",
      "\n",
      "[EPOCH 16/110]\n",
      "  Batch [10/13] - Loss: 0.4638\n",
      "  Train Loss: 0.5146\n",
      "  Val Loss: 0.6484\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 17/110]\n",
      "  Batch [10/13] - Loss: 0.5400\n",
      "  Train Loss: 0.5098\n",
      "  Val Loss: 0.6282\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 18/110]\n",
      "  Batch [10/13] - Loss: 0.5784\n",
      "  Train Loss: 0.4928\n",
      "  Val Loss: 0.6283\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 19/110]\n",
      "  Batch [10/13] - Loss: 0.4930\n",
      "  Train Loss: 0.4836\n",
      "  Val Loss: 0.6188\n",
      "  Time: 6.32s\n",
      "\n",
      "[EPOCH 20/110]\n",
      "  Batch [10/13] - Loss: 0.4955\n",
      "  Train Loss: 0.4853\n",
      "  Val Loss: 0.6323\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 21/110]\n",
      "  Batch [10/13] - Loss: 0.4871\n",
      "  Train Loss: 0.4799\n",
      "  Val Loss: 0.6335\n",
      "  Time: 6.32s\n",
      "\n",
      "[EPOCH 22/110]\n",
      "  Batch [10/13] - Loss: 0.4767\n",
      "  Train Loss: 0.4592\n",
      "  Val Loss: 0.5942\n",
      "  Time: 6.30s\n",
      "  ✓ Best model saved (val_loss: 0.5942)\n",
      "\n",
      "[EPOCH 23/110]\n",
      "  Batch [10/13] - Loss: 0.4651\n",
      "  Train Loss: 0.4582\n",
      "  Val Loss: 0.6034\n",
      "  Time: 6.10s\n",
      "\n",
      "[EPOCH 24/110]\n",
      "  Batch [10/13] - Loss: 0.4716\n",
      "  Train Loss: 0.4627\n",
      "  Val Loss: 0.6208\n",
      "  Time: 6.37s\n",
      "\n",
      "[EPOCH 25/110]\n",
      "  Batch [10/13] - Loss: 0.4911\n",
      "  Train Loss: 0.4606\n",
      "  Val Loss: 0.5838\n",
      "  Time: 6.45s\n",
      "  ✓ Best model saved (val_loss: 0.5838)\n",
      "\n",
      "[EPOCH 26/110]\n",
      "  Batch [10/13] - Loss: 0.4491\n",
      "  Train Loss: 0.4516\n",
      "  Val Loss: 0.6149\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 27/110]\n",
      "  Batch [10/13] - Loss: 0.4613\n",
      "  Train Loss: 0.4523\n",
      "  Val Loss: 0.5989\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 28/110]\n",
      "  Batch [10/13] - Loss: 0.4621\n",
      "  Train Loss: 0.4544\n",
      "  Val Loss: 0.6082\n",
      "  Time: 6.12s\n",
      "\n",
      "[EPOCH 29/110]\n",
      "  Batch [10/13] - Loss: 0.4446\n",
      "  Train Loss: 0.4506\n",
      "  Val Loss: 0.6353\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 30/110]\n",
      "  Batch [10/13] - Loss: 0.4444\n",
      "  Train Loss: 0.4499\n",
      "  Val Loss: 0.6017\n",
      "  Time: 6.29s\n",
      "\n",
      "[EPOCH 31/110]\n",
      "  Batch [10/13] - Loss: 0.4706\n",
      "  Train Loss: 0.4537\n",
      "  Val Loss: 0.5965\n",
      "  Time: 6.30s\n",
      "\n",
      "[EPOCH 32/110]\n",
      "  Batch [10/13] - Loss: 0.4043\n",
      "  Train Loss: 0.4475\n",
      "  Val Loss: 0.5941\n",
      "  Time: 6.29s\n",
      "\n",
      "[EPOCH 33/110]\n",
      "  Batch [10/13] - Loss: 0.5160\n",
      "  Train Loss: 0.4531\n",
      "  Val Loss: 0.6116\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 34/110]\n",
      "  Batch [10/13] - Loss: 0.4686\n",
      "  Train Loss: 0.4589\n",
      "  Val Loss: 0.6146\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 35/110]\n",
      "  Batch [10/13] - Loss: 0.4582\n",
      "  Train Loss: 0.4538\n",
      "  Val Loss: 0.6233\n",
      "  Time: 6.12s\n",
      "\n",
      "[EPOCH 36/110]\n",
      "  Batch [10/13] - Loss: 0.4908\n",
      "  Train Loss: 0.4578\n",
      "  Val Loss: 0.6144\n",
      "  Time: 6.11s\n",
      "\n",
      "[EPOCH 37/110]\n",
      "  Batch [10/13] - Loss: 0.4607\n",
      "  Train Loss: 0.4592\n",
      "  Val Loss: 0.6036\n",
      "  Time: 6.28s\n",
      "\n",
      "[EPOCH 38/110]\n",
      "  Batch [10/13] - Loss: 0.4631\n",
      "  Train Loss: 0.4512\n",
      "  Val Loss: 0.5946\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 39/110]\n",
      "  Batch [10/13] - Loss: 0.5468\n",
      "  Train Loss: 0.4587\n",
      "  Val Loss: 0.6199\n",
      "  Time: 6.23s\n",
      "\n",
      "[EPOCH 40/110]\n",
      "  Batch [10/13] - Loss: 0.5844\n",
      "  Train Loss: 0.4532\n",
      "  Val Loss: 0.6181\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 41/110]\n",
      "  Batch [10/13] - Loss: 0.5453\n",
      "  Train Loss: 0.4494\n",
      "  Val Loss: 0.6020\n",
      "  Time: 6.09s\n",
      "\n",
      "[EPOCH 42/110]\n",
      "  Batch [10/13] - Loss: 0.4453\n",
      "  Train Loss: 0.4463\n",
      "  Val Loss: 0.6064\n",
      "  Time: 6.33s\n",
      "\n",
      "[EPOCH 43/110]\n",
      "  Batch [10/13] - Loss: 0.4445\n",
      "  Train Loss: 0.4507\n",
      "  Val Loss: 0.5966\n",
      "  Time: 6.33s\n",
      "\n",
      "[EPOCH 44/110]\n",
      "  Batch [10/13] - Loss: 0.4085\n",
      "  Train Loss: 0.4564\n",
      "  Val Loss: 0.6077\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 45/110]\n",
      "  Batch [10/13] - Loss: 0.4624\n",
      "  Train Loss: 0.4379\n",
      "  Val Loss: 0.6069\n",
      "  Time: 6.44s\n",
      "\n",
      "[EPOCH 46/110]\n",
      "  Batch [10/13] - Loss: 0.4216\n",
      "  Train Loss: 0.4438\n",
      "  Val Loss: 0.6249\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 47/110]\n",
      "  Batch [10/13] - Loss: 0.4823\n",
      "  Train Loss: 0.4505\n",
      "  Val Loss: 0.6072\n",
      "  Time: 6.26s\n",
      "\n",
      "[EPOCH 48/110]\n",
      "  Batch [10/13] - Loss: 0.4590\n",
      "  Train Loss: 0.4521\n",
      "  Val Loss: 0.6119\n",
      "  Time: 6.08s\n",
      "\n",
      "[EPOCH 49/110]\n",
      "  Batch [10/13] - Loss: 0.4901\n",
      "  Train Loss: 0.4487\n",
      "  Val Loss: 0.6220\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 50/110]\n",
      "  Batch [10/13] - Loss: 0.4382\n",
      "  Train Loss: 0.4517\n",
      "  Val Loss: 0.6104\n",
      "  Time: 6.28s\n",
      "\n",
      "[EPOCH 51/110]\n",
      "  Batch [10/13] - Loss: 0.4064\n",
      "  Train Loss: 0.4378\n",
      "  Val Loss: 0.6070\n",
      "  Time: 6.29s\n",
      "\n",
      "[EPOCH 52/110]\n",
      "  Batch [10/13] - Loss: 0.4537\n",
      "  Train Loss: 0.4510\n",
      "  Val Loss: 0.6126\n",
      "  Time: 6.55s\n",
      "\n",
      "[EPOCH 53/110]\n",
      "  Batch [10/13] - Loss: 0.4824\n",
      "  Train Loss: 0.4468\n",
      "  Val Loss: 0.6157\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 54/110]\n",
      "  Batch [10/13] - Loss: 0.4248\n",
      "  Train Loss: 0.4484\n",
      "  Val Loss: 0.6010\n",
      "  Time: 6.30s\n",
      "\n",
      "[EPOCH 55/110]\n",
      "  Batch [10/13] - Loss: 0.4307\n",
      "  Train Loss: 0.4431\n",
      "  Val Loss: 0.6034\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 56/110]\n",
      "  Batch [10/13] - Loss: 0.5129\n",
      "  Train Loss: 0.4515\n",
      "  Val Loss: 0.6173\n",
      "  Time: 6.30s\n",
      "\n",
      "[EPOCH 57/110]\n",
      "  Batch [10/13] - Loss: 0.4829\n",
      "  Train Loss: 0.4477\n",
      "  Val Loss: 0.6269\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 58/110]\n",
      "  Batch [10/13] - Loss: 0.3473\n",
      "  Train Loss: 0.4530\n",
      "  Val Loss: 0.6047\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 59/110]\n",
      "  Batch [10/13] - Loss: 0.4867\n",
      "  Train Loss: 0.4473\n",
      "  Val Loss: 0.6224\n",
      "  Time: 6.37s\n",
      "\n",
      "[EPOCH 60/110]\n",
      "  Batch [10/13] - Loss: 0.4294\n",
      "  Train Loss: 0.4491\n",
      "  Val Loss: 0.6167\n",
      "  Time: 6.27s\n",
      "\n",
      "[EARLY STOPPING] No improvement for 35 epochs\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 25\n",
      "  Best Val Loss: 0.5838\n",
      "  Total Time: 10.72 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_050_arch_rpn_dense_v1/plots\n",
      "\n",
      "[OK] Training completed for arch_rpn_dense_v1!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_050_arch_rpn_dense_v1\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 1213 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.70s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.783\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.701\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.741\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 50.66 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_050_arch_rpn_dense_v1/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7827\n",
      "  mAP@0.5:0.95: 0.5369\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: arch_pos_frac_030_v1\n",
      "  Best config + positive fraction 0.30\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_051_arch_pos_frac_030_v1\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_051_arch_pos_frac_030_v1\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 52 images\n",
      "[OK] Loaded 2322 annotations\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training for 110 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/110]\n",
      "  Batch [10/13] - Loss: 1.2048\n",
      "  Train Loss: 1.7351\n",
      "  Val Loss: 1.0477\n",
      "  Time: 6.25s\n",
      "  ✓ Best model saved (val_loss: 1.0477)\n",
      "\n",
      "[EPOCH 2/110]\n",
      "  Batch [10/13] - Loss: 0.8887\n",
      "  Train Loss: 0.8731\n",
      "  Val Loss: 0.9966\n",
      "  Time: 6.39s\n",
      "  ✓ Best model saved (val_loss: 0.9966)\n",
      "\n",
      "[EPOCH 3/110]\n",
      "  Batch [10/13] - Loss: 0.7086\n",
      "  Train Loss: 0.7531\n",
      "  Val Loss: 0.8214\n",
      "  Time: 6.27s\n",
      "  ✓ Best model saved (val_loss: 0.8214)\n",
      "\n",
      "[EPOCH 4/110]\n",
      "  Batch [10/13] - Loss: 0.6276\n",
      "  Train Loss: 0.6437\n",
      "  Val Loss: 0.7186\n",
      "  Time: 6.38s\n",
      "  ✓ Best model saved (val_loss: 0.7186)\n",
      "\n",
      "[EPOCH 5/110]\n",
      "  Batch [10/13] - Loss: 0.5452\n",
      "  Train Loss: 0.6043\n",
      "  Val Loss: 0.7055\n",
      "  Time: 6.33s\n",
      "  ✓ Best model saved (val_loss: 0.7055)\n",
      "\n",
      "[EPOCH 6/110]\n",
      "  Batch [10/13] - Loss: 0.4889\n",
      "  Train Loss: 0.5725\n",
      "  Val Loss: 0.6852\n",
      "  Time: 6.08s\n",
      "  ✓ Best model saved (val_loss: 0.6852)\n",
      "\n",
      "[EPOCH 7/110]\n",
      "  Batch [10/13] - Loss: 0.4894\n",
      "  Train Loss: 0.5531\n",
      "  Val Loss: 0.6964\n",
      "  Time: 6.16s\n",
      "\n",
      "[EPOCH 8/110]\n",
      "  Batch [10/13] - Loss: 0.5888\n",
      "  Train Loss: 0.5513\n",
      "  Val Loss: 0.6669\n",
      "  Time: 6.76s\n",
      "  ✓ Best model saved (val_loss: 0.6669)\n",
      "\n",
      "[EPOCH 9/110]\n",
      "  Batch [10/13] - Loss: 0.4878\n",
      "  Train Loss: 0.5408\n",
      "  Val Loss: 0.6671\n",
      "  Time: 7.42s\n",
      "\n",
      "[EPOCH 10/110]\n",
      "  Batch [10/13] - Loss: 0.4335\n",
      "  Train Loss: 0.5149\n",
      "  Val Loss: 0.6448\n",
      "  Time: 7.37s\n",
      "  ✓ Best model saved (val_loss: 0.6448)\n",
      "\n",
      "[EPOCH 11/110]\n",
      "  Batch [10/13] - Loss: 0.5419\n",
      "  Train Loss: 0.5269\n",
      "  Val Loss: 0.6256\n",
      "  Time: 7.36s\n",
      "  ✓ Best model saved (val_loss: 0.6256)\n",
      "\n",
      "[EPOCH 12/110]\n",
      "  Batch [10/13] - Loss: 0.5008\n",
      "  Train Loss: 0.5164\n",
      "  Val Loss: 0.6381\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 13/110]\n",
      "  Batch [10/13] - Loss: 0.5223\n",
      "  Train Loss: 0.5245\n",
      "  Val Loss: 0.6635\n",
      "  Time: 6.47s\n",
      "\n",
      "[EPOCH 14/110]\n",
      "  Batch [10/13] - Loss: 0.4914\n",
      "  Train Loss: 0.5235\n",
      "  Val Loss: 0.6328\n",
      "  Time: 6.38s\n",
      "\n",
      "[EPOCH 15/110]\n",
      "  Batch [10/13] - Loss: 0.5059\n",
      "  Train Loss: 0.5089\n",
      "  Val Loss: 0.6622\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 16/110]\n",
      "  Batch [10/13] - Loss: 0.4782\n",
      "  Train Loss: 0.5042\n",
      "  Val Loss: 0.6529\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 17/110]\n",
      "  Batch [10/13] - Loss: 0.4544\n",
      "  Train Loss: 0.4937\n",
      "  Val Loss: 0.6444\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 18/110]\n",
      "  Batch [10/13] - Loss: 0.4946\n",
      "  Train Loss: 0.4871\n",
      "  Val Loss: 0.6270\n",
      "  Time: 6.37s\n",
      "\n",
      "[EPOCH 19/110]\n",
      "  Batch [10/13] - Loss: 0.4559\n",
      "  Train Loss: 0.4923\n",
      "  Val Loss: 0.6588\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 20/110]\n",
      "  Batch [10/13] - Loss: 0.4576\n",
      "  Train Loss: 0.4893\n",
      "  Val Loss: 0.6280\n",
      "  Time: 6.45s\n",
      "\n",
      "[EPOCH 21/110]\n",
      "  Batch [10/13] - Loss: 0.4794\n",
      "  Train Loss: 0.4734\n",
      "  Val Loss: 0.6229\n",
      "  Time: 7.42s\n",
      "  ✓ Best model saved (val_loss: 0.6229)\n",
      "\n",
      "[EPOCH 22/110]\n",
      "  Batch [10/13] - Loss: 0.3763\n",
      "  Train Loss: 0.4575\n",
      "  Val Loss: 0.6087\n",
      "  Time: 7.51s\n",
      "  ✓ Best model saved (val_loss: 0.6087)\n",
      "\n",
      "[EPOCH 23/110]\n",
      "  Batch [10/13] - Loss: 0.3996\n",
      "  Train Loss: 0.4430\n",
      "  Val Loss: 0.6131\n",
      "  Time: 7.29s\n",
      "\n",
      "[EPOCH 24/110]\n",
      "  Batch [10/13] - Loss: 0.4597\n",
      "  Train Loss: 0.4669\n",
      "  Val Loss: 0.6176\n",
      "  Time: 7.40s\n",
      "\n",
      "[EPOCH 25/110]\n",
      "  Batch [10/13] - Loss: 0.4355\n",
      "  Train Loss: 0.4486\n",
      "  Val Loss: 0.6111\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 26/110]\n",
      "  Batch [10/13] - Loss: 0.4193\n",
      "  Train Loss: 0.4524\n",
      "  Val Loss: 0.6247\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 27/110]\n",
      "  Batch [10/13] - Loss: 0.4401\n",
      "  Train Loss: 0.4379\n",
      "  Val Loss: 0.6194\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 28/110]\n",
      "  Batch [10/13] - Loss: 0.4181\n",
      "  Train Loss: 0.4544\n",
      "  Val Loss: 0.6148\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 29/110]\n",
      "  Batch [10/13] - Loss: 0.4190\n",
      "  Train Loss: 0.4370\n",
      "  Val Loss: 0.6046\n",
      "  Time: 6.52s\n",
      "  ✓ Best model saved (val_loss: 0.6046)\n",
      "\n",
      "[EPOCH 30/110]\n",
      "  Batch [10/13] - Loss: 0.4410\n",
      "  Train Loss: 0.4483\n",
      "  Val Loss: 0.6193\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 31/110]\n",
      "  Batch [10/13] - Loss: 0.4586\n",
      "  Train Loss: 0.4556\n",
      "  Val Loss: 0.6068\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 32/110]\n",
      "  Batch [10/13] - Loss: 0.4588\n",
      "  Train Loss: 0.4506\n",
      "  Val Loss: 0.6033\n",
      "  Time: 6.40s\n",
      "  ✓ Best model saved (val_loss: 0.6033)\n",
      "\n",
      "[EPOCH 33/110]\n",
      "  Batch [10/13] - Loss: 0.4512\n",
      "  Train Loss: 0.4427\n",
      "  Val Loss: 0.6138\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 34/110]\n",
      "  Batch [10/13] - Loss: 0.3842\n",
      "  Train Loss: 0.4461\n",
      "  Val Loss: 0.6207\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 35/110]\n",
      "  Batch [10/13] - Loss: 0.4366\n",
      "  Train Loss: 0.4498\n",
      "  Val Loss: 0.6124\n",
      "  Time: 6.18s\n",
      "\n",
      "[EPOCH 36/110]\n",
      "  Batch [10/13] - Loss: 0.4082\n",
      "  Train Loss: 0.4457\n",
      "  Val Loss: 0.6335\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 37/110]\n",
      "  Batch [10/13] - Loss: 0.4051\n",
      "  Train Loss: 0.4540\n",
      "  Val Loss: 0.6241\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 38/110]\n",
      "  Batch [10/13] - Loss: 0.4194\n",
      "  Train Loss: 0.4523\n",
      "  Val Loss: 0.6388\n",
      "  Time: 6.47s\n",
      "\n",
      "[EPOCH 39/110]\n",
      "  Batch [10/13] - Loss: 0.4295\n",
      "  Train Loss: 0.4378\n",
      "  Val Loss: 0.6177\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 40/110]\n",
      "  Batch [10/13] - Loss: 0.4255\n",
      "  Train Loss: 0.4587\n",
      "  Val Loss: 0.6156\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 41/110]\n",
      "  Batch [10/13] - Loss: 0.4536\n",
      "  Train Loss: 0.4432\n",
      "  Val Loss: 0.6225\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 42/110]\n",
      "  Batch [10/13] - Loss: 0.4327\n",
      "  Train Loss: 0.4538\n",
      "  Val Loss: 0.6175\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 43/110]\n",
      "  Batch [10/13] - Loss: 0.4504\n",
      "  Train Loss: 0.4371\n",
      "  Val Loss: 0.6026\n",
      "  Time: 6.47s\n",
      "  ✓ Best model saved (val_loss: 0.6026)\n",
      "\n",
      "[EPOCH 44/110]\n",
      "  Batch [10/13] - Loss: 0.3637\n",
      "  Train Loss: 0.4402\n",
      "  Val Loss: 0.6128\n",
      "  Time: 6.50s\n",
      "\n",
      "[EPOCH 45/110]\n",
      "  Batch [10/13] - Loss: 0.3988\n",
      "  Train Loss: 0.4444\n",
      "  Val Loss: 0.6191\n",
      "  Time: 6.16s\n",
      "\n",
      "[EPOCH 46/110]\n",
      "  Batch [10/13] - Loss: 0.4556\n",
      "  Train Loss: 0.4440\n",
      "  Val Loss: 0.6238\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 47/110]\n",
      "  Batch [10/13] - Loss: 0.3785\n",
      "  Train Loss: 0.4430\n",
      "  Val Loss: 0.6179\n",
      "  Time: 6.38s\n",
      "\n",
      "[EPOCH 48/110]\n",
      "  Batch [10/13] - Loss: 0.4774\n",
      "  Train Loss: 0.4435\n",
      "  Val Loss: 0.6195\n",
      "  Time: 6.51s\n",
      "\n",
      "[EPOCH 49/110]\n",
      "  Batch [10/13] - Loss: 0.4247\n",
      "  Train Loss: 0.4432\n",
      "  Val Loss: 0.6267\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 50/110]\n",
      "  Batch [10/13] - Loss: 0.4017\n",
      "  Train Loss: 0.4350\n",
      "  Val Loss: 0.6105\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 51/110]\n",
      "  Batch [10/13] - Loss: 0.4554\n",
      "  Train Loss: 0.4470\n",
      "  Val Loss: 0.6130\n",
      "  Time: 6.51s\n",
      "\n",
      "[EPOCH 52/110]\n",
      "  Batch [10/13] - Loss: 0.4243\n",
      "  Train Loss: 0.4329\n",
      "  Val Loss: 0.6301\n",
      "  Time: 6.55s\n",
      "\n",
      "[EPOCH 53/110]\n",
      "  Batch [10/13] - Loss: 0.4429\n",
      "  Train Loss: 0.4455\n",
      "  Val Loss: 0.6302\n",
      "  Time: 6.12s\n",
      "\n",
      "[EPOCH 54/110]\n",
      "  Batch [10/13] - Loss: 0.4821\n",
      "  Train Loss: 0.4397\n",
      "  Val Loss: 0.6059\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 55/110]\n",
      "  Batch [10/13] - Loss: 0.4332\n",
      "  Train Loss: 0.4506\n",
      "  Val Loss: 0.6183\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 56/110]\n",
      "  Batch [10/13] - Loss: 0.4626\n",
      "  Train Loss: 0.4381\n",
      "  Val Loss: 0.6231\n",
      "  Time: 6.49s\n",
      "\n",
      "[EPOCH 57/110]\n",
      "  Batch [10/13] - Loss: 0.4471\n",
      "  Train Loss: 0.4427\n",
      "  Val Loss: 0.6276\n",
      "  Time: 6.45s\n",
      "\n",
      "[EPOCH 58/110]\n",
      "  Batch [10/13] - Loss: 0.3833\n",
      "  Train Loss: 0.4460\n",
      "  Val Loss: 0.6175\n",
      "  Time: 6.53s\n",
      "\n",
      "[EPOCH 59/110]\n",
      "  Batch [10/13] - Loss: 0.4184\n",
      "  Train Loss: 0.4490\n",
      "  Val Loss: 0.6267\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 60/110]\n",
      "  Batch [10/13] - Loss: 0.4224\n",
      "  Train Loss: 0.4440\n",
      "  Val Loss: 0.6307\n",
      "  Time: 6.29s\n",
      "\n",
      "[EPOCH 61/110]\n",
      "  Batch [10/13] - Loss: 0.3971\n",
      "  Train Loss: 0.4543\n",
      "  Val Loss: 0.6059\n",
      "  Time: 6.45s\n",
      "\n",
      "[EPOCH 62/110]\n",
      "  Batch [10/13] - Loss: 0.3850\n",
      "  Train Loss: 0.4384\n",
      "  Val Loss: 0.6203\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 63/110]\n",
      "  Batch [10/13] - Loss: 0.4283\n",
      "  Train Loss: 0.4504\n",
      "  Val Loss: 0.6262\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 64/110]\n",
      "  Batch [10/13] - Loss: 0.4414\n",
      "  Train Loss: 0.4411\n",
      "  Val Loss: 0.6254\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 65/110]\n",
      "  Batch [10/13] - Loss: 0.4075\n",
      "  Train Loss: 0.4313\n",
      "  Val Loss: 0.6411\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 66/110]\n",
      "  Batch [10/13] - Loss: 0.3948\n",
      "  Train Loss: 0.4403\n",
      "  Val Loss: 0.6184\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 67/110]\n",
      "  Batch [10/13] - Loss: 0.4756\n",
      "  Train Loss: 0.4479\n",
      "  Val Loss: 0.6160\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 68/110]\n",
      "  Batch [10/13] - Loss: 0.4372\n",
      "  Train Loss: 0.4415\n",
      "  Val Loss: 0.6315\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 69/110]\n",
      "  Batch [10/13] - Loss: 0.4074\n",
      "  Train Loss: 0.4472\n",
      "  Val Loss: 0.6207\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 70/110]\n",
      "  Batch [10/13] - Loss: 0.3826\n",
      "  Train Loss: 0.4373\n",
      "  Val Loss: 0.6188\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 71/110]\n",
      "  Batch [10/13] - Loss: 0.4342\n",
      "  Train Loss: 0.4435\n",
      "  Val Loss: 0.6169\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 72/110]\n",
      "  Batch [10/13] - Loss: 0.4092\n",
      "  Train Loss: 0.4456\n",
      "  Val Loss: 0.6179\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 73/110]\n",
      "  Batch [10/13] - Loss: 0.4108\n",
      "  Train Loss: 0.4456\n",
      "  Val Loss: 0.6032\n",
      "  Time: 6.37s\n",
      "\n",
      "[EPOCH 74/110]\n",
      "  Batch [10/13] - Loss: 0.3633\n",
      "  Train Loss: 0.4375\n",
      "  Val Loss: 0.6108\n",
      "  Time: 10.78s\n",
      "\n",
      "[EPOCH 75/110]\n",
      "  Batch [10/13] - Loss: 0.4295\n",
      "  Train Loss: 0.4438\n",
      "  Val Loss: 0.6126\n",
      "  Time: 11.25s\n",
      "\n",
      "[EPOCH 76/110]\n",
      "  Batch [10/13] - Loss: 0.4108\n",
      "  Train Loss: 0.4444\n",
      "  Val Loss: 0.6277\n",
      "  Time: 11.39s\n",
      "\n",
      "[EPOCH 77/110]\n",
      "  Batch [10/13] - Loss: 0.4487\n",
      "  Train Loss: 0.4449\n",
      "  Val Loss: 0.6378\n",
      "  Time: 11.31s\n",
      "\n",
      "[EPOCH 78/110]\n",
      "  Batch [10/13] - Loss: 0.3665\n",
      "  Train Loss: 0.4402\n",
      "  Val Loss: 0.6133\n",
      "  Time: 11.05s\n",
      "\n",
      "[EARLY STOPPING] No improvement for 35 epochs\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 43\n",
      "  Best Val Loss: 0.6026\n",
      "  Total Time: 14.56 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_051_arch_pos_frac_030_v1/plots\n",
      "\n",
      "[OK] Training completed for arch_pos_frac_030_v1!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_051_arch_pos_frac_030_v1\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 1181 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.68s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.783\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.698\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.735\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.737\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 85.11 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_051_arch_pos_frac_030_v1/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7829\n",
      "  mAP@0.5:0.95: 0.5329\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: arch_combined_score_rpn\n",
      "  Score 0.10 + RPN thresholds combined\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_052_arch_combined_score_rpn\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_052_arch_combined_score_rpn\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 52 images\n",
      "[OK] Loaded 2322 annotations\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training for 110 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/110]\n",
      "  Batch [10/13] - Loss: 1.0088\n",
      "  Train Loss: 1.7493\n",
      "  Val Loss: 1.1354\n",
      "  Time: 11.83s\n",
      "  ✓ Best model saved (val_loss: 1.1354)\n",
      "\n",
      "[EPOCH 2/110]\n",
      "  Batch [10/13] - Loss: 1.0209\n",
      "  Train Loss: 0.9661\n",
      "  Val Loss: 0.8935\n",
      "  Time: 11.67s\n",
      "  ✓ Best model saved (val_loss: 0.8935)\n",
      "\n",
      "[EPOCH 3/110]\n",
      "  Batch [10/13] - Loss: 0.7220\n",
      "  Train Loss: 0.7351\n",
      "  Val Loss: 0.7746\n",
      "  Time: 11.76s\n",
      "  ✓ Best model saved (val_loss: 0.7746)\n",
      "\n",
      "[EPOCH 4/110]\n",
      "  Batch [10/13] - Loss: 0.7110\n",
      "  Train Loss: 0.6718\n",
      "  Val Loss: 0.7057\n",
      "  Time: 11.92s\n",
      "  ✓ Best model saved (val_loss: 0.7057)\n",
      "\n",
      "[EPOCH 5/110]\n",
      "  Batch [10/13] - Loss: 0.5936\n",
      "  Train Loss: 0.6146\n",
      "  Val Loss: 0.7146\n",
      "  Time: 11.92s\n",
      "\n",
      "[EPOCH 6/110]\n",
      "  Batch [10/13] - Loss: 0.6793\n",
      "  Train Loss: 0.6015\n",
      "  Val Loss: 0.7157\n",
      "  Time: 11.62s\n",
      "\n",
      "[EPOCH 7/110]\n",
      "  Batch [10/13] - Loss: 0.5134\n",
      "  Train Loss: 0.5703\n",
      "  Val Loss: 0.6707\n",
      "  Time: 6.36s\n",
      "  ✓ Best model saved (val_loss: 0.6707)\n",
      "\n",
      "[EPOCH 8/110]\n",
      "  Batch [10/13] - Loss: 0.5817\n",
      "  Train Loss: 0.5693\n",
      "  Val Loss: 0.6645\n",
      "  Time: 6.57s\n",
      "  ✓ Best model saved (val_loss: 0.6645)\n",
      "\n",
      "[EPOCH 9/110]\n",
      "  Batch [10/13] - Loss: 0.5554\n",
      "  Train Loss: 0.5497\n",
      "  Val Loss: 0.6599\n",
      "  Time: 6.53s\n",
      "  ✓ Best model saved (val_loss: 0.6599)\n",
      "\n",
      "[EPOCH 10/110]\n",
      "  Batch [10/13] - Loss: 0.6135\n",
      "  Train Loss: 0.5544\n",
      "  Val Loss: 0.6758\n",
      "  Time: 6.38s\n",
      "\n",
      "[EPOCH 11/110]\n",
      "  Batch [10/13] - Loss: 0.6295\n",
      "  Train Loss: 0.5683\n",
      "  Val Loss: 0.6458\n",
      "  Time: 6.37s\n",
      "  ✓ Best model saved (val_loss: 0.6458)\n",
      "\n",
      "[EPOCH 12/110]\n",
      "  Batch [10/13] - Loss: 0.5002\n",
      "  Train Loss: 0.5247\n",
      "  Val Loss: 0.6329\n",
      "  Time: 6.35s\n",
      "  ✓ Best model saved (val_loss: 0.6329)\n",
      "\n",
      "[EPOCH 13/110]\n",
      "  Batch [10/13] - Loss: 0.5720\n",
      "  Train Loss: 0.5226\n",
      "  Val Loss: 0.6675\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 14/110]\n",
      "  Batch [10/13] - Loss: 0.5701\n",
      "  Train Loss: 0.5209\n",
      "  Val Loss: 0.6326\n",
      "  Time: 6.37s\n",
      "  ✓ Best model saved (val_loss: 0.6326)\n",
      "\n",
      "[EPOCH 15/110]\n",
      "  Batch [10/13] - Loss: 0.4963\n",
      "  Train Loss: 0.5046\n",
      "  Val Loss: 0.6412\n",
      "  Time: 6.19s\n",
      "\n",
      "[EPOCH 16/110]\n",
      "  Batch [10/13] - Loss: 0.5159\n",
      "  Train Loss: 0.5121\n",
      "  Val Loss: 0.6819\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 17/110]\n",
      "  Batch [10/13] - Loss: 0.4843\n",
      "  Train Loss: 0.5258\n",
      "  Val Loss: 0.6808\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 18/110]\n",
      "  Batch [10/13] - Loss: 0.4977\n",
      "  Train Loss: 0.5008\n",
      "  Val Loss: 0.6056\n",
      "  Time: 6.26s\n",
      "  ✓ Best model saved (val_loss: 0.6056)\n",
      "\n",
      "[EPOCH 19/110]\n",
      "  Batch [10/13] - Loss: 0.5212\n",
      "  Train Loss: 0.4949\n",
      "  Val Loss: 0.6287\n",
      "  Time: 6.53s\n",
      "\n",
      "[EPOCH 20/110]\n",
      "  Batch [10/13] - Loss: 0.5013\n",
      "  Train Loss: 0.4811\n",
      "  Val Loss: 0.6221\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 21/110]\n",
      "  Batch [10/13] - Loss: 0.4539\n",
      "  Train Loss: 0.4830\n",
      "  Val Loss: 0.6066\n",
      "  Time: 6.44s\n",
      "\n",
      "[EPOCH 22/110]\n",
      "  Batch [10/13] - Loss: 0.4806\n",
      "  Train Loss: 0.4591\n",
      "  Val Loss: 0.5984\n",
      "  Time: 6.39s\n",
      "  ✓ Best model saved (val_loss: 0.5984)\n",
      "\n",
      "[EPOCH 23/110]\n",
      "  Batch [10/13] - Loss: 0.4481\n",
      "  Train Loss: 0.4676\n",
      "  Val Loss: 0.5972\n",
      "  Time: 6.44s\n",
      "  ✓ Best model saved (val_loss: 0.5972)\n",
      "\n",
      "[EPOCH 24/110]\n",
      "  Batch [10/13] - Loss: 0.5931\n",
      "  Train Loss: 0.4658\n",
      "  Val Loss: 0.5956\n",
      "  Time: 6.43s\n",
      "  ✓ Best model saved (val_loss: 0.5956)\n",
      "\n",
      "[EPOCH 25/110]\n",
      "  Batch [10/13] - Loss: 0.4424\n",
      "  Train Loss: 0.4568\n",
      "  Val Loss: 0.6131\n",
      "  Time: 6.44s\n",
      "\n",
      "[EPOCH 26/110]\n",
      "  Batch [10/13] - Loss: 0.4767\n",
      "  Train Loss: 0.4565\n",
      "  Val Loss: 0.6059\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 27/110]\n",
      "  Batch [10/13] - Loss: 0.4918\n",
      "  Train Loss: 0.4621\n",
      "  Val Loss: 0.6059\n",
      "  Time: 6.54s\n",
      "\n",
      "[EPOCH 28/110]\n",
      "  Batch [10/13] - Loss: 0.4038\n",
      "  Train Loss: 0.4557\n",
      "  Val Loss: 0.5989\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 29/110]\n",
      "  Batch [10/13] - Loss: 0.4885\n",
      "  Train Loss: 0.4536\n",
      "  Val Loss: 0.6102\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 30/110]\n",
      "  Batch [10/13] - Loss: 0.4361\n",
      "  Train Loss: 0.4613\n",
      "  Val Loss: 0.6191\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 31/110]\n",
      "  Batch [10/13] - Loss: 0.4055\n",
      "  Train Loss: 0.4516\n",
      "  Val Loss: 0.6053\n",
      "  Time: 6.19s\n",
      "\n",
      "[EPOCH 32/110]\n",
      "  Batch [10/13] - Loss: 0.3749\n",
      "  Train Loss: 0.4447\n",
      "  Val Loss: 0.6041\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 33/110]\n",
      "  Batch [10/13] - Loss: 0.4405\n",
      "  Train Loss: 0.4587\n",
      "  Val Loss: 0.6052\n",
      "  Time: 6.45s\n",
      "\n",
      "[EPOCH 34/110]\n",
      "  Batch [10/13] - Loss: 0.4456\n",
      "  Train Loss: 0.4485\n",
      "  Val Loss: 0.6053\n",
      "  Time: 6.48s\n",
      "\n",
      "[EPOCH 35/110]\n",
      "  Batch [10/13] - Loss: 0.4309\n",
      "  Train Loss: 0.4534\n",
      "  Val Loss: 0.6083\n",
      "  Time: 6.57s\n",
      "\n",
      "[EPOCH 36/110]\n",
      "  Batch [10/13] - Loss: 0.4476\n",
      "  Train Loss: 0.4520\n",
      "  Val Loss: 0.5933\n",
      "  Time: 6.14s\n",
      "  ✓ Best model saved (val_loss: 0.5933)\n",
      "\n",
      "[EPOCH 37/110]\n",
      "  Batch [10/13] - Loss: 0.4332\n",
      "  Train Loss: 0.4528\n",
      "  Val Loss: 0.6097\n",
      "  Time: 6.15s\n",
      "\n",
      "[EPOCH 38/110]\n",
      "  Batch [10/13] - Loss: 0.4476\n",
      "  Train Loss: 0.4752\n",
      "  Val Loss: 0.6138\n",
      "  Time: 6.45s\n",
      "\n",
      "[EPOCH 39/110]\n",
      "  Batch [10/13] - Loss: 0.5144\n",
      "  Train Loss: 0.4525\n",
      "  Val Loss: 0.6218\n",
      "  Time: 6.28s\n",
      "\n",
      "[EPOCH 40/110]\n",
      "  Batch [10/13] - Loss: 0.3959\n",
      "  Train Loss: 0.4637\n",
      "  Val Loss: 0.6291\n",
      "  Time: 6.50s\n",
      "\n",
      "[EPOCH 41/110]\n",
      "  Batch [10/13] - Loss: 0.4128\n",
      "  Train Loss: 0.4550\n",
      "  Val Loss: 0.6197\n",
      "  Time: 6.45s\n",
      "\n",
      "[EPOCH 42/110]\n",
      "  Batch [10/13] - Loss: 0.4731\n",
      "  Train Loss: 0.4535\n",
      "  Val Loss: 0.6190\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 43/110]\n",
      "  Batch [10/13] - Loss: 0.3837\n",
      "  Train Loss: 0.4457\n",
      "  Val Loss: 0.5952\n",
      "  Time: 6.48s\n",
      "\n",
      "[EPOCH 44/110]\n",
      "  Batch [10/13] - Loss: 0.4603\n",
      "  Train Loss: 0.4611\n",
      "  Val Loss: 0.6107\n",
      "  Time: 6.49s\n",
      "\n",
      "[EPOCH 45/110]\n",
      "  Batch [10/13] - Loss: 0.4892\n",
      "  Train Loss: 0.4603\n",
      "  Val Loss: 0.5951\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 46/110]\n",
      "  Batch [10/13] - Loss: 0.4837\n",
      "  Train Loss: 0.4511\n",
      "  Val Loss: 0.6097\n",
      "  Time: 6.30s\n",
      "\n",
      "[EPOCH 47/110]\n",
      "  Batch [10/13] - Loss: 0.4554\n",
      "  Train Loss: 0.4553\n",
      "  Val Loss: 0.6083\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 48/110]\n",
      "  Batch [10/13] - Loss: 0.4354\n",
      "  Train Loss: 0.4553\n",
      "  Val Loss: 0.5994\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 49/110]\n",
      "  Batch [10/13] - Loss: 0.4374\n",
      "  Train Loss: 0.4490\n",
      "  Val Loss: 0.6108\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 50/110]\n",
      "  Batch [10/13] - Loss: 0.4372\n",
      "  Train Loss: 0.4552\n",
      "  Val Loss: 0.6125\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 51/110]\n",
      "  Batch [10/13] - Loss: 0.4166\n",
      "  Train Loss: 0.4519\n",
      "  Val Loss: 0.6068\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 52/110]\n",
      "  Batch [10/13] - Loss: 0.4749\n",
      "  Train Loss: 0.4482\n",
      "  Val Loss: 0.6260\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 53/110]\n",
      "  Batch [10/13] - Loss: 0.3938\n",
      "  Train Loss: 0.4558\n",
      "  Val Loss: 0.5965\n",
      "  Time: 6.74s\n",
      "\n",
      "[EPOCH 54/110]\n",
      "  Batch [10/13] - Loss: 0.4299\n",
      "  Train Loss: 0.4614\n",
      "  Val Loss: 0.6123\n",
      "  Time: 6.65s\n",
      "\n",
      "[EPOCH 55/110]\n",
      "  Batch [10/13] - Loss: 0.3706\n",
      "  Train Loss: 0.4443\n",
      "  Val Loss: 0.5965\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 56/110]\n",
      "  Batch [10/13] - Loss: 0.4514\n",
      "  Train Loss: 0.4478\n",
      "  Val Loss: 0.6010\n",
      "  Time: 6.62s\n",
      "\n",
      "[EPOCH 57/110]\n",
      "  Batch [10/13] - Loss: 0.4427\n",
      "  Train Loss: 0.4443\n",
      "  Val Loss: 0.6056\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 58/110]\n",
      "  Batch [10/13] - Loss: 0.4966\n",
      "  Train Loss: 0.4592\n",
      "  Val Loss: 0.6109\n",
      "  Time: 6.38s\n",
      "\n",
      "[EPOCH 59/110]\n",
      "  Batch [10/13] - Loss: 0.4745\n",
      "  Train Loss: 0.4528\n",
      "  Val Loss: 0.6052\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 60/110]\n",
      "  Batch [10/13] - Loss: 0.4446\n",
      "  Train Loss: 0.4484\n",
      "  Val Loss: 0.6151\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 61/110]\n",
      "  Batch [10/13] - Loss: 0.4624\n",
      "  Train Loss: 0.4538\n",
      "  Val Loss: 0.6091\n",
      "  Time: 6.52s\n",
      "\n",
      "[EPOCH 62/110]\n",
      "  Batch [10/13] - Loss: 0.4761\n",
      "  Train Loss: 0.4511\n",
      "  Val Loss: 0.6140\n",
      "  Time: 6.49s\n",
      "\n",
      "[EPOCH 63/110]\n",
      "  Batch [10/13] - Loss: 0.4650\n",
      "  Train Loss: 0.4588\n",
      "  Val Loss: 0.6123\n",
      "  Time: 6.56s\n",
      "\n",
      "[EPOCH 64/110]\n",
      "  Batch [10/13] - Loss: 0.4302\n",
      "  Train Loss: 0.4515\n",
      "  Val Loss: 0.6031\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 65/110]\n",
      "  Batch [10/13] - Loss: 0.4473\n",
      "  Train Loss: 0.4618\n",
      "  Val Loss: 0.6167\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 66/110]\n",
      "  Batch [10/13] - Loss: 0.4508\n",
      "  Train Loss: 0.4458\n",
      "  Val Loss: 0.6145\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 67/110]\n",
      "  Batch [10/13] - Loss: 0.5359\n",
      "  Train Loss: 0.4547\n",
      "  Val Loss: 0.6228\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 68/110]\n",
      "  Batch [10/13] - Loss: 0.4033\n",
      "  Train Loss: 0.4389\n",
      "  Val Loss: 0.6084\n",
      "  Time: 6.55s\n",
      "\n",
      "[EPOCH 69/110]\n",
      "  Batch [10/13] - Loss: 0.4815\n",
      "  Train Loss: 0.4554\n",
      "  Val Loss: 0.5972\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 70/110]\n",
      "  Batch [10/13] - Loss: 0.3944\n",
      "  Train Loss: 0.4490\n",
      "  Val Loss: 0.5997\n",
      "  Time: 6.17s\n",
      "\n",
      "[EPOCH 71/110]\n",
      "  Batch [10/13] - Loss: 0.4386\n",
      "  Train Loss: 0.4469\n",
      "  Val Loss: 0.6198\n",
      "  Time: 6.42s\n",
      "\n",
      "[EARLY STOPPING] No improvement for 35 epochs\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 36\n",
      "  Best Val Loss: 0.5933\n",
      "  Total Time: 14.22 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_052_arch_combined_score_rpn/plots\n",
      "\n",
      "[OK] Training completed for arch_combined_score_rpn!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_052_arch_combined_score_rpn\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 1150 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.64s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.784\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.707\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.737\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.738\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 40.54 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_052_arch_combined_score_rpn/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7837\n",
      "  mAP@0.5:0.95: 0.5378\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: arch_combined_full\n",
      "  All architecture optimizations combined\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_053_arch_combined_full\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_053_arch_combined_full\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 52 images\n",
      "[OK] Loaded 2322 annotations\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training for 120 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/120]\n",
      "  Batch [10/13] - Loss: 1.0758\n",
      "  Train Loss: 1.7126\n",
      "  Val Loss: 1.0834\n",
      "  Time: 6.36s\n",
      "  ✓ Best model saved (val_loss: 1.0834)\n",
      "\n",
      "[EPOCH 2/120]\n",
      "  Batch [10/13] - Loss: 0.9262\n",
      "  Train Loss: 0.8552\n",
      "  Val Loss: 0.8225\n",
      "  Time: 6.44s\n",
      "  ✓ Best model saved (val_loss: 0.8225)\n",
      "\n",
      "[EPOCH 3/120]\n",
      "  Batch [10/13] - Loss: 0.7131\n",
      "  Train Loss: 0.7160\n",
      "  Val Loss: 0.8299\n",
      "  Time: 6.17s\n",
      "\n",
      "[EPOCH 4/120]\n",
      "  Batch [10/13] - Loss: 0.7162\n",
      "  Train Loss: 0.6871\n",
      "  Val Loss: 0.7279\n",
      "  Time: 6.21s\n",
      "  ✓ Best model saved (val_loss: 0.7279)\n",
      "\n",
      "[EPOCH 5/120]\n",
      "  Batch [10/13] - Loss: 0.5807\n",
      "  Train Loss: 0.6272\n",
      "  Val Loss: 0.7334\n",
      "  Time: 6.21s\n",
      "\n",
      "[EPOCH 6/120]\n",
      "  Batch [10/13] - Loss: 0.6740\n",
      "  Train Loss: 0.6177\n",
      "  Val Loss: 0.7057\n",
      "  Time: 6.17s\n",
      "  ✓ Best model saved (val_loss: 0.7057)\n",
      "\n",
      "[EPOCH 7/120]\n",
      "  Batch [10/13] - Loss: 0.5695\n",
      "  Train Loss: 0.5860\n",
      "  Val Loss: 0.6746\n",
      "  Time: 6.40s\n",
      "  ✓ Best model saved (val_loss: 0.6746)\n",
      "\n",
      "[EPOCH 8/120]\n",
      "  Batch [10/13] - Loss: 0.5488\n",
      "  Train Loss: 0.5677\n",
      "  Val Loss: 0.6725\n",
      "  Time: 6.34s\n",
      "  ✓ Best model saved (val_loss: 0.6725)\n",
      "\n",
      "[EPOCH 9/120]\n",
      "  Batch [10/13] - Loss: 0.5336\n",
      "  Train Loss: 0.5615\n",
      "  Val Loss: 0.6887\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 10/120]\n",
      "  Batch [10/13] - Loss: 0.5649\n",
      "  Train Loss: 0.5498\n",
      "  Val Loss: 0.6698\n",
      "  Time: 6.35s\n",
      "  ✓ Best model saved (val_loss: 0.6698)\n",
      "\n",
      "[EPOCH 11/120]\n",
      "  Batch [10/13] - Loss: 0.5051\n",
      "  Train Loss: 0.5330\n",
      "  Val Loss: 0.6782\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 12/120]\n",
      "  Batch [10/13] - Loss: 0.5827\n",
      "  Train Loss: 0.5263\n",
      "  Val Loss: 0.6553\n",
      "  Time: 6.37s\n",
      "  ✓ Best model saved (val_loss: 0.6553)\n",
      "\n",
      "[EPOCH 13/120]\n",
      "  Batch [10/13] - Loss: 0.4801\n",
      "  Train Loss: 0.5304\n",
      "  Val Loss: 0.6476\n",
      "  Time: 6.43s\n",
      "  ✓ Best model saved (val_loss: 0.6476)\n",
      "\n",
      "[EPOCH 14/120]\n",
      "  Batch [10/13] - Loss: 0.5509\n",
      "  Train Loss: 0.5249\n",
      "  Val Loss: 0.6417\n",
      "  Time: 6.34s\n",
      "  ✓ Best model saved (val_loss: 0.6417)\n",
      "\n",
      "[EPOCH 15/120]\n",
      "  Batch [10/13] - Loss: 0.5124\n",
      "  Train Loss: 0.5096\n",
      "  Val Loss: 0.6352\n",
      "  Time: 6.14s\n",
      "  ✓ Best model saved (val_loss: 0.6352)\n",
      "\n",
      "[EPOCH 16/120]\n",
      "  Batch [10/13] - Loss: 0.5211\n",
      "  Train Loss: 0.5253\n",
      "  Val Loss: 0.6684\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 17/120]\n",
      "  Batch [10/13] - Loss: 0.5061\n",
      "  Train Loss: 0.5009\n",
      "  Val Loss: 0.6348\n",
      "  Time: 6.11s\n",
      "  ✓ Best model saved (val_loss: 0.6348)\n",
      "\n",
      "[EPOCH 18/120]\n",
      "  Batch [10/13] - Loss: 0.5381\n",
      "  Train Loss: 0.5228\n",
      "  Val Loss: 0.6530\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 19/120]\n",
      "  Batch [10/13] - Loss: 0.4638\n",
      "  Train Loss: 0.5136\n",
      "  Val Loss: 0.6544\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 20/120]\n",
      "  Batch [10/13] - Loss: 0.4962\n",
      "  Train Loss: 0.4996\n",
      "  Val Loss: 0.6520\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 21/120]\n",
      "  Batch [10/13] - Loss: 0.4963\n",
      "  Train Loss: 0.4996\n",
      "  Val Loss: 0.6370\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 22/120]\n",
      "  Batch [10/13] - Loss: 0.5627\n",
      "  Train Loss: 0.5233\n",
      "  Val Loss: 0.6525\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 23/120]\n",
      "  Batch [10/13] - Loss: 0.4490\n",
      "  Train Loss: 0.5010\n",
      "  Val Loss: 0.6556\n",
      "  Time: 6.38s\n",
      "\n",
      "[EPOCH 24/120]\n",
      "  Batch [10/13] - Loss: 0.5863\n",
      "  Train Loss: 0.4851\n",
      "  Val Loss: 0.6525\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 25/120]\n",
      "  Batch [10/13] - Loss: 0.4788\n",
      "  Train Loss: 0.4951\n",
      "  Val Loss: 0.6132\n",
      "  Time: 6.33s\n",
      "  ✓ Best model saved (val_loss: 0.6132)\n",
      "\n",
      "[EPOCH 26/120]\n",
      "  Batch [10/13] - Loss: 0.4173\n",
      "  Train Loss: 0.4664\n",
      "  Val Loss: 0.6336\n",
      "  Time: 6.68s\n",
      "\n",
      "[EPOCH 27/120]\n",
      "  Batch [10/13] - Loss: 0.4428\n",
      "  Train Loss: 0.4674\n",
      "  Val Loss: 0.6189\n",
      "  Time: 6.21s\n",
      "\n",
      "[EPOCH 28/120]\n",
      "  Batch [10/13] - Loss: 0.4531\n",
      "  Train Loss: 0.4691\n",
      "  Val Loss: 0.6199\n",
      "  Time: 6.37s\n",
      "\n",
      "[EPOCH 29/120]\n",
      "  Batch [10/13] - Loss: 0.4784\n",
      "  Train Loss: 0.4624\n",
      "  Val Loss: 0.6202\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 30/120]\n",
      "  Batch [10/13] - Loss: 0.4306\n",
      "  Train Loss: 0.4591\n",
      "  Val Loss: 0.6342\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 31/120]\n",
      "  Batch [10/13] - Loss: 0.4254\n",
      "  Train Loss: 0.4548\n",
      "  Val Loss: 0.6303\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 32/120]\n",
      "  Batch [10/13] - Loss: 0.4473\n",
      "  Train Loss: 0.4551\n",
      "  Val Loss: 0.6263\n",
      "  Time: 6.38s\n",
      "\n",
      "[EPOCH 33/120]\n",
      "  Batch [10/13] - Loss: 0.4650\n",
      "  Train Loss: 0.4627\n",
      "  Val Loss: 0.6380\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 34/120]\n",
      "  Batch [10/13] - Loss: 0.4445\n",
      "  Train Loss: 0.4630\n",
      "  Val Loss: 0.6280\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 35/120]\n",
      "  Batch [10/13] - Loss: 0.4630\n",
      "  Train Loss: 0.4466\n",
      "  Val Loss: 0.6271\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 36/120]\n",
      "  Batch [10/13] - Loss: 0.4113\n",
      "  Train Loss: 0.4523\n",
      "  Val Loss: 0.6234\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 37/120]\n",
      "  Batch [10/13] - Loss: 0.4193\n",
      "  Train Loss: 0.4580\n",
      "  Val Loss: 0.6413\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 38/120]\n",
      "  Batch [10/13] - Loss: 0.4042\n",
      "  Train Loss: 0.4583\n",
      "  Val Loss: 0.6215\n",
      "  Time: 6.47s\n",
      "\n",
      "[EPOCH 39/120]\n",
      "  Batch [10/13] - Loss: 0.4280\n",
      "  Train Loss: 0.4602\n",
      "  Val Loss: 0.6307\n",
      "  Time: 6.19s\n",
      "\n",
      "[EPOCH 40/120]\n",
      "  Batch [10/13] - Loss: 0.4850\n",
      "  Train Loss: 0.4618\n",
      "  Val Loss: 0.6277\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 41/120]\n",
      "  Batch [10/13] - Loss: 0.4087\n",
      "  Train Loss: 0.4399\n",
      "  Val Loss: 0.6206\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 42/120]\n",
      "  Batch [10/13] - Loss: 0.4115\n",
      "  Train Loss: 0.4536\n",
      "  Val Loss: 0.6328\n",
      "  Time: 6.17s\n",
      "\n",
      "[EPOCH 43/120]\n",
      "  Batch [10/13] - Loss: 0.4648\n",
      "  Train Loss: 0.4529\n",
      "  Val Loss: 0.6216\n",
      "  Time: 6.38s\n",
      "\n",
      "[EPOCH 44/120]\n",
      "  Batch [10/13] - Loss: 0.5019\n",
      "  Train Loss: 0.4532\n",
      "  Val Loss: 0.6220\n",
      "  Time: 6.18s\n",
      "\n",
      "[EPOCH 45/120]\n",
      "  Batch [10/13] - Loss: 0.4832\n",
      "  Train Loss: 0.4645\n",
      "  Val Loss: 0.6157\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 46/120]\n",
      "  Batch [10/13] - Loss: 0.4351\n",
      "  Train Loss: 0.4594\n",
      "  Val Loss: 0.6347\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 47/120]\n",
      "  Batch [10/13] - Loss: 0.4483\n",
      "  Train Loss: 0.4550\n",
      "  Val Loss: 0.6410\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 48/120]\n",
      "  Batch [10/13] - Loss: 0.4551\n",
      "  Train Loss: 0.4583\n",
      "  Val Loss: 0.6443\n",
      "  Time: 6.19s\n",
      "\n",
      "[EPOCH 49/120]\n",
      "  Batch [10/13] - Loss: 0.4016\n",
      "  Train Loss: 0.4570\n",
      "  Val Loss: 0.6301\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 50/120]\n",
      "  Batch [10/13] - Loss: 0.4725\n",
      "  Train Loss: 0.4582\n",
      "  Val Loss: 0.6418\n",
      "  Time: 6.44s\n",
      "\n",
      "[EPOCH 51/120]\n",
      "  Batch [10/13] - Loss: 0.3944\n",
      "  Train Loss: 0.4582\n",
      "  Val Loss: 0.6174\n",
      "  Time: 6.37s\n",
      "\n",
      "[EPOCH 52/120]\n",
      "  Batch [10/13] - Loss: 0.4273\n",
      "  Train Loss: 0.4498\n",
      "  Val Loss: 0.6080\n",
      "  Time: 6.44s\n",
      "  ✓ Best model saved (val_loss: 0.6080)\n",
      "\n",
      "[EPOCH 53/120]\n",
      "  Batch [10/13] - Loss: 0.4377\n",
      "  Train Loss: 0.4667\n",
      "  Val Loss: 0.6264\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 54/120]\n",
      "  Batch [10/13] - Loss: 0.4860\n",
      "  Train Loss: 0.4622\n",
      "  Val Loss: 0.6268\n",
      "  Time: 6.16s\n",
      "\n",
      "[EPOCH 55/120]\n",
      "  Batch [10/13] - Loss: 0.4283\n",
      "  Train Loss: 0.4609\n",
      "  Val Loss: 0.6363\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 56/120]\n",
      "  Batch [10/13] - Loss: 0.5088\n",
      "  Train Loss: 0.4635\n",
      "  Val Loss: 0.6365\n",
      "  Time: 6.37s\n",
      "\n",
      "[EPOCH 57/120]\n",
      "  Batch [10/13] - Loss: 0.4665\n",
      "  Train Loss: 0.4646\n",
      "  Val Loss: 0.6392\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 58/120]\n",
      "  Batch [10/13] - Loss: 0.4899\n",
      "  Train Loss: 0.4555\n",
      "  Val Loss: 0.6246\n",
      "  Time: 6.20s\n",
      "\n",
      "[EPOCH 59/120]\n",
      "  Batch [10/13] - Loss: 0.4307\n",
      "  Train Loss: 0.4517\n",
      "  Val Loss: 0.6290\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 60/120]\n",
      "  Batch [10/13] - Loss: 0.4807\n",
      "  Train Loss: 0.4568\n",
      "  Val Loss: 0.6443\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 61/120]\n",
      "  Batch [10/13] - Loss: 0.4855\n",
      "  Train Loss: 0.4555\n",
      "  Val Loss: 0.6373\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 62/120]\n",
      "  Batch [10/13] - Loss: 0.4734\n",
      "  Train Loss: 0.4518\n",
      "  Val Loss: 0.6364\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 63/120]\n",
      "  Batch [10/13] - Loss: 0.4864\n",
      "  Train Loss: 0.4580\n",
      "  Val Loss: 0.6368\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 64/120]\n",
      "  Batch [10/13] - Loss: 0.4537\n",
      "  Train Loss: 0.4567\n",
      "  Val Loss: 0.6398\n",
      "  Time: 6.38s\n",
      "\n",
      "[EPOCH 65/120]\n",
      "  Batch [10/13] - Loss: 0.3574\n",
      "  Train Loss: 0.4457\n",
      "  Val Loss: 0.6263\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 66/120]\n",
      "  Batch [10/13] - Loss: 0.4774\n",
      "  Train Loss: 0.4637\n",
      "  Val Loss: 0.6357\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 67/120]\n",
      "  Batch [10/13] - Loss: 0.4271\n",
      "  Train Loss: 0.4533\n",
      "  Val Loss: 0.6258\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 68/120]\n",
      "  Batch [10/13] - Loss: 0.4814\n",
      "  Train Loss: 0.4637\n",
      "  Val Loss: 0.6294\n",
      "  Time: 6.44s\n",
      "\n",
      "[EPOCH 69/120]\n",
      "  Batch [10/13] - Loss: 0.4607\n",
      "  Train Loss: 0.4526\n",
      "  Val Loss: 0.6268\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 70/120]\n",
      "  Batch [10/13] - Loss: 0.4957\n",
      "  Train Loss: 0.4702\n",
      "  Val Loss: 0.6372\n",
      "  Time: 6.20s\n",
      "\n",
      "[EPOCH 71/120]\n",
      "  Batch [10/13] - Loss: 0.4858\n",
      "  Train Loss: 0.4496\n",
      "  Val Loss: 0.6101\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 72/120]\n",
      "  Batch [10/13] - Loss: 0.3908\n",
      "  Train Loss: 0.4525\n",
      "  Val Loss: 0.6299\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 73/120]\n",
      "  Batch [10/13] - Loss: 0.4869\n",
      "  Train Loss: 0.4515\n",
      "  Val Loss: 0.6300\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 74/120]\n",
      "  Batch [10/13] - Loss: 0.4372\n",
      "  Train Loss: 0.4466\n",
      "  Val Loss: 0.6352\n",
      "  Time: 6.75s\n",
      "\n",
      "[EPOCH 75/120]\n",
      "  Batch [10/13] - Loss: 0.4244\n",
      "  Train Loss: 0.4446\n",
      "  Val Loss: 0.6380\n",
      "  Time: 6.59s\n",
      "\n",
      "[EPOCH 76/120]\n",
      "  Batch [10/13] - Loss: 0.4640\n",
      "  Train Loss: 0.4590\n",
      "  Val Loss: 0.6268\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 77/120]\n",
      "  Batch [10/13] - Loss: 0.4582\n",
      "  Train Loss: 0.4523\n",
      "  Val Loss: 0.6235\n",
      "  Time: 6.52s\n",
      "\n",
      "[EPOCH 78/120]\n",
      "  Batch [10/13] - Loss: 0.4337\n",
      "  Train Loss: 0.4474\n",
      "  Val Loss: 0.6455\n",
      "  Time: 6.52s\n",
      "\n",
      "[EPOCH 79/120]\n",
      "  Batch [10/13] - Loss: 0.4532\n",
      "  Train Loss: 0.4419\n",
      "  Val Loss: 0.6214\n",
      "  Time: 6.30s\n",
      "\n",
      "[EPOCH 80/120]\n",
      "  Batch [10/13] - Loss: 0.4065\n",
      "  Train Loss: 0.4577\n",
      "  Val Loss: 0.6308\n",
      "  Time: 6.54s\n",
      "\n",
      "[EPOCH 81/120]\n",
      "  Batch [10/13] - Loss: 0.4210\n",
      "  Train Loss: 0.4479\n",
      "  Val Loss: 0.6163\n",
      "  Time: 6.50s\n",
      "\n",
      "[EPOCH 82/120]\n",
      "  Batch [10/13] - Loss: 0.5068\n",
      "  Train Loss: 0.4550\n",
      "  Val Loss: 0.6400\n",
      "  Time: 6.55s\n",
      "\n",
      "[EPOCH 83/120]\n",
      "  Batch [10/13] - Loss: 0.4540\n",
      "  Train Loss: 0.4634\n",
      "  Val Loss: 0.6313\n",
      "  Time: 6.59s\n",
      "\n",
      "[EPOCH 84/120]\n",
      "  Batch [10/13] - Loss: 0.4404\n",
      "  Train Loss: 0.4549\n",
      "  Val Loss: 0.6250\n",
      "  Time: 6.75s\n",
      "\n",
      "[EPOCH 85/120]\n",
      "  Batch [10/13] - Loss: 0.4522\n",
      "  Train Loss: 0.4557\n",
      "  Val Loss: 0.6293\n",
      "  Time: 6.76s\n",
      "\n",
      "[EPOCH 86/120]\n",
      "  Batch [10/13] - Loss: 0.3749\n",
      "  Train Loss: 0.4579\n",
      "  Val Loss: 0.6354\n",
      "  Time: 6.59s\n",
      "\n",
      "[EPOCH 87/120]\n",
      "  Batch [10/13] - Loss: 0.4666\n",
      "  Train Loss: 0.4538\n",
      "  Val Loss: 0.6342\n",
      "  Time: 6.48s\n",
      "\n",
      "[EPOCH 88/120]\n",
      "  Batch [10/13] - Loss: 0.4411\n",
      "  Train Loss: 0.4538\n",
      "  Val Loss: 0.6405\n",
      "  Time: 6.53s\n",
      "\n",
      "[EPOCH 89/120]\n",
      "  Batch [10/13] - Loss: 0.4602\n",
      "  Train Loss: 0.4546\n",
      "  Val Loss: 0.6230\n",
      "  Time: 6.53s\n",
      "\n",
      "[EPOCH 90/120]\n",
      "  Batch [10/13] - Loss: 0.4344\n",
      "  Train Loss: 0.4577\n",
      "  Val Loss: 0.6226\n",
      "  Time: 6.52s\n",
      "\n",
      "[EPOCH 91/120]\n",
      "  Batch [10/13] - Loss: 0.4481\n",
      "  Train Loss: 0.4492\n",
      "  Val Loss: 0.6232\n",
      "  Time: 6.65s\n",
      "\n",
      "[EPOCH 92/120]\n",
      "  Batch [10/13] - Loss: 0.3940\n",
      "  Train Loss: 0.4575\n",
      "  Val Loss: 0.6364\n",
      "  Time: 6.65s\n",
      "\n",
      "[EARLY STOPPING] No improvement for 40 epochs\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 52\n",
      "  Best Val Loss: 0.6080\n",
      "  Total Time: 16.32 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_053_arch_combined_full/plots\n",
      "\n",
      "[OK] Training completed for arch_combined_full!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_053_arch_combined_full\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 986 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.76s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.766\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.686\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.706\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.708\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 41.16 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_053_arch_combined_full/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7664\n",
      "  mAP@0.5:0.95: 0.5261\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: arch_score_012_v1\n",
      "  Best config + score threshold 0.12 (middle ground)\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_054_arch_score_012_v1\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_054_arch_score_012_v1\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 52 images\n",
      "[OK] Loaded 2322 annotations\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training for 110 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/110]\n",
      "  Batch [10/13] - Loss: 1.3167\n",
      "  Train Loss: 1.7664\n",
      "  Val Loss: 1.1105\n",
      "  Time: 6.54s\n",
      "  ✓ Best model saved (val_loss: 1.1105)\n",
      "\n",
      "[EPOCH 2/110]\n",
      "  Batch [10/13] - Loss: 0.8634\n",
      "  Train Loss: 0.9376\n",
      "  Val Loss: 0.8803\n",
      "  Time: 6.37s\n",
      "  ✓ Best model saved (val_loss: 0.8803)\n",
      "\n",
      "[EPOCH 3/110]\n",
      "  Batch [10/13] - Loss: 0.8181\n",
      "  Train Loss: 0.7478\n",
      "  Val Loss: 0.8868\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 4/110]\n",
      "  Batch [10/13] - Loss: 0.7091\n",
      "  Train Loss: 0.7121\n",
      "  Val Loss: 0.7550\n",
      "  Time: 6.64s\n",
      "  ✓ Best model saved (val_loss: 0.7550)\n",
      "\n",
      "[EPOCH 5/110]\n",
      "  Batch [10/13] - Loss: 0.6720\n",
      "  Train Loss: 0.6226\n",
      "  Val Loss: 0.7213\n",
      "  Time: 6.59s\n",
      "  ✓ Best model saved (val_loss: 0.7213)\n",
      "\n",
      "[EPOCH 6/110]\n",
      "  Batch [10/13] - Loss: 0.6077\n",
      "  Train Loss: 0.5905\n",
      "  Val Loss: 0.6514\n",
      "  Time: 6.82s\n",
      "  ✓ Best model saved (val_loss: 0.6514)\n",
      "\n",
      "[EPOCH 7/110]\n",
      "  Batch [10/13] - Loss: 0.5154\n",
      "  Train Loss: 0.5442\n",
      "  Val Loss: 0.6521\n",
      "  Time: 6.67s\n",
      "\n",
      "[EPOCH 8/110]\n",
      "  Batch [10/13] - Loss: 0.6606\n",
      "  Train Loss: 0.5679\n",
      "  Val Loss: 0.7060\n",
      "  Time: 6.63s\n",
      "\n",
      "[EPOCH 9/110]\n",
      "  Batch [10/13] - Loss: 0.5994\n",
      "  Train Loss: 0.5585\n",
      "  Val Loss: 0.6671\n",
      "  Time: 6.59s\n",
      "\n",
      "[EPOCH 10/110]\n",
      "  Batch [10/13] - Loss: 0.5524\n",
      "  Train Loss: 0.5566\n",
      "  Val Loss: 0.6430\n",
      "  Time: 6.31s\n",
      "  ✓ Best model saved (val_loss: 0.6430)\n",
      "\n",
      "[EPOCH 11/110]\n",
      "  Batch [10/13] - Loss: 0.4920\n",
      "  Train Loss: 0.5291\n",
      "  Val Loss: 0.6800\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 12/110]\n",
      "  Batch [10/13] - Loss: 0.5386\n",
      "  Train Loss: 0.5161\n",
      "  Val Loss: 0.6374\n",
      "  Time: 6.42s\n",
      "  ✓ Best model saved (val_loss: 0.6374)\n",
      "\n",
      "[EPOCH 13/110]\n",
      "  Batch [10/13] - Loss: 0.5683\n",
      "  Train Loss: 0.5135\n",
      "  Val Loss: 0.6256\n",
      "  Time: 6.38s\n",
      "  ✓ Best model saved (val_loss: 0.6256)\n",
      "\n",
      "[EPOCH 14/110]\n",
      "  Batch [10/13] - Loss: 0.5460\n",
      "  Train Loss: 0.5168\n",
      "  Val Loss: 0.6346\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 15/110]\n",
      "  Batch [10/13] - Loss: 0.5293\n",
      "  Train Loss: 0.5199\n",
      "  Val Loss: 0.6164\n",
      "  Time: 6.36s\n",
      "  ✓ Best model saved (val_loss: 0.6164)\n",
      "\n",
      "[EPOCH 16/110]\n",
      "  Batch [10/13] - Loss: 0.4518\n",
      "  Train Loss: 0.5042\n",
      "  Val Loss: 0.6063\n",
      "  Time: 6.73s\n",
      "  ✓ Best model saved (val_loss: 0.6063)\n",
      "\n",
      "[EPOCH 17/110]\n",
      "  Batch [10/13] - Loss: 0.5084\n",
      "  Train Loss: 0.4962\n",
      "  Val Loss: 0.6235\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 18/110]\n",
      "  Batch [10/13] - Loss: 0.4543\n",
      "  Train Loss: 0.4886\n",
      "  Val Loss: 0.6128\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 19/110]\n",
      "  Batch [10/13] - Loss: 0.4843\n",
      "  Train Loss: 0.4943\n",
      "  Val Loss: 0.6252\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 20/110]\n",
      "  Batch [10/13] - Loss: 0.5137\n",
      "  Train Loss: 0.4905\n",
      "  Val Loss: 0.6207\n",
      "  Time: 6.34s\n",
      "\n",
      "[EPOCH 21/110]\n",
      "  Batch [10/13] - Loss: 0.4814\n",
      "  Train Loss: 0.4731\n",
      "  Val Loss: 0.6131\n",
      "  Time: 6.38s\n",
      "\n",
      "[EPOCH 22/110]\n",
      "  Batch [10/13] - Loss: 0.4244\n",
      "  Train Loss: 0.4654\n",
      "  Val Loss: 0.6188\n",
      "  Time: 6.15s\n",
      "\n",
      "[EPOCH 23/110]\n",
      "  Batch [10/13] - Loss: 0.4551\n",
      "  Train Loss: 0.4504\n",
      "  Val Loss: 0.6226\n",
      "  Time: 6.15s\n",
      "\n",
      "[EPOCH 24/110]\n",
      "  Batch [10/13] - Loss: 0.4666\n",
      "  Train Loss: 0.4546\n",
      "  Val Loss: 0.6136\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 25/110]\n",
      "  Batch [10/13] - Loss: 0.4391\n",
      "  Train Loss: 0.4538\n",
      "  Val Loss: 0.6001\n",
      "  Time: 6.39s\n",
      "  ✓ Best model saved (val_loss: 0.6001)\n",
      "\n",
      "[EPOCH 26/110]\n",
      "  Batch [10/13] - Loss: 0.5104\n",
      "  Train Loss: 0.4467\n",
      "  Val Loss: 0.6010\n",
      "  Time: 6.15s\n",
      "\n",
      "[EPOCH 27/110]\n",
      "  Batch [10/13] - Loss: 0.4708\n",
      "  Train Loss: 0.4529\n",
      "  Val Loss: 0.6230\n",
      "  Time: 6.37s\n",
      "\n",
      "[EPOCH 28/110]\n",
      "  Batch [10/13] - Loss: 0.4367\n",
      "  Train Loss: 0.4499\n",
      "  Val Loss: 0.6090\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 29/110]\n",
      "  Batch [10/13] - Loss: 0.5142\n",
      "  Train Loss: 0.4486\n",
      "  Val Loss: 0.6141\n",
      "  Time: 6.38s\n",
      "\n",
      "[EPOCH 30/110]\n",
      "  Batch [10/13] - Loss: 0.4255\n",
      "  Train Loss: 0.4419\n",
      "  Val Loss: 0.6179\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 31/110]\n",
      "  Batch [10/13] - Loss: 0.5762\n",
      "  Train Loss: 0.4511\n",
      "  Val Loss: 0.6182\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 32/110]\n",
      "  Batch [10/13] - Loss: 0.4411\n",
      "  Train Loss: 0.4501\n",
      "  Val Loss: 0.6071\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 33/110]\n",
      "  Batch [10/13] - Loss: 0.4612\n",
      "  Train Loss: 0.4450\n",
      "  Val Loss: 0.6218\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 34/110]\n",
      "  Batch [10/13] - Loss: 0.5365\n",
      "  Train Loss: 0.4424\n",
      "  Val Loss: 0.6097\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 35/110]\n",
      "  Batch [10/13] - Loss: 0.4788\n",
      "  Train Loss: 0.4527\n",
      "  Val Loss: 0.6202\n",
      "  Time: 6.40s\n",
      "\n",
      "[EPOCH 36/110]\n",
      "  Batch [10/13] - Loss: 0.3938\n",
      "  Train Loss: 0.4444\n",
      "  Val Loss: 0.6098\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 37/110]\n",
      "  Batch [10/13] - Loss: 0.5404\n",
      "  Train Loss: 0.4540\n",
      "  Val Loss: 0.6131\n",
      "  Time: 6.36s\n",
      "\n",
      "[EPOCH 38/110]\n",
      "  Batch [10/13] - Loss: 0.4820\n",
      "  Train Loss: 0.4485\n",
      "  Val Loss: 0.6299\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 39/110]\n",
      "  Batch [10/13] - Loss: 0.5041\n",
      "  Train Loss: 0.4528\n",
      "  Val Loss: 0.6200\n",
      "  Time: 6.14s\n",
      "\n",
      "[EPOCH 40/110]\n",
      "  Batch [10/13] - Loss: 0.4163\n",
      "  Train Loss: 0.4553\n",
      "  Val Loss: 0.6095\n",
      "  Time: 6.48s\n",
      "\n",
      "[EPOCH 41/110]\n",
      "  Batch [10/13] - Loss: 0.5150\n",
      "  Train Loss: 0.4413\n",
      "  Val Loss: 0.6356\n",
      "  Time: 8.05s\n",
      "\n",
      "[EPOCH 42/110]\n",
      "  Batch [10/13] - Loss: 0.4987\n",
      "  Train Loss: 0.4374\n",
      "  Val Loss: 0.6161\n",
      "  Time: 11.19s\n",
      "\n",
      "[EPOCH 43/110]\n",
      "  Batch [10/13] - Loss: 0.4524\n",
      "  Train Loss: 0.4432\n",
      "  Val Loss: 0.6263\n",
      "  Time: 10.97s\n",
      "\n",
      "[EPOCH 44/110]\n",
      "  Batch [10/13] - Loss: 0.5487\n",
      "  Train Loss: 0.4549\n",
      "  Val Loss: 0.6192\n",
      "  Time: 10.64s\n",
      "\n",
      "[EPOCH 45/110]\n",
      "  Batch [10/13] - Loss: 0.4920\n",
      "  Train Loss: 0.4408\n",
      "  Val Loss: 0.6199\n",
      "  Time: 11.53s\n",
      "\n",
      "[EPOCH 46/110]\n",
      "  Batch [10/13] - Loss: 0.4410\n",
      "  Train Loss: 0.4462\n",
      "  Val Loss: 0.6153\n",
      "  Time: 11.21s\n",
      "\n",
      "[EPOCH 47/110]\n",
      "  Batch [10/13] - Loss: 0.4499\n",
      "  Train Loss: 0.4431\n",
      "  Val Loss: 0.6220\n",
      "  Time: 11.37s\n",
      "\n",
      "[EPOCH 48/110]\n",
      "  Batch [10/13] - Loss: 0.4118\n",
      "  Train Loss: 0.4442\n",
      "  Val Loss: 0.6121\n",
      "  Time: 11.14s\n",
      "\n",
      "[EPOCH 49/110]\n",
      "  Batch [10/13] - Loss: 0.5789\n",
      "  Train Loss: 0.4459\n",
      "  Val Loss: 0.6258\n",
      "  Time: 10.73s\n",
      "\n",
      "[EPOCH 50/110]\n",
      "  Batch [10/13] - Loss: 0.5493\n",
      "  Train Loss: 0.4499\n",
      "  Val Loss: 0.6175\n",
      "  Time: 11.56s\n",
      "\n",
      "[EPOCH 51/110]\n",
      "  Batch [10/13] - Loss: 0.4952\n",
      "  Train Loss: 0.4410\n",
      "  Val Loss: 0.6289\n",
      "  Time: 11.60s\n",
      "\n",
      "[EPOCH 52/110]\n",
      "  Batch [10/13] - Loss: 0.4714\n",
      "  Train Loss: 0.4396\n",
      "  Val Loss: 0.6150\n",
      "  Time: 10.90s\n",
      "\n",
      "[EPOCH 53/110]\n",
      "  Batch [10/13] - Loss: 0.4580\n",
      "  Train Loss: 0.4408\n",
      "  Val Loss: 0.6185\n",
      "  Time: 11.31s\n",
      "\n",
      "[EPOCH 54/110]\n",
      "  Batch [10/13] - Loss: 0.5609\n",
      "  Train Loss: 0.4555\n",
      "  Val Loss: 0.6277\n",
      "  Time: 11.58s\n",
      "\n",
      "[EPOCH 55/110]\n",
      "  Batch [10/13] - Loss: 0.5049\n",
      "  Train Loss: 0.4479\n",
      "  Val Loss: 0.6274\n",
      "  Time: 11.29s\n",
      "\n",
      "[EPOCH 56/110]\n",
      "  Batch [10/13] - Loss: 0.4626\n",
      "  Train Loss: 0.4424\n",
      "  Val Loss: 0.6303\n",
      "  Time: 10.87s\n",
      "\n",
      "[EPOCH 57/110]\n",
      "  Batch [10/13] - Loss: 0.4324\n",
      "  Train Loss: 0.4438\n",
      "  Val Loss: 0.6294\n",
      "  Time: 11.45s\n",
      "\n",
      "[EPOCH 58/110]\n",
      "  Batch [10/13] - Loss: 0.4982\n",
      "  Train Loss: 0.4391\n",
      "  Val Loss: 0.6195\n",
      "  Time: 11.24s\n",
      "\n",
      "[EPOCH 59/110]\n",
      "  Batch [10/13] - Loss: 0.4847\n",
      "  Train Loss: 0.4386\n",
      "  Val Loss: 0.6233\n",
      "  Time: 11.34s\n",
      "\n",
      "[EPOCH 60/110]\n",
      "  Batch [10/13] - Loss: 0.4606\n",
      "  Train Loss: 0.4475\n",
      "  Val Loss: 0.6173\n",
      "  Time: 11.11s\n",
      "\n",
      "[EARLY STOPPING] No improvement for 35 epochs\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 25\n",
      "  Best Val Loss: 0.6001\n",
      "  Total Time: 12.63 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_054_arch_score_012_v1/plots\n",
      "\n",
      "[OK] Training completed for arch_score_012_v1!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_054_arch_score_012_v1\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 1137 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.64s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.784\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.684\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 63.70 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_054_arch_score_012_v1/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7841\n",
      "  mAP@0.5:0.95: 0.5287\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: arch_score_posfrac\n",
      "  Score 0.10 + Positive fraction 0.30\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_055_arch_score_posfrac\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_055_arch_score_posfrac\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 52 images\n",
      "[OK] Loaded 2322 annotations\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training for 110 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/110]\n",
      "  Batch [10/13] - Loss: 1.1578\n",
      "  Train Loss: 1.6925\n",
      "  Val Loss: 1.1264\n",
      "  Time: 11.16s\n",
      "  ✓ Best model saved (val_loss: 1.1264)\n",
      "\n",
      "[EPOCH 2/110]\n",
      "  Batch [10/13] - Loss: 0.8162\n",
      "  Train Loss: 0.8847\n",
      "  Val Loss: 0.8608\n",
      "  Time: 11.36s\n",
      "  ✓ Best model saved (val_loss: 0.8608)\n",
      "\n",
      "[EPOCH 3/110]\n",
      "  Batch [10/13] - Loss: 0.7520\n",
      "  Train Loss: 0.7370\n",
      "  Val Loss: 0.8143\n",
      "  Time: 8.76s\n",
      "  ✓ Best model saved (val_loss: 0.8143)\n",
      "\n",
      "[EPOCH 4/110]\n",
      "  Batch [10/13] - Loss: 0.6162\n",
      "  Train Loss: 0.6690\n",
      "  Val Loss: 0.7346\n",
      "  Time: 6.54s\n",
      "  ✓ Best model saved (val_loss: 0.7346)\n",
      "\n",
      "[EPOCH 5/110]\n",
      "  Batch [10/13] - Loss: 0.5675\n",
      "  Train Loss: 0.6312\n",
      "  Val Loss: 0.7061\n",
      "  Time: 6.21s\n",
      "  ✓ Best model saved (val_loss: 0.7061)\n",
      "\n",
      "[EPOCH 6/110]\n",
      "  Batch [10/13] - Loss: 0.6330\n",
      "  Train Loss: 0.6197\n",
      "  Val Loss: 0.6770\n",
      "  Time: 6.25s\n",
      "  ✓ Best model saved (val_loss: 0.6770)\n",
      "\n",
      "[EPOCH 7/110]\n",
      "  Batch [10/13] - Loss: 0.5339\n",
      "  Train Loss: 0.5741\n",
      "  Val Loss: 0.7293\n",
      "  Time: 6.60s\n",
      "\n",
      "[EPOCH 8/110]\n",
      "  Batch [10/13] - Loss: 0.5518\n",
      "  Train Loss: 0.5804\n",
      "  Val Loss: 0.6489\n",
      "  Time: 6.86s\n",
      "  ✓ Best model saved (val_loss: 0.6489)\n",
      "\n",
      "[EPOCH 9/110]\n",
      "  Batch [10/13] - Loss: 0.5440\n",
      "  Train Loss: 0.5632\n",
      "  Val Loss: 0.6596\n",
      "  Time: 6.50s\n",
      "\n",
      "[EPOCH 10/110]\n",
      "  Batch [10/13] - Loss: 0.5044\n",
      "  Train Loss: 0.5334\n",
      "  Val Loss: 0.6705\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 11/110]\n",
      "  Batch [10/13] - Loss: 0.6088\n",
      "  Train Loss: 0.5334\n",
      "  Val Loss: 0.6672\n",
      "  Time: 6.47s\n",
      "\n",
      "[EPOCH 12/110]\n",
      "  Batch [10/13] - Loss: 0.5162\n",
      "  Train Loss: 0.5166\n",
      "  Val Loss: 0.6660\n",
      "  Time: 6.51s\n",
      "\n",
      "[EPOCH 13/110]\n",
      "  Batch [10/13] - Loss: 0.5236\n",
      "  Train Loss: 0.5066\n",
      "  Val Loss: 0.6352\n",
      "  Time: 6.24s\n",
      "  ✓ Best model saved (val_loss: 0.6352)\n",
      "\n",
      "[EPOCH 14/110]\n",
      "  Batch [10/13] - Loss: 0.5188\n",
      "  Train Loss: 0.5110\n",
      "  Val Loss: 0.6464\n",
      "  Time: 6.48s\n",
      "\n",
      "[EPOCH 15/110]\n",
      "  Batch [10/13] - Loss: 0.5144\n",
      "  Train Loss: 0.5066\n",
      "  Val Loss: 0.6491\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 16/110]\n",
      "  Batch [10/13] - Loss: 0.5361\n",
      "  Train Loss: 0.5022\n",
      "  Val Loss: 0.6665\n",
      "  Time: 6.42s\n",
      "\n",
      "[EPOCH 17/110]\n",
      "  Batch [10/13] - Loss: 0.4883\n",
      "  Train Loss: 0.5095\n",
      "  Val Loss: 0.6629\n",
      "  Time: 6.44s\n",
      "\n",
      "[EPOCH 18/110]\n",
      "  Batch [10/13] - Loss: 0.4749\n",
      "  Train Loss: 0.5158\n",
      "  Val Loss: 0.6463\n",
      "  Time: 6.47s\n",
      "\n",
      "[EPOCH 19/110]\n",
      "  Batch [10/13] - Loss: 0.4956\n",
      "  Train Loss: 0.4894\n",
      "  Val Loss: 0.6216\n",
      "  Time: 6.46s\n",
      "  ✓ Best model saved (val_loss: 0.6216)\n",
      "\n",
      "[EPOCH 20/110]\n",
      "  Batch [10/13] - Loss: 0.5080\n",
      "  Train Loss: 0.4684\n",
      "  Val Loss: 0.6525\n",
      "  Time: 6.57s\n",
      "\n",
      "[EPOCH 21/110]\n",
      "  Batch [10/13] - Loss: 0.4670\n",
      "  Train Loss: 0.4722\n",
      "  Val Loss: 0.6315\n",
      "  Time: 6.60s\n",
      "\n",
      "[EPOCH 22/110]\n",
      "  Batch [10/13] - Loss: 0.4418\n",
      "  Train Loss: 0.4589\n",
      "  Val Loss: 0.6122\n",
      "  Time: 6.22s\n",
      "  ✓ Best model saved (val_loss: 0.6122)\n",
      "\n",
      "[EPOCH 23/110]\n",
      "  Batch [10/13] - Loss: 0.4442\n",
      "  Train Loss: 0.4603\n",
      "  Val Loss: 0.6259\n",
      "  Time: 6.51s\n",
      "\n",
      "[EPOCH 24/110]\n",
      "  Batch [10/13] - Loss: 0.4419\n",
      "  Train Loss: 0.4479\n",
      "  Val Loss: 0.6259\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 25/110]\n",
      "  Batch [10/13] - Loss: 0.4417\n",
      "  Train Loss: 0.4466\n",
      "  Val Loss: 0.6205\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 26/110]\n",
      "  Batch [10/13] - Loss: 0.4401\n",
      "  Train Loss: 0.4559\n",
      "  Val Loss: 0.6310\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 27/110]\n",
      "  Batch [10/13] - Loss: 0.4066\n",
      "  Train Loss: 0.4484\n",
      "  Val Loss: 0.6329\n",
      "  Time: 6.55s\n",
      "\n",
      "[EPOCH 28/110]\n",
      "  Batch [10/13] - Loss: 0.4583\n",
      "  Train Loss: 0.4554\n",
      "  Val Loss: 0.6298\n",
      "  Time: 6.62s\n",
      "\n",
      "[EPOCH 29/110]\n",
      "  Batch [10/13] - Loss: 0.4540\n",
      "  Train Loss: 0.4533\n",
      "  Val Loss: 0.6270\n",
      "  Time: 6.49s\n",
      "\n",
      "[EPOCH 30/110]\n",
      "  Batch [10/13] - Loss: 0.4288\n",
      "  Train Loss: 0.4535\n",
      "  Val Loss: 0.6360\n",
      "  Time: 6.56s\n",
      "\n",
      "[EPOCH 31/110]\n",
      "  Batch [10/13] - Loss: 0.4404\n",
      "  Train Loss: 0.4588\n",
      "  Val Loss: 0.6223\n",
      "  Time: 6.61s\n",
      "\n",
      "[EPOCH 32/110]\n",
      "  Batch [10/13] - Loss: 0.4300\n",
      "  Train Loss: 0.4472\n",
      "  Val Loss: 0.6332\n",
      "  Time: 6.58s\n",
      "\n",
      "[EPOCH 33/110]\n",
      "  Batch [10/13] - Loss: 0.4231\n",
      "  Train Loss: 0.4535\n",
      "  Val Loss: 0.6327\n",
      "  Time: 6.47s\n",
      "\n",
      "[EPOCH 34/110]\n",
      "  Batch [10/13] - Loss: 0.4188\n",
      "  Train Loss: 0.4535\n",
      "  Val Loss: 0.6415\n",
      "  Time: 6.66s\n",
      "\n",
      "[EPOCH 35/110]\n",
      "  Batch [10/13] - Loss: 0.4480\n",
      "  Train Loss: 0.4532\n",
      "  Val Loss: 0.6451\n",
      "  Time: 6.72s\n",
      "\n",
      "[EPOCH 36/110]\n",
      "  Batch [10/13] - Loss: 0.4021\n",
      "  Train Loss: 0.4528\n",
      "  Val Loss: 0.6605\n",
      "  Time: 6.49s\n",
      "\n",
      "[EPOCH 37/110]\n",
      "  Batch [10/13] - Loss: 0.4483\n",
      "  Train Loss: 0.4528\n",
      "  Val Loss: 0.6257\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 38/110]\n",
      "  Batch [10/13] - Loss: 0.4716\n",
      "  Train Loss: 0.4583\n",
      "  Val Loss: 0.6331\n",
      "  Time: 6.60s\n",
      "\n",
      "[EPOCH 39/110]\n",
      "  Batch [10/13] - Loss: 0.4663\n",
      "  Train Loss: 0.4423\n",
      "  Val Loss: 0.6308\n",
      "  Time: 6.63s\n",
      "\n",
      "[EPOCH 40/110]\n",
      "  Batch [10/13] - Loss: 0.4332\n",
      "  Train Loss: 0.4497\n",
      "  Val Loss: 0.6478\n",
      "  Time: 6.62s\n",
      "\n",
      "[EPOCH 41/110]\n",
      "  Batch [10/13] - Loss: 0.4360\n",
      "  Train Loss: 0.4451\n",
      "  Val Loss: 0.6347\n",
      "  Time: 6.58s\n",
      "\n",
      "[EPOCH 42/110]\n",
      "  Batch [10/13] - Loss: 0.4344\n",
      "  Train Loss: 0.4503\n",
      "  Val Loss: 0.6256\n",
      "  Time: 6.66s\n",
      "\n",
      "[EPOCH 43/110]\n",
      "  Batch [10/13] - Loss: 0.5436\n",
      "  Train Loss: 0.4472\n",
      "  Val Loss: 0.6309\n",
      "  Time: 6.66s\n",
      "\n",
      "[EPOCH 44/110]\n",
      "  Batch [10/13] - Loss: 0.4626\n",
      "  Train Loss: 0.4387\n",
      "  Val Loss: 0.6438\n",
      "  Time: 6.58s\n",
      "\n",
      "[EPOCH 45/110]\n",
      "  Batch [10/13] - Loss: 0.4500\n",
      "  Train Loss: 0.4484\n",
      "  Val Loss: 0.6563\n",
      "  Time: 6.58s\n",
      "\n",
      "[EPOCH 46/110]\n",
      "  Batch [10/13] - Loss: 0.5602\n",
      "  Train Loss: 0.4583\n",
      "  Val Loss: 0.6259\n",
      "  Time: 6.57s\n",
      "\n",
      "[EPOCH 47/110]\n",
      "  Batch [10/13] - Loss: 0.4327\n",
      "  Train Loss: 0.4535\n",
      "  Val Loss: 0.6323\n",
      "  Time: 6.88s\n",
      "\n",
      "[EPOCH 48/110]\n",
      "  Batch [10/13] - Loss: 0.4061\n",
      "  Train Loss: 0.4444\n",
      "  Val Loss: 0.6282\n",
      "  Time: 6.63s\n",
      "\n",
      "[EPOCH 49/110]\n",
      "  Batch [10/13] - Loss: 0.4706\n",
      "  Train Loss: 0.4486\n",
      "  Val Loss: 0.6341\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 50/110]\n",
      "  Batch [10/13] - Loss: 0.4318\n",
      "  Train Loss: 0.4516\n",
      "  Val Loss: 0.6188\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 51/110]\n",
      "  Batch [10/13] - Loss: 0.4590\n",
      "  Train Loss: 0.4492\n",
      "  Val Loss: 0.6403\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 52/110]\n",
      "  Batch [10/13] - Loss: 0.5092\n",
      "  Train Loss: 0.4482\n",
      "  Val Loss: 0.6338\n",
      "  Time: 10.24s\n",
      "\n",
      "[EPOCH 53/110]\n",
      "  Batch [10/13] - Loss: 0.5236\n",
      "  Train Loss: 0.4438\n",
      "  Val Loss: 0.6298\n",
      "  Time: 11.22s\n",
      "\n",
      "[EPOCH 54/110]\n",
      "  Batch [10/13] - Loss: 0.4366\n",
      "  Train Loss: 0.4488\n",
      "  Val Loss: 0.6323\n",
      "  Time: 11.05s\n",
      "\n",
      "[EPOCH 55/110]\n",
      "  Batch [10/13] - Loss: 0.4353\n",
      "  Train Loss: 0.4524\n",
      "  Val Loss: 0.6300\n",
      "  Time: 11.25s\n",
      "\n",
      "[EPOCH 56/110]\n",
      "  Batch [10/13] - Loss: 0.4363\n",
      "  Train Loss: 0.4570\n",
      "  Val Loss: 0.6454\n",
      "  Time: 11.31s\n",
      "\n",
      "[EPOCH 57/110]\n",
      "  Batch [10/13] - Loss: 0.5102\n",
      "  Train Loss: 0.4472\n",
      "  Val Loss: 0.6410\n",
      "  Time: 11.61s\n",
      "\n",
      "[EARLY STOPPING] No improvement for 35 epochs\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 22\n",
      "  Best Val Loss: 0.6122\n",
      "  Total Time: 11.06 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_055_arch_score_posfrac/plots\n",
      "\n",
      "[OK] Training completed for arch_score_posfrac!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_055_arch_score_posfrac\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 1149 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.67s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.546\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.792\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.721\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.548\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.741\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.742\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 85.67 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Updated best model for 02_faster_rcnn: exp_055_arch_score_posfrac (mAP@0.5:0.95 = 0.5458)\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_055_arch_score_posfrac/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7918\n",
      "  mAP@0.5:0.95: 0.5458\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: arch_score_010_modaug\n",
      "  Score 0.10 with moderate augmentation\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_056_arch_score_010_modaug\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_056_arch_score_010_modaug\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.02, s=0.1, v=0.1\n",
      "  Geometric: degrees=5.0, translate=0.08, scale=0.12\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 52 images\n",
      "[OK] Loaded 2322 annotations\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training for 100 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/100]\n",
      "  Batch [10/13] - Loss: 1.1400\n",
      "  Train Loss: 1.6851\n",
      "  Val Loss: 1.0485\n",
      "  Time: 11.45s\n",
      "  ✓ Best model saved (val_loss: 1.0485)\n",
      "\n",
      "[EPOCH 2/100]\n",
      "  Batch [10/13] - Loss: 0.7994\n",
      "  Train Loss: 0.9077\n",
      "  Val Loss: 0.8852\n",
      "  Time: 11.09s\n",
      "  ✓ Best model saved (val_loss: 0.8852)\n",
      "\n",
      "[EPOCH 3/100]\n",
      "  Batch [10/13] - Loss: 0.7452\n",
      "  Train Loss: 0.7406\n",
      "  Val Loss: 0.8052\n",
      "  Time: 10.99s\n",
      "  ✓ Best model saved (val_loss: 0.8052)\n",
      "\n",
      "[EPOCH 4/100]\n",
      "  Batch [10/13] - Loss: 0.6790\n",
      "  Train Loss: 0.7007\n",
      "  Val Loss: 0.7468\n",
      "  Time: 11.45s\n",
      "  ✓ Best model saved (val_loss: 0.7468)\n",
      "\n",
      "[EPOCH 5/100]\n",
      "  Batch [10/13] - Loss: 0.7148\n",
      "  Train Loss: 0.6513\n",
      "  Val Loss: 0.7187\n",
      "  Time: 11.15s\n",
      "  ✓ Best model saved (val_loss: 0.7187)\n",
      "\n",
      "[EPOCH 6/100]\n",
      "  Batch [10/13] - Loss: 0.6342\n",
      "  Train Loss: 0.6332\n",
      "  Val Loss: 0.7185\n",
      "  Time: 11.39s\n",
      "  ✓ Best model saved (val_loss: 0.7185)\n",
      "\n",
      "[EPOCH 7/100]\n",
      "  Batch [10/13] - Loss: 0.6101\n",
      "  Train Loss: 0.6055\n",
      "  Val Loss: 0.6828\n",
      "  Time: 11.26s\n",
      "  ✓ Best model saved (val_loss: 0.6828)\n",
      "\n",
      "[EPOCH 8/100]\n",
      "  Batch [10/13] - Loss: 0.6062\n",
      "  Train Loss: 0.5782\n",
      "  Val Loss: 0.6709\n",
      "  Time: 11.47s\n",
      "  ✓ Best model saved (val_loss: 0.6709)\n",
      "\n",
      "[EPOCH 9/100]\n",
      "  Batch [10/13] - Loss: 0.7082\n",
      "  Train Loss: 0.5779\n",
      "  Val Loss: 0.6909\n",
      "  Time: 10.57s\n",
      "\n",
      "[EPOCH 10/100]\n",
      "  Batch [10/13] - Loss: 0.5548\n",
      "  Train Loss: 0.5492\n",
      "  Val Loss: 0.6608\n",
      "  Time: 11.17s\n",
      "  ✓ Best model saved (val_loss: 0.6608)\n",
      "\n",
      "[EPOCH 11/100]\n",
      "  Batch [10/13] - Loss: 0.5776\n",
      "  Train Loss: 0.5420\n",
      "  Val Loss: 0.6793\n",
      "  Time: 10.96s\n",
      "\n",
      "[EPOCH 12/100]\n",
      "  Batch [10/13] - Loss: 0.5042\n",
      "  Train Loss: 0.5384\n",
      "  Val Loss: 0.6394\n",
      "  Time: 11.47s\n",
      "  ✓ Best model saved (val_loss: 0.6394)\n",
      "\n",
      "[EPOCH 13/100]\n",
      "  Batch [10/13] - Loss: 0.5458\n",
      "  Train Loss: 0.5533\n",
      "  Val Loss: 0.6753\n",
      "  Time: 11.39s\n",
      "\n",
      "[EPOCH 14/100]\n",
      "  Batch [10/13] - Loss: 0.5514\n",
      "  Train Loss: 0.5261\n",
      "  Val Loss: 0.6510\n",
      "  Time: 11.53s\n",
      "\n",
      "[EPOCH 15/100]\n",
      "  Batch [10/13] - Loss: 0.5023\n",
      "  Train Loss: 0.5030\n",
      "  Val Loss: 0.6341\n",
      "  Time: 11.12s\n",
      "  ✓ Best model saved (val_loss: 0.6341)\n",
      "\n",
      "[EPOCH 16/100]\n",
      "  Batch [10/13] - Loss: 0.4950\n",
      "  Train Loss: 0.5080\n",
      "  Val Loss: 0.6424\n",
      "  Time: 11.28s\n",
      "\n",
      "[EPOCH 17/100]\n",
      "  Batch [10/13] - Loss: 0.5306\n",
      "  Train Loss: 0.5024\n",
      "  Val Loss: 0.6415\n",
      "  Time: 11.21s\n",
      "\n",
      "[EPOCH 18/100]\n",
      "  Batch [10/13] - Loss: 0.6029\n",
      "  Train Loss: 0.5255\n",
      "  Val Loss: 0.6405\n",
      "  Time: 11.04s\n",
      "\n",
      "[EPOCH 19/100]\n",
      "  Batch [10/13] - Loss: 0.5487\n",
      "  Train Loss: 0.5288\n",
      "  Val Loss: 0.6458\n",
      "  Time: 11.41s\n",
      "\n",
      "[EPOCH 20/100]\n",
      "  Batch [10/13] - Loss: 0.5270\n",
      "  Train Loss: 0.5074\n",
      "  Val Loss: 0.6310\n",
      "  Time: 11.42s\n",
      "  ✓ Best model saved (val_loss: 0.6310)\n",
      "\n",
      "[EPOCH 21/100]\n",
      "  Batch [10/13] - Loss: 0.5196\n",
      "  Train Loss: 0.4867\n",
      "  Val Loss: 0.6329\n",
      "  Time: 11.31s\n",
      "\n",
      "[EPOCH 22/100]\n",
      "  Batch [10/13] - Loss: 0.5050\n",
      "  Train Loss: 0.4708\n",
      "  Val Loss: 0.6151\n",
      "  Time: 11.38s\n",
      "  ✓ Best model saved (val_loss: 0.6151)\n",
      "\n",
      "[EPOCH 23/100]\n",
      "  Batch [10/13] - Loss: 0.4326\n",
      "  Train Loss: 0.4665\n",
      "  Val Loss: 0.6238\n",
      "  Time: 11.35s\n",
      "\n",
      "[EPOCH 24/100]\n",
      "  Batch [10/13] - Loss: 0.5195\n",
      "  Train Loss: 0.4657\n",
      "  Val Loss: 0.6254\n",
      "  Time: 10.42s\n",
      "\n",
      "[EPOCH 25/100]\n",
      "  Batch [10/13] - Loss: 0.4861\n",
      "  Train Loss: 0.4669\n",
      "  Val Loss: 0.6166\n",
      "  Time: 10.76s\n",
      "\n",
      "[EPOCH 26/100]\n",
      "  Batch [10/13] - Loss: 0.4468\n",
      "  Train Loss: 0.4557\n",
      "  Val Loss: 0.6111\n",
      "  Time: 10.90s\n",
      "  ✓ Best model saved (val_loss: 0.6111)\n",
      "\n",
      "[EPOCH 27/100]\n",
      "  Batch [10/13] - Loss: 0.4697\n",
      "  Train Loss: 0.4616\n",
      "  Val Loss: 0.6240\n",
      "  Time: 11.26s\n",
      "\n",
      "[EPOCH 28/100]\n",
      "  Batch [10/13] - Loss: 0.5334\n",
      "  Train Loss: 0.4803\n",
      "  Val Loss: 0.6376\n",
      "  Time: 11.61s\n",
      "\n",
      "[EPOCH 29/100]\n",
      "  Batch [10/13] - Loss: 0.5032\n",
      "  Train Loss: 0.4685\n",
      "  Val Loss: 0.6294\n",
      "  Time: 11.43s\n",
      "\n",
      "[EPOCH 30/100]\n",
      "  Batch [10/13] - Loss: 0.4902\n",
      "  Train Loss: 0.4741\n",
      "  Val Loss: 0.6192\n",
      "  Time: 11.31s\n",
      "\n",
      "[EPOCH 31/100]\n",
      "  Batch [10/13] - Loss: 0.4282\n",
      "  Train Loss: 0.4542\n",
      "  Val Loss: 0.6187\n",
      "  Time: 10.93s\n",
      "\n",
      "[EPOCH 32/100]\n",
      "  Batch [10/13] - Loss: 0.4299\n",
      "  Train Loss: 0.4704\n",
      "  Val Loss: 0.6142\n",
      "  Time: 11.54s\n",
      "\n",
      "[EPOCH 33/100]\n",
      "  Batch [10/13] - Loss: 0.5681\n",
      "  Train Loss: 0.4718\n",
      "  Val Loss: 0.6296\n",
      "  Time: 10.77s\n",
      "\n",
      "[EPOCH 34/100]\n",
      "  Batch [10/13] - Loss: 0.5025\n",
      "  Train Loss: 0.4636\n",
      "  Val Loss: 0.6173\n",
      "  Time: 11.00s\n",
      "\n",
      "[EPOCH 35/100]\n",
      "  Batch [10/13] - Loss: 0.4637\n",
      "  Train Loss: 0.4677\n",
      "  Val Loss: 0.6238\n",
      "  Time: 11.66s\n",
      "\n",
      "[EPOCH 36/100]\n",
      "  Batch [10/13] - Loss: 0.4585\n",
      "  Train Loss: 0.4594\n",
      "  Val Loss: 0.6347\n",
      "  Time: 11.56s\n",
      "\n",
      "[EPOCH 37/100]\n",
      "  Batch [10/13] - Loss: 0.4684\n",
      "  Train Loss: 0.4610\n",
      "  Val Loss: 0.6077\n",
      "  Time: 11.64s\n",
      "  ✓ Best model saved (val_loss: 0.6077)\n",
      "\n",
      "[EPOCH 38/100]\n",
      "  Batch [10/13] - Loss: 0.5025\n",
      "  Train Loss: 0.4562\n",
      "  Val Loss: 0.6276\n",
      "  Time: 7.70s\n",
      "\n",
      "[EPOCH 39/100]\n",
      "  Batch [10/13] - Loss: 0.4736\n",
      "  Train Loss: 0.4648\n",
      "  Val Loss: 0.6083\n",
      "  Time: 6.64s\n",
      "\n",
      "[EPOCH 40/100]\n",
      "  Batch [10/13] - Loss: 0.5324\n",
      "  Train Loss: 0.4659\n",
      "  Val Loss: 0.6206\n",
      "  Time: 6.70s\n",
      "\n",
      "[EPOCH 41/100]\n",
      "  Batch [10/13] - Loss: 0.4392\n",
      "  Train Loss: 0.4595\n",
      "  Val Loss: 0.6193\n",
      "  Time: 6.53s\n",
      "\n",
      "[EPOCH 42/100]\n",
      "  Batch [10/13] - Loss: 0.4541\n",
      "  Train Loss: 0.4620\n",
      "  Val Loss: 0.6154\n",
      "  Time: 6.59s\n",
      "\n",
      "[EPOCH 43/100]\n",
      "  Batch [10/13] - Loss: 0.4266\n",
      "  Train Loss: 0.4473\n",
      "  Val Loss: 0.6216\n",
      "  Time: 6.57s\n",
      "\n",
      "[EPOCH 44/100]\n",
      "  Batch [10/13] - Loss: 0.4726\n",
      "  Train Loss: 0.4585\n",
      "  Val Loss: 0.6228\n",
      "  Time: 6.56s\n",
      "\n",
      "[EPOCH 45/100]\n",
      "  Batch [10/13] - Loss: 0.4666\n",
      "  Train Loss: 0.4494\n",
      "  Val Loss: 0.6396\n",
      "  Time: 6.78s\n",
      "\n",
      "[EPOCH 46/100]\n",
      "  Batch [10/13] - Loss: 0.5494\n",
      "  Train Loss: 0.4655\n",
      "  Val Loss: 0.6209\n",
      "  Time: 6.31s\n",
      "\n",
      "[EPOCH 47/100]\n",
      "  Batch [10/13] - Loss: 0.4339\n",
      "  Train Loss: 0.4583\n",
      "  Val Loss: 0.6385\n",
      "  Time: 6.69s\n",
      "\n",
      "[EPOCH 48/100]\n",
      "  Batch [10/13] - Loss: 0.5201\n",
      "  Train Loss: 0.4551\n",
      "  Val Loss: 0.6334\n",
      "  Time: 6.60s\n",
      "\n",
      "[EPOCH 49/100]\n",
      "  Batch [10/13] - Loss: 0.4892\n",
      "  Train Loss: 0.4457\n",
      "  Val Loss: 0.6488\n",
      "  Time: 6.50s\n",
      "\n",
      "[EPOCH 50/100]\n",
      "  Batch [10/13] - Loss: 0.5221\n",
      "  Train Loss: 0.4631\n",
      "  Val Loss: 0.6183\n",
      "  Time: 6.55s\n",
      "\n",
      "[EPOCH 51/100]\n",
      "  Batch [10/13] - Loss: 0.4753\n",
      "  Train Loss: 0.4618\n",
      "  Val Loss: 0.6080\n",
      "  Time: 6.33s\n",
      "\n",
      "[EPOCH 52/100]\n",
      "  Batch [10/13] - Loss: 0.4895\n",
      "  Train Loss: 0.4587\n",
      "  Val Loss: 0.6171\n",
      "  Time: 6.52s\n",
      "\n",
      "[EPOCH 53/100]\n",
      "  Batch [10/13] - Loss: 0.4399\n",
      "  Train Loss: 0.4543\n",
      "  Val Loss: 0.6236\n",
      "  Time: 6.63s\n",
      "\n",
      "[EPOCH 54/100]\n",
      "  Batch [10/13] - Loss: 0.4777\n",
      "  Train Loss: 0.4555\n",
      "  Val Loss: 0.6290\n",
      "  Time: 6.74s\n",
      "\n",
      "[EPOCH 55/100]\n",
      "  Batch [10/13] - Loss: 0.5051\n",
      "  Train Loss: 0.4585\n",
      "  Val Loss: 0.6284\n",
      "  Time: 6.32s\n",
      "\n",
      "[EPOCH 56/100]\n",
      "  Batch [10/13] - Loss: 0.5230\n",
      "  Train Loss: 0.4650\n",
      "  Val Loss: 0.6344\n",
      "  Time: 6.76s\n",
      "\n",
      "[EPOCH 57/100]\n",
      "  Batch [10/13] - Loss: 0.4377\n",
      "  Train Loss: 0.4512\n",
      "  Val Loss: 0.6193\n",
      "  Time: 6.58s\n",
      "\n",
      "[EPOCH 58/100]\n",
      "  Batch [10/13] - Loss: 0.4312\n",
      "  Train Loss: 0.4454\n",
      "  Val Loss: 0.6270\n",
      "  Time: 6.64s\n",
      "\n",
      "[EPOCH 59/100]\n",
      "  Batch [10/13] - Loss: 0.4403\n",
      "  Train Loss: 0.4522\n",
      "  Val Loss: 0.6288\n",
      "  Time: 6.60s\n",
      "\n",
      "[EPOCH 60/100]\n",
      "  Batch [10/13] - Loss: 0.5220\n",
      "  Train Loss: 0.4580\n",
      "  Val Loss: 0.6204\n",
      "  Time: 6.56s\n",
      "\n",
      "[EPOCH 61/100]\n",
      "  Batch [10/13] - Loss: 0.5022\n",
      "  Train Loss: 0.4557\n",
      "  Val Loss: 0.6109\n",
      "  Time: 6.65s\n",
      "\n",
      "[EPOCH 62/100]\n",
      "  Batch [10/13] - Loss: 0.4418\n",
      "  Train Loss: 0.4574\n",
      "  Val Loss: 0.6397\n",
      "  Time: 6.64s\n",
      "\n",
      "[EPOCH 63/100]\n",
      "  Batch [10/13] - Loss: 0.4818\n",
      "  Train Loss: 0.4515\n",
      "  Val Loss: 0.6185\n",
      "  Time: 6.71s\n",
      "\n",
      "[EPOCH 64/100]\n",
      "  Batch [10/13] - Loss: 0.4780\n",
      "  Train Loss: 0.4607\n",
      "  Val Loss: 0.6238\n",
      "  Time: 6.64s\n",
      "\n",
      "[EPOCH 65/100]\n",
      "  Batch [10/13] - Loss: 0.4486\n",
      "  Train Loss: 0.4619\n",
      "  Val Loss: 0.6191\n",
      "  Time: 6.52s\n",
      "\n",
      "[EPOCH 66/100]\n",
      "  Batch [10/13] - Loss: 0.4954\n",
      "  Train Loss: 0.4502\n",
      "  Val Loss: 0.6257\n",
      "  Time: 6.57s\n",
      "\n",
      "[EPOCH 67/100]\n",
      "  Batch [10/13] - Loss: 0.4777\n",
      "  Train Loss: 0.4560\n",
      "  Val Loss: 0.6275\n",
      "  Time: 6.66s\n",
      "\n",
      "[EARLY STOPPING] No improvement for 30 epochs\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 37\n",
      "  Best Val Loss: 0.6077\n",
      "  Total Time: 15.31 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_056_arch_score_010_modaug/plots\n",
      "\n",
      "[OK] Training completed for arch_score_010_modaug!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_056_arch_score_010_modaug\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 1175 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.64s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.781\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.684\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.735\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 40.14 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_056_arch_score_010_modaug/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7807\n",
      "  mAP@0.5:0.95: 0.5373\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: arch_conservative\n",
      "  Conservative architecture changes (lower risk)\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_057_arch_conservative\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_057_arch_conservative\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 52 images\n",
      "[OK] Loaded 2322 annotations\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training for 110 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/110]\n",
      "  Batch [10/13] - Loss: 1.0517\n",
      "  Train Loss: 1.7194\n",
      "  Val Loss: 1.0802\n",
      "  Time: 6.51s\n",
      "  ✓ Best model saved (val_loss: 1.0802)\n",
      "\n",
      "[EPOCH 2/110]\n",
      "  Batch [10/13] - Loss: 0.9608\n",
      "  Train Loss: 0.9234\n",
      "  Val Loss: 0.9138\n",
      "  Time: 6.22s\n",
      "  ✓ Best model saved (val_loss: 0.9138)\n",
      "\n",
      "[EPOCH 3/110]\n",
      "  Batch [10/13] - Loss: 0.7115\n",
      "  Train Loss: 0.7411\n",
      "  Val Loss: 0.7281\n",
      "  Time: 6.56s\n",
      "  ✓ Best model saved (val_loss: 0.7281)\n",
      "\n",
      "[EPOCH 4/110]\n",
      "  Batch [10/13] - Loss: 0.6235\n",
      "  Train Loss: 0.6398\n",
      "  Val Loss: 0.7003\n",
      "  Time: 6.52s\n",
      "  ✓ Best model saved (val_loss: 0.7003)\n",
      "\n",
      "[EPOCH 5/110]\n",
      "  Batch [10/13] - Loss: 0.6072\n",
      "  Train Loss: 0.5946\n",
      "  Val Loss: 0.6860\n",
      "  Time: 6.66s\n",
      "  ✓ Best model saved (val_loss: 0.6860)\n",
      "\n",
      "[EPOCH 6/110]\n",
      "  Batch [10/13] - Loss: 0.7260\n",
      "  Train Loss: 0.6412\n",
      "  Val Loss: 0.7146\n",
      "  Time: 6.44s\n",
      "\n",
      "[EPOCH 7/110]\n",
      "  Batch [10/13] - Loss: 0.6103\n",
      "  Train Loss: 0.5877\n",
      "  Val Loss: 0.6754\n",
      "  Time: 6.46s\n",
      "  ✓ Best model saved (val_loss: 0.6754)\n",
      "\n",
      "[EPOCH 8/110]\n",
      "  Batch [10/13] - Loss: 0.6265\n",
      "  Train Loss: 0.5614\n",
      "  Val Loss: 0.6696\n",
      "  Time: 6.60s\n",
      "  ✓ Best model saved (val_loss: 0.6696)\n",
      "\n",
      "[EPOCH 9/110]\n",
      "  Batch [10/13] - Loss: 0.5722\n",
      "  Train Loss: 0.5556\n",
      "  Val Loss: 0.6640\n",
      "  Time: 6.65s\n",
      "  ✓ Best model saved (val_loss: 0.6640)\n",
      "\n",
      "[EPOCH 10/110]\n",
      "  Batch [10/13] - Loss: 0.5585\n",
      "  Train Loss: 0.5441\n",
      "  Val Loss: 0.6696\n",
      "  Time: 6.63s\n",
      "\n",
      "[EPOCH 11/110]\n",
      "  Batch [10/13] - Loss: 0.5341\n",
      "  Train Loss: 0.5244\n",
      "  Val Loss: 0.6503\n",
      "  Time: 6.70s\n",
      "  ✓ Best model saved (val_loss: 0.6503)\n",
      "\n",
      "[EPOCH 12/110]\n",
      "  Batch [10/13] - Loss: 0.5448\n",
      "  Train Loss: 0.5517\n",
      "  Val Loss: 0.7072\n",
      "  Time: 6.66s\n",
      "\n",
      "[EPOCH 13/110]\n",
      "  Batch [10/13] - Loss: 0.5352\n",
      "  Train Loss: 0.5396\n",
      "  Val Loss: 0.6518\n",
      "  Time: 6.58s\n",
      "\n",
      "[EPOCH 14/110]\n",
      "  Batch [10/13] - Loss: 0.6126\n",
      "  Train Loss: 0.5476\n",
      "  Val Loss: 0.6773\n",
      "  Time: 6.57s\n",
      "\n",
      "[EPOCH 15/110]\n",
      "  Batch [10/13] - Loss: 0.5804\n",
      "  Train Loss: 0.5502\n",
      "  Val Loss: 0.6822\n",
      "  Time: 6.54s\n",
      "\n",
      "[EPOCH 16/110]\n",
      "  Batch [10/13] - Loss: 0.5480\n",
      "  Train Loss: 0.5093\n",
      "  Val Loss: 0.6362\n",
      "  Time: 6.43s\n",
      "  ✓ Best model saved (val_loss: 0.6362)\n",
      "\n",
      "[EPOCH 17/110]\n",
      "  Batch [10/13] - Loss: 0.5231\n",
      "  Train Loss: 0.5283\n",
      "  Val Loss: 0.6662\n",
      "  Time: 6.49s\n",
      "\n",
      "[EPOCH 18/110]\n",
      "  Batch [10/13] - Loss: 0.5436\n",
      "  Train Loss: 0.5209\n",
      "  Val Loss: 0.6276\n",
      "  Time: 6.40s\n",
      "  ✓ Best model saved (val_loss: 0.6276)\n",
      "\n",
      "[EPOCH 19/110]\n",
      "  Batch [10/13] - Loss: 0.5094\n",
      "  Train Loss: 0.4903\n",
      "  Val Loss: 0.6312\n",
      "  Time: 6.52s\n",
      "\n",
      "[EPOCH 20/110]\n",
      "  Batch [10/13] - Loss: 0.4430\n",
      "  Train Loss: 0.4953\n",
      "  Val Loss: 0.6439\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 21/110]\n",
      "  Batch [10/13] - Loss: 0.4916\n",
      "  Train Loss: 0.4958\n",
      "  Val Loss: 0.6327\n",
      "  Time: 6.51s\n",
      "\n",
      "[EPOCH 22/110]\n",
      "  Batch [10/13] - Loss: 0.4746\n",
      "  Train Loss: 0.4746\n",
      "  Val Loss: 0.6195\n",
      "  Time: 6.54s\n",
      "  ✓ Best model saved (val_loss: 0.6195)\n",
      "\n",
      "[EPOCH 23/110]\n",
      "  Batch [10/13] - Loss: 0.4673\n",
      "  Train Loss: 0.4715\n",
      "  Val Loss: 0.6095\n",
      "  Time: 6.41s\n",
      "  ✓ Best model saved (val_loss: 0.6095)\n",
      "\n",
      "[EPOCH 24/110]\n",
      "  Batch [10/13] - Loss: 0.5027\n",
      "  Train Loss: 0.4671\n",
      "  Val Loss: 0.6252\n",
      "  Time: 6.48s\n",
      "\n",
      "[EPOCH 25/110]\n",
      "  Batch [10/13] - Loss: 0.4451\n",
      "  Train Loss: 0.4709\n",
      "  Val Loss: 0.6298\n",
      "  Time: 6.51s\n",
      "\n",
      "[EPOCH 26/110]\n",
      "  Batch [10/13] - Loss: 0.5224\n",
      "  Train Loss: 0.4643\n",
      "  Val Loss: 0.6467\n",
      "  Time: 6.49s\n",
      "\n",
      "[EPOCH 27/110]\n",
      "  Batch [10/13] - Loss: 0.4118\n",
      "  Train Loss: 0.4727\n",
      "  Val Loss: 0.6142\n",
      "  Time: 6.80s\n",
      "\n",
      "[EPOCH 28/110]\n",
      "  Batch [10/13] - Loss: 0.4197\n",
      "  Train Loss: 0.4580\n",
      "  Val Loss: 0.6314\n",
      "  Time: 6.64s\n",
      "\n",
      "[EPOCH 29/110]\n",
      "  Batch [10/13] - Loss: 0.4432\n",
      "  Train Loss: 0.4564\n",
      "  Val Loss: 0.6574\n",
      "  Time: 6.57s\n",
      "\n",
      "[EPOCH 30/110]\n",
      "  Batch [10/13] - Loss: 0.4845\n",
      "  Train Loss: 0.4682\n",
      "  Val Loss: 0.6343\n",
      "  Time: 6.58s\n",
      "\n",
      "[EPOCH 31/110]\n",
      "  Batch [10/13] - Loss: 0.4789\n",
      "  Train Loss: 0.4635\n",
      "  Val Loss: 0.6253\n",
      "  Time: 6.48s\n",
      "\n",
      "[EPOCH 32/110]\n",
      "  Batch [10/13] - Loss: 0.5262\n",
      "  Train Loss: 0.4708\n",
      "  Val Loss: 0.6335\n",
      "  Time: 7.53s\n",
      "\n",
      "[EPOCH 33/110]\n",
      "  Batch [10/13] - Loss: 0.5052\n",
      "  Train Loss: 0.4743\n",
      "  Val Loss: 0.6301\n",
      "  Time: 7.55s\n",
      "\n",
      "[EPOCH 34/110]\n",
      "  Batch [10/13] - Loss: 0.4829\n",
      "  Train Loss: 0.4719\n",
      "  Val Loss: 0.6374\n",
      "  Time: 7.51s\n",
      "\n",
      "[EPOCH 35/110]\n",
      "  Batch [10/13] - Loss: 0.4419\n",
      "  Train Loss: 0.4570\n",
      "  Val Loss: 0.6288\n",
      "  Time: 7.48s\n",
      "\n",
      "[EPOCH 36/110]\n",
      "  Batch [10/13] - Loss: 0.4652\n",
      "  Train Loss: 0.4611\n",
      "  Val Loss: 0.6317\n",
      "  Time: 7.59s\n",
      "\n",
      "[EPOCH 37/110]\n",
      "  Batch [10/13] - Loss: 0.4967\n",
      "  Train Loss: 0.4674\n",
      "  Val Loss: 0.6136\n",
      "  Time: 7.60s\n",
      "\n",
      "[EPOCH 38/110]\n",
      "  Batch [10/13] - Loss: 0.4540\n",
      "  Train Loss: 0.4602\n",
      "  Val Loss: 0.6215\n",
      "  Time: 7.38s\n",
      "\n",
      "[EPOCH 39/110]\n",
      "  Batch [10/13] - Loss: 0.4250\n",
      "  Train Loss: 0.4540\n",
      "  Val Loss: 0.6141\n",
      "  Time: 7.56s\n",
      "\n",
      "[EPOCH 40/110]\n",
      "  Batch [10/13] - Loss: 0.4937\n",
      "  Train Loss: 0.4638\n",
      "  Val Loss: 0.6381\n",
      "  Time: 7.52s\n",
      "\n",
      "[EPOCH 41/110]\n",
      "  Batch [10/13] - Loss: 0.4079\n",
      "  Train Loss: 0.4597\n",
      "  Val Loss: 0.6264\n",
      "  Time: 7.23s\n",
      "\n",
      "[EPOCH 42/110]\n",
      "  Batch [10/13] - Loss: 0.5081\n",
      "  Train Loss: 0.4529\n",
      "  Val Loss: 0.6191\n",
      "  Time: 7.49s\n",
      "\n",
      "[EPOCH 43/110]\n",
      "  Batch [10/13] - Loss: 0.5169\n",
      "  Train Loss: 0.4611\n",
      "  Val Loss: 0.6381\n",
      "  Time: 7.29s\n",
      "\n",
      "[EPOCH 44/110]\n",
      "  Batch [10/13] - Loss: 0.4862\n",
      "  Train Loss: 0.4506\n",
      "  Val Loss: 0.6095\n",
      "  Time: 7.59s\n",
      "\n",
      "[EPOCH 45/110]\n",
      "  Batch [10/13] - Loss: 0.4720\n",
      "  Train Loss: 0.4637\n",
      "  Val Loss: 0.6156\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 46/110]\n",
      "  Batch [10/13] - Loss: 0.4901\n",
      "  Train Loss: 0.4647\n",
      "  Val Loss: 0.6289\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 47/110]\n",
      "  Batch [10/13] - Loss: 0.4765\n",
      "  Train Loss: 0.4569\n",
      "  Val Loss: 0.6251\n",
      "  Time: 6.55s\n",
      "\n",
      "[EPOCH 48/110]\n",
      "  Batch [10/13] - Loss: 0.4827\n",
      "  Train Loss: 0.4544\n",
      "  Val Loss: 0.6128\n",
      "  Time: 6.22s\n",
      "\n",
      "[EPOCH 49/110]\n",
      "  Batch [10/13] - Loss: 0.4410\n",
      "  Train Loss: 0.4613\n",
      "  Val Loss: 0.6385\n",
      "  Time: 6.49s\n",
      "\n",
      "[EPOCH 50/110]\n",
      "  Batch [10/13] - Loss: 0.4432\n",
      "  Train Loss: 0.4533\n",
      "  Val Loss: 0.6320\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 51/110]\n",
      "  Batch [10/13] - Loss: 0.4854\n",
      "  Train Loss: 0.4699\n",
      "  Val Loss: 0.6282\n",
      "  Time: 6.52s\n",
      "\n",
      "[EPOCH 52/110]\n",
      "  Batch [10/13] - Loss: 0.4515\n",
      "  Train Loss: 0.4588\n",
      "  Val Loss: 0.6159\n",
      "  Time: 6.28s\n",
      "\n",
      "[EPOCH 53/110]\n",
      "  Batch [10/13] - Loss: 0.4675\n",
      "  Train Loss: 0.4651\n",
      "  Val Loss: 0.6149\n",
      "  Time: 6.51s\n",
      "\n",
      "[EPOCH 54/110]\n",
      "  Batch [10/13] - Loss: 0.4645\n",
      "  Train Loss: 0.4661\n",
      "  Val Loss: 0.6134\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 55/110]\n",
      "  Batch [10/13] - Loss: 0.4427\n",
      "  Train Loss: 0.4596\n",
      "  Val Loss: 0.6037\n",
      "  Time: 6.44s\n",
      "  ✓ Best model saved (val_loss: 0.6037)\n",
      "\n",
      "[EPOCH 56/110]\n",
      "  Batch [10/13] - Loss: 0.4226\n",
      "  Train Loss: 0.4624\n",
      "  Val Loss: 0.6397\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 57/110]\n",
      "  Batch [10/13] - Loss: 0.4885\n",
      "  Train Loss: 0.4653\n",
      "  Val Loss: 0.6302\n",
      "  Time: 6.54s\n",
      "\n",
      "[EPOCH 58/110]\n",
      "  Batch [10/13] - Loss: 0.4968\n",
      "  Train Loss: 0.4543\n",
      "  Val Loss: 0.6150\n",
      "  Time: 6.53s\n",
      "\n",
      "[EPOCH 59/110]\n",
      "  Batch [10/13] - Loss: 0.4188\n",
      "  Train Loss: 0.4638\n",
      "  Val Loss: 0.6206\n",
      "  Time: 6.27s\n",
      "\n",
      "[EPOCH 60/110]\n",
      "  Batch [10/13] - Loss: 0.4552\n",
      "  Train Loss: 0.4558\n",
      "  Val Loss: 0.6248\n",
      "  Time: 6.73s\n",
      "\n",
      "[EPOCH 61/110]\n",
      "  Batch [10/13] - Loss: 0.5271\n",
      "  Train Loss: 0.4710\n",
      "  Val Loss: 0.6213\n",
      "  Time: 6.57s\n",
      "\n",
      "[EPOCH 62/110]\n",
      "  Batch [10/13] - Loss: 0.4069\n",
      "  Train Loss: 0.4662\n",
      "  Val Loss: 0.6293\n",
      "  Time: 6.51s\n",
      "\n",
      "[EPOCH 63/110]\n",
      "  Batch [10/13] - Loss: 0.4488\n",
      "  Train Loss: 0.4563\n",
      "  Val Loss: 0.6191\n",
      "  Time: 6.37s\n",
      "\n",
      "[EPOCH 64/110]\n",
      "  Batch [10/13] - Loss: 0.4594\n",
      "  Train Loss: 0.4687\n",
      "  Val Loss: 0.6315\n",
      "  Time: 6.35s\n",
      "\n",
      "[EPOCH 65/110]\n",
      "  Batch [10/13] - Loss: 0.4585\n",
      "  Train Loss: 0.4528\n",
      "  Val Loss: 0.6285\n",
      "  Time: 6.45s\n",
      "\n",
      "[EPOCH 66/110]\n",
      "  Batch [10/13] - Loss: 0.4307\n",
      "  Train Loss: 0.4567\n",
      "  Val Loss: 0.6343\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 67/110]\n",
      "  Batch [10/13] - Loss: 0.4227\n",
      "  Train Loss: 0.4629\n",
      "  Val Loss: 0.6214\n",
      "  Time: 6.62s\n",
      "\n",
      "[EPOCH 68/110]\n",
      "  Batch [10/13] - Loss: 0.4654\n",
      "  Train Loss: 0.4468\n",
      "  Val Loss: 0.6295\n",
      "  Time: 6.60s\n",
      "\n",
      "[EPOCH 69/110]\n",
      "  Batch [10/13] - Loss: 0.4414\n",
      "  Train Loss: 0.4555\n",
      "  Val Loss: 0.6251\n",
      "  Time: 6.53s\n",
      "\n",
      "[EPOCH 70/110]\n",
      "  Batch [10/13] - Loss: 0.4968\n",
      "  Train Loss: 0.4584\n",
      "  Val Loss: 0.6197\n",
      "  Time: 6.48s\n",
      "\n",
      "[EPOCH 71/110]\n",
      "  Batch [10/13] - Loss: 0.4462\n",
      "  Train Loss: 0.4677\n",
      "  Val Loss: 0.6258\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 72/110]\n",
      "  Batch [10/13] - Loss: 0.4210\n",
      "  Train Loss: 0.4540\n",
      "  Val Loss: 0.6247\n",
      "  Time: 6.45s\n",
      "\n",
      "[EPOCH 73/110]\n",
      "  Batch [10/13] - Loss: 0.4560\n",
      "  Train Loss: 0.4530\n",
      "  Val Loss: 0.6253\n",
      "  Time: 6.44s\n",
      "\n",
      "[EPOCH 74/110]\n",
      "  Batch [10/13] - Loss: 0.3779\n",
      "  Train Loss: 0.4596\n",
      "  Val Loss: 0.6155\n",
      "  Time: 6.44s\n",
      "\n",
      "[EPOCH 75/110]\n",
      "  Batch [10/13] - Loss: 0.4167\n",
      "  Train Loss: 0.4458\n",
      "  Val Loss: 0.6248\n",
      "  Time: 6.58s\n",
      "\n",
      "[EPOCH 76/110]\n",
      "  Batch [10/13] - Loss: 0.5323\n",
      "  Train Loss: 0.4668\n",
      "  Val Loss: 0.6246\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 77/110]\n",
      "  Batch [10/13] - Loss: 0.4564\n",
      "  Train Loss: 0.4605\n",
      "  Val Loss: 0.6339\n",
      "  Time: 6.49s\n",
      "\n",
      "[EPOCH 78/110]\n",
      "  Batch [10/13] - Loss: 0.4749\n",
      "  Train Loss: 0.4558\n",
      "  Val Loss: 0.6261\n",
      "  Time: 6.54s\n",
      "\n",
      "[EPOCH 79/110]\n",
      "  Batch [10/13] - Loss: 0.5114\n",
      "  Train Loss: 0.4673\n",
      "  Val Loss: 0.6321\n",
      "  Time: 6.50s\n",
      "\n",
      "[EPOCH 80/110]\n",
      "  Batch [10/13] - Loss: 0.4778\n",
      "  Train Loss: 0.4702\n",
      "  Val Loss: 0.6218\n",
      "  Time: 6.44s\n",
      "\n",
      "[EPOCH 81/110]\n",
      "  Batch [10/13] - Loss: 0.4294\n",
      "  Train Loss: 0.4564\n",
      "  Val Loss: 0.6281\n",
      "  Time: 6.50s\n",
      "\n",
      "[EPOCH 82/110]\n",
      "  Batch [10/13] - Loss: 0.5350\n",
      "  Train Loss: 0.4641\n",
      "  Val Loss: 0.6227\n",
      "  Time: 6.46s\n",
      "\n",
      "[EPOCH 83/110]\n",
      "  Batch [10/13] - Loss: 0.4353\n",
      "  Train Loss: 0.4442\n",
      "  Val Loss: 0.6274\n",
      "  Time: 6.47s\n",
      "\n",
      "[EPOCH 84/110]\n",
      "  Batch [10/13] - Loss: 0.4807\n",
      "  Train Loss: 0.4560\n",
      "  Val Loss: 0.6298\n",
      "  Time: 6.48s\n",
      "\n",
      "[EPOCH 85/110]\n",
      "  Batch [10/13] - Loss: 0.5033\n",
      "  Train Loss: 0.4634\n",
      "  Val Loss: 0.6194\n",
      "  Time: 6.24s\n",
      "\n",
      "[EPOCH 86/110]\n",
      "  Batch [10/13] - Loss: 0.4623\n",
      "  Train Loss: 0.4523\n",
      "  Val Loss: 0.6234\n",
      "  Time: 6.26s\n",
      "\n",
      "[EPOCH 87/110]\n",
      "  Batch [10/13] - Loss: 0.4176\n",
      "  Train Loss: 0.4541\n",
      "  Val Loss: 0.6235\n",
      "  Time: 6.57s\n",
      "\n",
      "[EPOCH 88/110]\n",
      "  Batch [10/13] - Loss: 0.4677\n",
      "  Train Loss: 0.4559\n",
      "  Val Loss: 0.6251\n",
      "  Time: 6.23s\n",
      "\n",
      "[EPOCH 89/110]\n",
      "  Batch [10/13] - Loss: 0.4649\n",
      "  Train Loss: 0.4612\n",
      "  Val Loss: 0.6269\n",
      "  Time: 6.54s\n",
      "\n",
      "[EPOCH 90/110]\n",
      "  Batch [10/13] - Loss: 0.4443\n",
      "  Train Loss: 0.4702\n",
      "  Val Loss: 0.6035\n",
      "  Time: 6.47s\n",
      "  ✓ Best model saved (val_loss: 0.6035)\n",
      "\n",
      "[EPOCH 91/110]\n",
      "  Batch [10/13] - Loss: 0.4967\n",
      "  Train Loss: 0.4507\n",
      "  Val Loss: 0.6170\n",
      "  Time: 6.77s\n",
      "\n",
      "[EPOCH 92/110]\n",
      "  Batch [10/13] - Loss: 0.4645\n",
      "  Train Loss: 0.4491\n",
      "  Val Loss: 0.6344\n",
      "  Time: 6.20s\n",
      "\n",
      "[EPOCH 93/110]\n",
      "  Batch [10/13] - Loss: 0.4234\n",
      "  Train Loss: 0.4528\n",
      "  Val Loss: 0.6209\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 94/110]\n",
      "  Batch [10/13] - Loss: 0.5401\n",
      "  Train Loss: 0.4588\n",
      "  Val Loss: 0.6212\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 95/110]\n",
      "  Batch [10/13] - Loss: 0.4972\n",
      "  Train Loss: 0.4697\n",
      "  Val Loss: 0.6242\n",
      "  Time: 6.25s\n",
      "\n",
      "[EPOCH 96/110]\n",
      "  Batch [10/13] - Loss: 0.4715\n",
      "  Train Loss: 0.4653\n",
      "  Val Loss: 0.6345\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 97/110]\n",
      "  Batch [10/13] - Loss: 0.4968\n",
      "  Train Loss: 0.4601\n",
      "  Val Loss: 0.6288\n",
      "  Time: 6.49s\n",
      "\n",
      "[EPOCH 98/110]\n",
      "  Batch [10/13] - Loss: 0.4188\n",
      "  Train Loss: 0.4583\n",
      "  Val Loss: 0.6175\n",
      "  Time: 6.58s\n",
      "\n",
      "[EPOCH 99/110]\n",
      "  Batch [10/13] - Loss: 0.4171\n",
      "  Train Loss: 0.4531\n",
      "  Val Loss: 0.6266\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 100/110]\n",
      "  Batch [10/13] - Loss: 0.5255\n",
      "  Train Loss: 0.4688\n",
      "  Val Loss: 0.6310\n",
      "  Time: 6.45s\n",
      "\n",
      "[EPOCH 101/110]\n",
      "  Batch [10/13] - Loss: 0.4603\n",
      "  Train Loss: 0.4642\n",
      "  Val Loss: 0.6415\n",
      "  Time: 6.52s\n",
      "\n",
      "[EPOCH 102/110]\n",
      "  Batch [10/13] - Loss: 0.4346\n",
      "  Train Loss: 0.4614\n",
      "  Val Loss: 0.6145\n",
      "  Time: 6.47s\n",
      "\n",
      "[EPOCH 103/110]\n",
      "  Batch [10/13] - Loss: 0.4686\n",
      "  Train Loss: 0.4675\n",
      "  Val Loss: 0.6228\n",
      "  Time: 6.43s\n",
      "\n",
      "[EPOCH 104/110]\n",
      "  Batch [10/13] - Loss: 0.5097\n",
      "  Train Loss: 0.4664\n",
      "  Val Loss: 0.6267\n",
      "  Time: 6.50s\n",
      "\n",
      "[EPOCH 105/110]\n",
      "  Batch [10/13] - Loss: 0.4273\n",
      "  Train Loss: 0.4521\n",
      "  Val Loss: 0.6324\n",
      "  Time: 6.41s\n",
      "\n",
      "[EPOCH 106/110]\n",
      "  Batch [10/13] - Loss: 0.4737\n",
      "  Train Loss: 0.4567\n",
      "  Val Loss: 0.6047\n",
      "  Time: 6.65s\n",
      "\n",
      "[EPOCH 107/110]\n",
      "  Batch [10/13] - Loss: 0.4892\n",
      "  Train Loss: 0.4606\n",
      "  Val Loss: 0.6353\n",
      "  Time: 6.59s\n",
      "\n",
      "[EPOCH 108/110]\n",
      "  Batch [10/13] - Loss: 0.4302\n",
      "  Train Loss: 0.4512\n",
      "  Val Loss: 0.6225\n",
      "  Time: 6.66s\n",
      "\n",
      "[EPOCH 109/110]\n",
      "  Batch [10/13] - Loss: 0.4102\n",
      "  Train Loss: 0.4556\n",
      "  Val Loss: 0.6216\n",
      "  Time: 6.39s\n",
      "\n",
      "[EPOCH 110/110]\n",
      "  Batch [10/13] - Loss: 0.4917\n",
      "  Train Loss: 0.4572\n",
      "  Val Loss: 0.6103\n",
      "  Time: 6.64s\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 90\n",
      "  Best Val Loss: 0.6035\n",
      "  Total Time: 19.56 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_057_arch_conservative/plots\n",
      "\n",
      "[OK] Training completed for arch_conservative!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_057_arch_conservative\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 1178 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.64s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.540\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.790\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.688\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.540\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.735\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.737\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 40.23 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_057_arch_conservative/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7903\n",
      "  mAP@0.5:0.95: 0.5398\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 6: Run Experiments\n",
    "# ==============================================================================\n",
    "\"\"\"\n",
    "CONFIGURABLE ARCHITECTURE PARAMETERS (Opción A):\n",
    "\n",
    "You can now configure these architecture parameters directly in experiments_config:\n",
    "\n",
    "- box_score_thresh (float, default 0.05): Minimum confidence threshold for detections\n",
    "  * Higher values (0.10-0.15) reduce false positives but may miss low-confidence objects\n",
    "  * Recommended range: 0.05-0.20\n",
    "\n",
    "- box_nms_thresh (float, default 0.5): NMS IoU threshold\n",
    "  * Lower values (0.4-0.45) allow closer boxes (good for dense scenes)\n",
    "  * Higher values (0.5-0.6) suppress more overlapping boxes\n",
    "  * Recommended range: 0.4-0.6\n",
    "\n",
    "- box_detections_per_img (int, default 100): Maximum detections per image\n",
    "  * Your dataset averages 44 objects/image, so 80-120 is reasonable\n",
    "  * Recommended range: 60-150\n",
    "\n",
    "- rpn_fg_iou_thresh (float, default 0.7): RPN foreground IoU threshold\n",
    "  * Lower values (0.6) are more lenient for dense/overlapping objects\n",
    "  * Recommended range: 0.6-0.7\n",
    "\n",
    "- rpn_bg_iou_thresh (float, default 0.3): RPN background IoU threshold\n",
    "  * Higher values (0.4) are more strict about background classification\n",
    "  * Recommended range: 0.3-0.5\n",
    "\n",
    "- box_positive_fraction (float, default 0.25): Ratio of positive samples in ROI head\n",
    "  * Higher values (0.30-0.35) provide more positive examples for dense scenes\n",
    "  * Recommended range: 0.20-0.35\n",
    "\n",
    "EXAMPLE USAGE in experiments_config:\n",
    "{\n",
    "    'name': 'optimized_score_thresh',\n",
    "    'description': 'Test higher confidence threshold',\n",
    "    'backbone': 'resnet50',\n",
    "    'pretrained': True,\n",
    "    'num_epochs': 50,\n",
    "    'batch_size': 4,\n",
    "    'learning_rate': 0.005,\n",
    "    ... (standard params) ...\n",
    "\n",
    "    # NEW: Architecture parameters\n",
    "    'box_score_thresh': 0.10,        # Higher confidence\n",
    "    'box_nms_thresh': 0.5,           # Keep default\n",
    "    'rpn_fg_iou_thresh': 0.6,        # More lenient\n",
    "    'box_positive_fraction': 0.30,   # More positive samples\n",
    "}\n",
    "\n",
    "NOTE: If parameter is not specified, torchvision defaults are used.\n",
    "All parameters are tracked in CSV for analysis.\n",
    "\"\"\"\n",
    "\n",
    "# Device detection\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"\\n[INFO] Using device: {device}\")\n",
    "\n",
    "# Experiment configuration with data augmentation\n",
    "experiments_config = [\n",
    "    # ==========================================================================\n",
    "    # BASELINE - Repeat best config for comparison\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'arch_baseline_repeat',\n",
    "        'description': 'Repeat best config (exp_028) with NO architecture changes',\n",
    "        'backbone': 'resnet50',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 110,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.004,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 20,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 35,\n",
    "        # Best augmentation from exp_028\n",
    "        'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "        'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True\n",
    "        # NO architecture params = all defaults (0.05, 0.5, 100, 0.7, 0.3, 0.25)\n",
    "    },\n",
    "\n",
    "    # ==========================================================================\n",
    "    # TEST 1: SCORE THRESHOLD 0.10 (Most Promising - Expect +2-4% mAP)\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'arch_score_010_v1',\n",
    "        'description': 'Best config + score threshold 0.10',\n",
    "        'backbone': 'resnet50',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 110,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.004,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 20,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 35,\n",
    "        'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "        'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True,\n",
    "        # ARCHITECTURE:\n",
    "        'box_score_thresh': 0.10  # Higher confidence threshold\n",
    "    },\n",
    "\n",
    "    # ==========================================================================\n",
    "    # TEST 2: SCORE THRESHOLD 0.15 (Very Strict)\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'arch_score_015_v1',\n",
    "        'description': 'Best config + score threshold 0.15 (strict)',\n",
    "        'backbone': 'resnet50',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 110,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.004,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 20,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 35,\n",
    "        'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "        'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True,\n",
    "        # ARCHITECTURE:\n",
    "        'box_score_thresh': 0.15  # Very high confidence\n",
    "    },\n",
    "\n",
    "    # ==========================================================================\n",
    "    # TEST 3: RPN THRESHOLDS (For Dense Scenes - Expect +0.5-2% mAP)\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'arch_rpn_dense_v1',\n",
    "        'description': 'Best config + RPN thresholds optimized for density',\n",
    "        'backbone': 'resnet50',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 110,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.004,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 20,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 35,\n",
    "        'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "        'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True,\n",
    "        # ARCHITECTURE:\n",
    "        'rpn_fg_iou_thresh': 0.6,  # More lenient (from 0.7)\n",
    "        'rpn_bg_iou_thresh': 0.4   # More strict (from 0.3)\n",
    "    },\n",
    "\n",
    "    # ==========================================================================\n",
    "    # TEST 4: POSITIVE FRACTION (More Positive Samples - Expect +0.5-1% mAP)\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'arch_pos_frac_030_v1',\n",
    "        'description': 'Best config + positive fraction 0.30',\n",
    "        'backbone': 'resnet50',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 110,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.004,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 20,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 35,\n",
    "        'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "        'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True,\n",
    "        # ARCHITECTURE:\n",
    "        'box_positive_fraction': 0.30  # More positive samples (from 0.25)\n",
    "    },\n",
    "\n",
    "    # ==========================================================================\n",
    "    # TEST 5: COMBINED OPTIMIZATION v1 (Score + RPN)\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'arch_combined_score_rpn',\n",
    "        'description': 'Score 0.10 + RPN thresholds combined',\n",
    "        'backbone': 'resnet50',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 110,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.004,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 20,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 35,\n",
    "        'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "        'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True,\n",
    "        # ARCHITECTURE - COMBINED:\n",
    "        'box_score_thresh': 0.10,\n",
    "        'rpn_fg_iou_thresh': 0.6,\n",
    "        'rpn_bg_iou_thresh': 0.4\n",
    "    },\n",
    "\n",
    "    # ==========================================================================\n",
    "    # TEST 6: COMBINED OPTIMIZATION v2 (All Parameters)\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'arch_combined_full',\n",
    "        'description': 'All architecture optimizations combined',\n",
    "        'backbone': 'resnet50',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 120,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.004,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 25,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 40,\n",
    "        'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "        'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True,\n",
    "        # ARCHITECTURE - ALL OPTIMIZATIONS:\n",
    "        'box_score_thresh': 0.10,\n",
    "        'rpn_fg_iou_thresh': 0.6,\n",
    "        'rpn_bg_iou_thresh': 0.4,\n",
    "        'box_positive_fraction': 0.30,\n",
    "        'box_detections_per_img': 80  # Slightly lower (avg is 44 obj/img)\n",
    "    },\n",
    "\n",
    "    # ==========================================================================\n",
    "    # TEST 7: Alternative Score Threshold 0.12\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'arch_score_012_v1',\n",
    "        'description': 'Best config + score threshold 0.12 (middle ground)',\n",
    "        'backbone': 'resnet50',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 110,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.004,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 20,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 35,\n",
    "        'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "        'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True,\n",
    "        # ARCHITECTURE:\n",
    "        'box_score_thresh': 0.12  # Middle ground between 0.10 and 0.15\n",
    "    },\n",
    "\n",
    "    # ==========================================================================\n",
    "    # TEST 8: Score + Positive Fraction\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'arch_score_posfrac',\n",
    "        'description': 'Score 0.10 + Positive fraction 0.30',\n",
    "        'backbone': 'resnet50',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 110,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.004,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 20,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 35,\n",
    "        'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "        'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True,\n",
    "        # ARCHITECTURE - COMBINED:\n",
    "        'box_score_thresh': 0.10,\n",
    "        'box_positive_fraction': 0.30\n",
    "    },\n",
    "\n",
    "    # ==========================================================================\n",
    "    # BONUS: Test with Moderate Augmentation + Architecture\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'arch_score_010_modaug',\n",
    "        'description': 'Score 0.10 with moderate augmentation',\n",
    "        'backbone': 'resnet50',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 100,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.005,  # Slightly higher LR\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 20,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 30,\n",
    "        # Moderate augmentation\n",
    "        'hsv_h': 0.02, 'hsv_s': 0.1, 'hsv_v': 0.1,\n",
    "        'degrees': 5.0, 'translate': 0.08, 'scale': 0.12,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True,\n",
    "        # ARCHITECTURE:\n",
    "        'box_score_thresh': 0.10\n",
    "    },\n",
    "\n",
    "    # ==========================================================================\n",
    "    # BONUS 2: Conservative Combined (Lower Risk)\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'arch_conservative',\n",
    "        'description': 'Conservative architecture changes (lower risk)',\n",
    "        'backbone': 'resnet50',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 110,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.004,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 20,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 35,\n",
    "        'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "        'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True,\n",
    "        # ARCHITECTURE - CONSERVATIVE:\n",
    "        'box_score_thresh': 0.08,      # Slightly higher but conservative\n",
    "        'box_positive_fraction': 0.28  # Slightly higher but conservative\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# Run experiments\n",
    "for exp_config in experiments_config:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"  STARTING EXPERIMENT: {exp_config['name']}\")\n",
    "    print(f\"  {exp_config['description']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = FasterRCNNTrainer(\n",
    "        experiment_name=exp_config['name'],\n",
    "        model_family_dir='02_faster_rcnn'\n",
    "    )\n",
    "\n",
    "    # Create transforms with augmentation\n",
    "    train_transforms = get_train_transforms(exp_config)\n",
    "    val_transforms = get_val_transforms()\n",
    "\n",
    "    print(f\"\\n[INFO] Data augmentation settings:\")\n",
    "    print(f\"  HSV: h={exp_config.get('hsv_h', 0)}, s={exp_config.get('hsv_s', 0)}, v={exp_config.get('hsv_v', 0)}\")\n",
    "    print(f\"  Geometric: degrees={exp_config.get('degrees', 0)}, translate={exp_config.get('translate', 0)}, scale={exp_config.get('scale', 0)}\")\n",
    "    print(f\"  Flip: horizontal={exp_config.get('horizontal_flip', 0)}, vertical={exp_config.get('vertical_flip', 0)}\")\n",
    "    print(f\"  Other: blur={exp_config.get('blur', False)}, brightness_contrast={exp_config.get('brightness_contrast', False)}\")\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = COCODataset(\n",
    "        root_dir=train_images_dir,\n",
    "        annotation_file=train_ann_file,\n",
    "        transforms=train_transforms\n",
    "    )\n",
    "\n",
    "    val_dataset = COCODataset(\n",
    "        root_dir=val_images_dir,\n",
    "        annotation_file=val_ann_file,\n",
    "        transforms=val_transforms\n",
    "    )\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=exp_config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        collate_fn=lambda x: tuple(zip(*x))\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=exp_config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        collate_fn=lambda x: tuple(zip(*x))\n",
    "    )\n",
    "\n",
    "    # Create model (num_classes = 1 (palm) + 1 (background) = 2)\n",
    "    model = get_model(\n",
    "        num_classes=2,\n",
    "        backbone=exp_config['backbone'],\n",
    "        pretrained=exp_config['pretrained'],\n",
    "        # Configurable architecture parameters (Opción A)\n",
    "        box_score_thresh=exp_config.get('box_score_thresh'),\n",
    "        box_nms_thresh=exp_config.get('box_nms_thresh'),\n",
    "        box_detections_per_img=exp_config.get('box_detections_per_img'),\n",
    "        rpn_fg_iou_thresh=exp_config.get('rpn_fg_iou_thresh'),\n",
    "        rpn_bg_iou_thresh=exp_config.get('rpn_bg_iou_thresh'),\n",
    "        box_positive_fraction=exp_config.get('box_positive_fraction')\n",
    "    )\n",
    "\n",
    "    # Create optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(\n",
    "        params,\n",
    "        lr=exp_config['learning_rate'],\n",
    "        momentum=exp_config['momentum'],\n",
    "        weight_decay=exp_config['weight_decay']\n",
    "    )\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=exp_config['step_size'],\n",
    "        gamma=exp_config['gamma']\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    history, best_val_loss, best_epoch = trainer.train(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        num_epochs=exp_config['num_epochs'],\n",
    "        device=device,\n",
    "        config=exp_config\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[OK] Training completed for {exp_config['name']}!\")\n",
    "    print(f\"  Results saved to: {trainer.experiment_dir}\")\n",
    "\n",
    "    # Automatic evaluation and CSV logging (same as YOLOv8)\n",
    "    print(f\"\\n[INFO] Evaluating model and saving metrics...\")\n",
    "\n",
    "    # Load best model for evaluation (must match training config)\n",
    "    model_eval = get_model(\n",
    "        num_classes=2,\n",
    "        backbone=exp_config['backbone'],\n",
    "        pretrained=False,\n",
    "        # Must use same architecture parameters as training\n",
    "        box_score_thresh=exp_config.get('box_score_thresh'),\n",
    "        box_nms_thresh=exp_config.get('box_nms_thresh'),\n",
    "        box_detections_per_img=exp_config.get('box_detections_per_img'),\n",
    "        rpn_fg_iou_thresh=exp_config.get('rpn_fg_iou_thresh'),\n",
    "        rpn_bg_iou_thresh=exp_config.get('rpn_bg_iou_thresh'),\n",
    "        box_positive_fraction=exp_config.get('box_positive_fraction')\n",
    "    )\n",
    "    model_eval.load_state_dict(torch.load(trainer.weights_dir / 'best.pt'))\n",
    "    model_eval.to(device)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    metrics = evaluate_model_coco(model_eval, val_loader, device, val_ann_file)\n",
    "\n",
    "    # Get dataset info\n",
    "    with open(train_ann_file, 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    with open(val_ann_file, 'r') as f:\n",
    "        val_data = json.load(f)\n",
    "\n",
    "    dataset_info = {\n",
    "        'num_train_images': len(train_data['images']),\n",
    "        'num_val_images': len(val_data['images']),\n",
    "        'num_train_boxes': len(train_data['annotations']),\n",
    "        'num_val_boxes': len(val_data['annotations'])\n",
    "    }\n",
    "\n",
    "    # Save metrics to CSV (master + family)\n",
    "    training_time_seconds = trainer.training_time\n",
    "    save_metrics_to_csv(\n",
    "        experiment_dir=trainer.experiment_dir,\n",
    "        experiment_id=trainer.experiment_id,\n",
    "        experiment_name=exp_config['name'],\n",
    "        config=exp_config,\n",
    "        metrics=metrics,\n",
    "        dataset_info=dataset_info,\n",
    "        training_time=training_time_seconds,\n",
    "        best_epoch=best_epoch\n",
    "    )\n",
    "\n",
    "    # Update best model tracker (overall + family)\n",
    "    update_best_model_tracker(\n",
    "        experiment_id=trainer.experiment_id,\n",
    "        experiment_name=exp_config['name'],\n",
    "        metrics=metrics,\n",
    "        config=exp_config\n",
    "    )\n",
    "\n",
    "    # Create comprehensive plots\n",
    "    history_plots = {\n",
    "        'train_loss': history['train_loss'],\n",
    "        'val_loss': history['val_loss'],\n",
    "        'learning_rate': history['learning_rate']\n",
    "    }\n",
    "    create_comprehensive_plots(\n",
    "        experiment_dir=trainer.experiment_dir,\n",
    "        history=history_plots,\n",
    "        metrics=metrics,\n",
    "        best_epoch=best_epoch,\n",
    "        experiment_id=trainer.experiment_id\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[OK] Metrics saved to CSVs and best model tracker updated!\")\n",
    "    print(f\"  mAP@0.5:      {metrics['mAP_50']:.4f}\")\n",
    "    print(f\"  mAP@0.5:0.95: {metrics['mAP_50_95']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 19 12:50:19 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:84:00.0 Off |                  N/A |\n",
      "| 47%   77C    P2            194W /  250W |   10970MiB /  11264MiB |     65%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:85:00.0 Off |                  N/A |\n",
      "| 24%   41C    P8             19W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:88:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8              6W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:89:00.0 Off |                  N/A |\n",
      "| 22%   28C    P8              4W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    519540      C   /opt/tljh/user/bin/python                     286MiB |\n",
      "|    0   N/A  N/A    694923      C   ....conda/envs/env-ait-dlcv/bin/python       2782MiB |\n",
      "|    0   N/A  N/A    701620      C   /opt/tljh/user/bin/python                    3174MiB |\n",
      "|    0   N/A  N/A    701925      C   /opt/tljh/user/bin/python                     466MiB |\n",
      "|    0   N/A  N/A    702665      C   python                                       4096MiB |\n",
      "|    0   N/A  N/A    703161      C   /opt/tljh/user/bin/python                     156MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "kCSrFovUHD0I",
    "outputId": "dd2a6201-ff20-4797-bfeb-16b62f084f42",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] SECTION 7 loaded (OPTIONAL)\n",
      "Use: evaluate_experiment('exp_001_baseline_resnet50') to re-evaluate a trained model\n",
      "\n",
      "================================================================================\n",
      "  Oil Palm Detection - Faster R-CNN Training System\n",
      "  All sections loaded successfully!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 7: Re-evaluate Trained Models (OPTIONAL)\n",
    "# ==============================================================================\n",
    "# NOTE: Evaluation is now done automatically after training in SECTION 6.\n",
    "# This section is OPTIONAL and only needed if you want to re-evaluate\n",
    "# an already trained model (e.g., after changing evaluation parameters).\n",
    "\n",
    "def evaluate_experiment(experiment_id, backbone='resnet50'):\n",
    "    \"\"\"\n",
    "    Evaluate a trained Faster R-CNN experiment and save metrics to CSV.\n",
    "\n",
    "    Args:\n",
    "        experiment_id: Experiment ID (e.g., 'exp_001_baseline_resnet50')\n",
    "        backbone: Model backbone used ('resnet50' or 'resnet101')\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "\n",
    "    Note: Architecture parameters are loaded from experiment_log.json config\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  EVALUATING: {experiment_id}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    experiment_dir = Path(EXPERIMENTS_PATH) / '02_faster_rcnn' / experiment_id\n",
    "\n",
    "    # Check if experiment exists\n",
    "    if not experiment_dir.exists():\n",
    "        print(f\"[ERROR] Experiment not found: {experiment_dir}\")\n",
    "        return None\n",
    "\n",
    "    # Load experiment config first to get architecture parameters\n",
    "    print(\"[INFO] Loading experiment config...\")\n",
    "    with open(experiment_dir / 'experiment_log.json', 'r') as f:\n",
    "        exp_log = json.load(f)\n",
    "\n",
    "    exp_config = exp_log.get('config', {})\n",
    "\n",
    "    # Load best model with same architecture parameters as training\n",
    "    print(\"[INFO] Loading best model...\")\n",
    "    model = get_model(\n",
    "        num_classes=2,\n",
    "        backbone=backbone,\n",
    "        pretrained=False,\n",
    "        # Use same architecture parameters as training\n",
    "        box_score_thresh=exp_config.get('box_score_thresh'),\n",
    "        box_nms_thresh=exp_config.get('box_nms_thresh'),\n",
    "        box_detections_per_img=exp_config.get('box_detections_per_img'),\n",
    "        rpn_fg_iou_thresh=exp_config.get('rpn_fg_iou_thresh'),\n",
    "        rpn_bg_iou_thresh=exp_config.get('rpn_bg_iou_thresh'),\n",
    "        box_positive_fraction=exp_config.get('box_positive_fraction')\n",
    "    )\n",
    "    model.load_state_dict(torch.load(experiment_dir / 'weights' / 'best.pt'))\n",
    "    model.to(device)\n",
    "\n",
    "    # Create validation loader\n",
    "    print(\"[INFO] Loading validation dataset...\")\n",
    "    val_dataset = COCODataset(val_images_dir, val_ann_file, get_val_transforms())\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False,\n",
    "                            num_workers=0, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    metrics = evaluate_model_coco(model, val_loader, device, val_ann_file)\n",
    "\n",
    "    # Get dataset info from annotation files\n",
    "    with open(train_ann_file, 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    with open(val_ann_file, 'r') as f:\n",
    "        val_data = json.load(f)\n",
    "\n",
    "    dataset_info = {\n",
    "        'num_train_images': len(train_data['images']),\n",
    "        'num_val_images': len(val_data['images']),\n",
    "        'num_train_boxes': len(train_data['annotations']),\n",
    "        'num_val_boxes': len(val_data['annotations'])\n",
    "    }\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    print(\"\\n[INFO] Saving metrics to CSV...\")\n",
    "    # training_time_minutes from exp_log is already in minutes, multiply by 60 to get seconds\n",
    "    training_time_seconds = exp_log.get('training_time_minutes', 0) * 60\n",
    "    save_metrics_to_csv(\n",
    "        experiment_dir=experiment_dir,\n",
    "        experiment_id=experiment_id,\n",
    "        experiment_name=exp_log['config'].get('name', experiment_id),\n",
    "        config=exp_log['config'],\n",
    "        metrics=metrics,\n",
    "        dataset_info=dataset_info,\n",
    "        training_time=training_time_seconds,  # Now in seconds, will be converted to hours in CSV\n",
    "        best_epoch=exp_log['best_epoch']\n",
    "    )\n",
    "\n",
    "    # Update best model tracker\n",
    "    update_best_model_tracker(\n",
    "        experiment_id=experiment_id,\n",
    "        experiment_name=exp_log['config'].get('name', experiment_id),\n",
    "        metrics=metrics,\n",
    "        config=exp_log['config']\n",
    "    )\n",
    "\n",
    "    # Create comprehensive plots (6 subplots like YOLOv8)\n",
    "    print(\"\\n[INFO] Creating comprehensive plots...\")\n",
    "    history = {\n",
    "        'train_loss': exp_log.get('train_loss', []),\n",
    "        'val_loss': exp_log.get('val_loss', []),\n",
    "        'learning_rate': exp_log.get('learning_rate', [])\n",
    "    }\n",
    "    create_comprehensive_plots(\n",
    "        experiment_dir=experiment_dir,\n",
    "        history=history,\n",
    "        metrics=metrics,\n",
    "        best_epoch=exp_log['best_epoch'],\n",
    "        experiment_id=experiment_id\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  EVALUATION SUMMARY - {experiment_id}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  mAP@0.5:      {metrics['mAP_50']:.4f}\")\n",
    "    print(f\"  mAP@0.5:0.95: {metrics['mAP_50_95']:.4f}\")\n",
    "    print(f\"  mAP@0.75:     {metrics['mAP_75']:.4f}\")\n",
    "    print(f\"  Precision:    {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall:       {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1-Score:     {metrics['f1_score']:.4f}\")\n",
    "    print(f\"  Inference:    {metrics['inference_time_ms']:.2f} ms/image\")\n",
    "    print(f\"  Parameters:   {metrics['total_params_M']:.2f}M\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Example usage (uncomment to evaluate):\n",
    "\"\"\"\n",
    "# Evaluate all completed experiments\n",
    "experiment_ids = [\n",
    "    'exp_001_baseline_resnet50',\n",
    "    'exp_002_augmented_resnet50',\n",
    "    'exp_003_heavy_aug_resnet50'\n",
    "]\n",
    "\n",
    "for exp_id in experiment_ids:\n",
    "    evaluate_experiment(exp_id, backbone='resnet50')\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n[INFO] SECTION 7 loaded (OPTIONAL)\")\n",
    "print(\"Use: evaluate_experiment('exp_001_baseline_resnet50') to re-evaluate a trained model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjt5TZAMFq1I",
    "outputId": "8affba77-86f2-4cad-93a4-2d7a4eb029f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  EVALUATING: exp_001_baseline_resnet50\n",
      "======================================================================\n",
      "\n",
      "[INFO] Loading best model...\n",
      "[INFO] Loading validation dataset...\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n",
      "[INFO] Running inference for COCO evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Generated 1098 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.783\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.686\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.723\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.725\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 99.01 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "\n",
      "[INFO] Saving metrics to CSV...\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/all_experiments_log.csv\n",
      "\n",
      "[INFO] Creating comprehensive plots...\n",
      "[OK] Comprehensive plots saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/exp_001_baseline_resnet50/plots/comprehensive_results.png\n",
      "\n",
      "======================================================================\n",
      "  EVALUATION SUMMARY - exp_001_baseline_resnet50\n",
      "======================================================================\n",
      "  mAP@0.5:      0.7829\n",
      "  mAP@0.5:0.95: 0.5249\n",
      "  mAP@0.75:     0.6864\n",
      "  Precision:    0.7829\n",
      "  Recall:       0.7233\n",
      "  F1-Score:     0.7519\n",
      "  Inference:    99.01 ms/image\n",
      "  Parameters:   41.30M\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "  EVALUATING: exp_002_augmented_resnet50\n",
      "======================================================================\n",
      "\n",
      "[INFO] Loading best model...\n",
      "[INFO] Loading validation dataset...\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n",
      "[INFO] Running inference for COCO evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Generated 1190 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.786\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.653\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.720\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.721\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 98.92 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "\n",
      "[INFO] Saving metrics to CSV...\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/all_experiments_log.csv\n",
      "\n",
      "[INFO] Creating comprehensive plots...\n",
      "[OK] Comprehensive plots saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/exp_002_augmented_resnet50/plots/comprehensive_results.png\n",
      "\n",
      "======================================================================\n",
      "  EVALUATION SUMMARY - exp_002_augmented_resnet50\n",
      "======================================================================\n",
      "  mAP@0.5:      0.7861\n",
      "  mAP@0.5:0.95: 0.5212\n",
      "  mAP@0.75:     0.6535\n",
      "  Precision:    0.7861\n",
      "  Recall:       0.7200\n",
      "  F1-Score:     0.7516\n",
      "  Inference:    98.92 ms/image\n",
      "  Parameters:   41.30M\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "  EVALUATING: exp_003_heavy_aug_resnet50\n",
      "======================================================================\n",
      "\n",
      "[INFO] Loading best model...\n",
      "[INFO] Loading validation dataset...\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n",
      "[INFO] Running inference for COCO evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Generated 1216 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.778\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.695\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.731\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 100.10 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "\n",
      "[INFO] Saving metrics to CSV...\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/all_experiments_log.csv\n",
      "\n",
      "[INFO] Creating comprehensive plots...\n",
      "[OK] Comprehensive plots saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/exp_003_heavy_aug_resnet50/plots/comprehensive_results.png\n",
      "\n",
      "======================================================================\n",
      "  EVALUATION SUMMARY - exp_003_heavy_aug_resnet50\n",
      "======================================================================\n",
      "  mAP@0.5:      0.7781\n",
      "  mAP@0.5:0.95: 0.5277\n",
      "  mAP@0.75:     0.6953\n",
      "  Precision:    0.7781\n",
      "  Recall:       0.7299\n",
      "  F1-Score:     0.7532\n",
      "  Inference:    100.10 ms/image\n",
      "  Parameters:   41.30M\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all completed experiments\n",
    "experiment_ids = [\n",
    "    'exp_001_baseline_resnet50',\n",
    "    'exp_002_augmented_resnet50',\n",
    "    'exp_003_heavy_aug_resnet50'\n",
    "]\n",
    "\n",
    "for exp_id in experiment_ids:\n",
    "    evaluate_experiment(exp_id, backbone='resnet50')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
