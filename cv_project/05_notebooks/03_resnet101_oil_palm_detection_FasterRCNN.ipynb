{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip /home/jupyter-st124895/cv_project/04_experiments.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/cv_project\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 21 07:07:43 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:84:00.0 Off |                  N/A |\n",
      "| 48%   66C    P2             70W /  250W |     896MiB /  11264MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:85:00.0 Off |                  N/A |\n",
      "| 25%   41C    P8             19W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:88:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8              6W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:89:00.0 Off |                  N/A |\n",
      "| 25%   45C    P2             54W /  250W |     426MiB /  11264MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   3312933      C   /opt/tljh/user/bin/python                     558MiB |\n",
      "|    0   N/A  N/A   3318339      C   /opt/tljh/user/bin/python                      48MiB |\n",
      "|    0   N/A  N/A   3321707      C   /opt/tljh/user/bin/python                     286MiB |\n",
      "|    3   N/A  N/A   3324730      C   python                                        422MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgXaPROPYHNP",
    "outputId": "7155d924-73a6-4fb0-cb7f-bbf6f9dc1f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 21 07:07:43 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:84:00.0 Off |                  N/A |\n",
      "| 48%   66C    P2             70W /  250W |     896MiB /  11264MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:85:00.0 Off |                  N/A |\n",
      "| 25%   41C    P8             19W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:88:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8              6W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:89:00.0 Off |                  N/A |\n",
      "| 25%   45C    P2             54W /  250W |     426MiB /  11264MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   3312933      C   /opt/tljh/user/bin/python                     558MiB |\n",
      "|    0   N/A  N/A   3318339      C   /opt/tljh/user/bin/python                      48MiB |\n",
      "|    0   N/A  N/A   3321707      C   /opt/tljh/user/bin/python                     286MiB |\n",
      "|    3   N/A  N/A   3324730      C   python                                        422MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] PyTorch: 2.8.0+cu128\n",
      "[OK] Torchvision: 0.23.0+cu128\n",
      "[OK] CUDA available: True\n",
      "[OK] GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 1: Mount Google Drive & GPU Check\n",
    "# ==============================================================================\n",
    "\n",
    "# Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Check GPU\n",
    "import subprocess\n",
    "subprocess.run(['nvidia-smi'])\n",
    "\n",
    "# Install dependencies\n",
    "subprocess.run(['pip', 'install', 'torch', 'torchvision', 'pandas', 'matplotlib',\n",
    "                'seaborn', 'pycocotools', 'albumentations', '-q'])\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "print(f\"[OK] PyTorch: {torch.__version__}\")\n",
    "print(f\"[OK] Torchvision: {torchvision.__version__}\")\n",
    "print(f\"[OK] CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"[OK] GPU: {torch.cuda.get_device_name(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A1k2S35gYmD9"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 2: Dataset & Model Classes\n",
    "# ==============================================================================\n",
    "\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\n",
    "# For ResNet101 backbone\n",
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import cv2\n",
    "# import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "class COCODataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading COCO format annotations with Albumentations support.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, annotation_file, transforms=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: Path to images directory\n",
    "            annotation_file: Path to COCO JSON annotation file\n",
    "            transforms: Optional Albumentations transforms to apply\n",
    "        \"\"\"\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transforms = transforms\n",
    "\n",
    "        # Load COCO annotations\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "\n",
    "        # Create image id to annotations mapping\n",
    "        self.image_id_to_anns = {}\n",
    "        for ann in self.coco_data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.image_id_to_anns:\n",
    "                self.image_id_to_anns[img_id] = []\n",
    "            self.image_id_to_anns[img_id].append(ann)\n",
    "\n",
    "        # Get list of images\n",
    "        self.images = self.coco_data['images']\n",
    "\n",
    "        print(f\"[OK] Loaded {len(self.images)} images\")\n",
    "        print(f\"[OK] Loaded {len(self.coco_data['annotations'])} annotations\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image info\n",
    "        img_info = self.images[idx]\n",
    "        img_id = img_info['id']\n",
    "        img_path = self.root_dir / img_info['file_name']\n",
    "\n",
    "        # Load image as numpy array (for Albumentations)\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get annotations for this image\n",
    "        anns = self.image_id_to_anns.get(img_id, [])\n",
    "\n",
    "        # Prepare boxes and labels for Albumentations\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        areas = []\n",
    "\n",
    "        for ann in anns:\n",
    "            # COCO format: [x, y, width, height]\n",
    "            x, y, w, h = ann['bbox']\n",
    "            # Convert to [x1, y1, x2, y2] for Albumentations\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(ann['category_id'])\n",
    "            areas.append(ann['area'])\n",
    "\n",
    "        # Apply Albumentations transforms\n",
    "        if self.transforms and len(boxes) > 0:\n",
    "            try:\n",
    "                transformed = self.transforms(\n",
    "                    image=image,\n",
    "                    bboxes=boxes,\n",
    "                    labels=labels\n",
    "                )\n",
    "                image = transformed['image']\n",
    "                boxes = transformed['bboxes']\n",
    "                labels = transformed['labels']\n",
    "            except Exception as e:\n",
    "                # If transformation fails, use original data\n",
    "                print(f\"[WARNING] Transform failed for image {img_id}: {e}\")\n",
    "\n",
    "        # Always convert image to tensor at the end\n",
    "        if not isinstance(image, torch.Tensor):\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        # Convert to tensors\n",
    "        if len(boxes) > 0:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "            # Recalculate areas after transforms\n",
    "            if len(boxes) > 0:\n",
    "                areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "            else:\n",
    "                areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        else:\n",
    "            # Empty annotations\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "            areas = torch.zeros((0,), dtype=torch.float32)\n",
    "\n",
    "        image_id = torch.tensor([img_id])\n",
    "\n",
    "        # Create target dict\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = areas\n",
    "        target[\"iscrowd\"] = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "def get_train_transforms(config):\n",
    "    \"\"\"\n",
    "    Create training transforms with augmentation based on config.\n",
    "\n",
    "    Args:\n",
    "        config: Experiment configuration dict with augmentation parameters\n",
    "\n",
    "    Returns:\n",
    "        Albumentations Compose object\n",
    "    \"\"\"\n",
    "    transforms_list = []\n",
    "\n",
    "    # Color augmentation\n",
    "    if config.get('hsv_h', 0) > 0 or config.get('hsv_s', 0) > 0 or config.get('hsv_v', 0) > 0:\n",
    "        transforms_list.append(\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=int(config.get('hsv_h', 0) * 100),\n",
    "                sat_shift_limit=int(config.get('hsv_s', 0) * 100),\n",
    "                val_shift_limit=int(config.get('hsv_v', 0) * 100),\n",
    "                p=0.9\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Geometric augmentation\n",
    "    if config.get('degrees', 0) > 0 or config.get('translate', 0) > 0 or config.get('scale', 0) > 0:\n",
    "        transforms_list.append(\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=config.get('translate', 0.0),\n",
    "                scale_limit=config.get('scale', 0.0),\n",
    "                rotate_limit=config.get('degrees', 0),\n",
    "                border_mode=cv2.BORDER_CONSTANT,\n",
    "                p=0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Horizontal flip\n",
    "    if config.get('horizontal_flip', 0.0) > 0:\n",
    "        transforms_list.append(\n",
    "            A.HorizontalFlip(p=config.get('horizontal_flip', 0.0))\n",
    "        )\n",
    "\n",
    "    # Vertical flip\n",
    "    if config.get('vertical_flip', 0.0) > 0:\n",
    "        transforms_list.append(\n",
    "            A.VerticalFlip(p=config.get('vertical_flip', 0.0))\n",
    "        )\n",
    "\n",
    "    # Blur\n",
    "    if config.get('blur', False):\n",
    "        transforms_list.append(\n",
    "            A.Blur(blur_limit=3, p=0.1)\n",
    "        )\n",
    "\n",
    "    # Brightness/Contrast\n",
    "    if config.get('brightness_contrast', False):\n",
    "        transforms_list.append(\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.2,\n",
    "                contrast_limit=0.2,\n",
    "                p=0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Create compose with bbox parameters\n",
    "    return A.Compose(\n",
    "        transforms_list,\n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',  # [x1, y1, x2, y2]\n",
    "            label_fields=['labels'],\n",
    "            min_visibility=0.3,  # Keep boxes with at least 30% visible\n",
    "            min_area=100.0  # Keep boxes with at least 100 pixels area\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def get_val_transforms():\n",
    "    \"\"\"\n",
    "    Create validation transforms (no augmentation, just normalization).\n",
    "\n",
    "    Returns:\n",
    "        Albumentations Compose object\n",
    "    \"\"\"\n",
    "    return A.Compose(\n",
    "        [],  # No augmentation for validation\n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def get_model(num_classes, backbone='resnet50', pretrained=True,\n",
    "              # Configurable architecture parameters (Opción A):\n",
    "              box_score_thresh=None,\n",
    "              box_nms_thresh=None,\n",
    "              box_detections_per_img=None,\n",
    "              rpn_fg_iou_thresh=None,\n",
    "              rpn_bg_iou_thresh=None,\n",
    "              box_positive_fraction=None):\n",
    "    \"\"\"\n",
    "    Create Faster R-CNN model with configurable architecture parameters.\n",
    "\n",
    "    Args:\n",
    "        num_classes: Number of classes (including background)\n",
    "        backbone: Backbone architecture ('resnet50' or 'resnet101')\n",
    "                 - resnet50: 41.3M params, faster training (~2-3 hrs for 110 epochs)\n",
    "                 - resnet101: 60.2M params, better accuracy (+2-5% expected), slower (~3-4 hrs)\n",
    "        pretrained: Whether to use pretrained weights (recommended: True)\n",
    "\n",
    "        # Configurable parameters (None = use torchvision defaults):\n",
    "        box_score_thresh: Minimum confidence for detection (default: 0.05)\n",
    "        box_nms_thresh: NMS IoU threshold (default: 0.5)\n",
    "        box_detections_per_img: Max detections per image (default: 100)\n",
    "        rpn_fg_iou_thresh: RPN foreground IoU threshold (default: 0.7)\n",
    "        rpn_bg_iou_thresh: RPN background IoU threshold (default: 0.3)\n",
    "        box_positive_fraction: Positive sample ratio in ROI head (default: 0.25)\n",
    "\n",
    "    Returns:\n",
    "        model: Faster R-CNN model\n",
    "\n",
    "    Example usage in experiments_config:\n",
    "        {\n",
    "            'name': 'resnet101_best_params',\n",
    "            'backbone': 'resnet101',  # Use more powerful backbone\n",
    "            'box_score_thresh': 0.10,\n",
    "            'box_positive_fraction': 0.30,\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Set defaults for configurable parameters (match torchvision defaults)\n",
    "    box_score_thresh = box_score_thresh if box_score_thresh is not None else 0.05\n",
    "    box_nms_thresh = box_nms_thresh if box_nms_thresh is not None else 0.5\n",
    "    box_detections_per_img = box_detections_per_img if box_detections_per_img is not None else 100\n",
    "    rpn_fg_iou_thresh = rpn_fg_iou_thresh if rpn_fg_iou_thresh is not None else 0.7\n",
    "    rpn_bg_iou_thresh = rpn_bg_iou_thresh if rpn_bg_iou_thresh is not None else 0.3\n",
    "    box_positive_fraction = box_positive_fraction if box_positive_fraction is not None else 0.25\n",
    "\n",
    "    # Load pretrained model based on backbone choice\n",
    "    if backbone == 'resnet50':\n",
    "        if pretrained:\n",
    "            model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "        else:\n",
    "            model = fasterrcnn_resnet50_fpn(weights=None)\n",
    "\n",
    "    elif backbone == 'resnet101':\n",
    "        # Create ResNet101 backbone with FPN\n",
    "        backbone_model = resnet_fpn_backbone(\n",
    "            backbone_name='resnet101',\n",
    "            weights=ResNet101_Weights.DEFAULT if pretrained else None,\n",
    "            trainable_layers=5\n",
    "        )\n",
    "\n",
    "        # Create anchor generator (same as default FasterRCNN)\n",
    "        anchor_generator = AnchorGenerator(\n",
    "            sizes=((32,), (64,), (128,), (256,), (512,)),\n",
    "            aspect_ratios=((0.5, 1.0, 2.0),) * 5\n",
    "        )\n",
    "\n",
    "        # Create ROI pooler (same config as default)\n",
    "        roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "            featmap_names=['0', '1', '2', '3'],\n",
    "            output_size=7,\n",
    "            sampling_ratio=2\n",
    "        )\n",
    "\n",
    "        # Create Faster R-CNN model with ResNet101 backbone\n",
    "        model = FasterRCNN(\n",
    "            backbone_model,\n",
    "            num_classes=91,  # Will be replaced below\n",
    "            rpn_anchor_generator=anchor_generator,\n",
    "            box_roi_pool=roi_pooler\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Backbone {backbone} not supported. Use 'resnet50' or 'resnet101'\")\n",
    "\n",
    "    # Replace the classifier head\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # Apply configurable parameters to the model\n",
    "    model.roi_heads.score_thresh = box_score_thresh\n",
    "    model.roi_heads.nms_thresh = box_nms_thresh\n",
    "    model.roi_heads.detections_per_img = box_detections_per_img\n",
    "    model.roi_heads.fg_iou_thresh = rpn_fg_iou_thresh\n",
    "    model.roi_heads.bg_iou_thresh = rpn_bg_iou_thresh\n",
    "    model.roi_heads.positive_fraction = box_positive_fraction\n",
    "\n",
    "    # Also update RPN thresholds\n",
    "    model.rpn.fg_iou_thresh = rpn_fg_iou_thresh\n",
    "    model.rpn.bg_iou_thresh = rpn_bg_iou_thresh\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8eN3TzyTYsNH"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 3: ExperimentTrainer Class\n",
    "# ==============================================================================\n",
    "\n",
    "class FasterRCNNTrainer:\n",
    "    \"\"\"\n",
    "    Manages Faster R-CNN training experiments with automatic logging and tracking.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, experiment_name: str, model_family_dir: str = '02_faster_rcnn'):\n",
    "        \"\"\"\n",
    "        Initialize experiment trainer.\n",
    "\n",
    "        Args:\n",
    "            experiment_name: Name for this experiment\n",
    "            model_family_dir: Directory name for model family (e.g., '02_faster_rcnn')\n",
    "        \"\"\"\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model_family_dir = Path(EXPERIMENTS_PATH) / model_family_dir\n",
    "        self.model_family_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Auto-increment experiment ID\n",
    "        self.experiment_id = self._get_next_experiment_id()\n",
    "        self.experiment_dir = self.model_family_dir / self.experiment_id\n",
    "        self.experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Create subdirectories\n",
    "        self.weights_dir = self.experiment_dir / 'weights'\n",
    "        self.plots_dir = self.experiment_dir / 'plots'\n",
    "        self.weights_dir.mkdir(exist_ok=True)\n",
    "        self.plots_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"  EXPERIMENT: {self.experiment_id}\")\n",
    "        print(f\"  Family: {model_family_dir}\")\n",
    "        print(f\"  Directory: {self.experiment_dir}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "    def _get_next_experiment_id(self) -> str:\n",
    "        \"\"\"Auto-increment experiment number\"\"\"\n",
    "        existing_experiments = list(self.model_family_dir.glob('exp_*'))\n",
    "\n",
    "        if not existing_experiments:\n",
    "            exp_num = 1\n",
    "        else:\n",
    "            numbers = []\n",
    "            for exp_path in existing_experiments:\n",
    "                try:\n",
    "                    num_str = exp_path.name.split('_')[1]\n",
    "                    numbers.append(int(num_str))\n",
    "                except (IndexError, ValueError):\n",
    "                    continue\n",
    "\n",
    "            exp_num = max(numbers) + 1 if numbers else 1\n",
    "\n",
    "        return f\"exp_{exp_num:03d}_{self.experiment_name}\"\n",
    "\n",
    "    def _get_dataset_info(self, train_ann_file: str, val_ann_file: str) -> Dict:\n",
    "        \"\"\"Extract dataset information from COCO JSON files\"\"\"\n",
    "        dataset_info = {\n",
    "            'num_train_images': 0,\n",
    "            'num_val_images': 0,\n",
    "            'num_train_boxes': 0,\n",
    "            'num_val_boxes': 0\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Load train annotations\n",
    "            with open(train_ann_file, 'r') as f:\n",
    "                train_data = json.load(f)\n",
    "            dataset_info['num_train_images'] = len(train_data['images'])\n",
    "            dataset_info['num_train_boxes'] = len(train_data['annotations'])\n",
    "\n",
    "            # Load val annotations\n",
    "            with open(val_ann_file, 'r') as f:\n",
    "                val_data = json.load(f)\n",
    "            dataset_info['num_val_images'] = len(val_data['images'])\n",
    "            dataset_info['num_val_boxes'] = len(val_data['annotations'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Could not extract dataset info: {e}\")\n",
    "\n",
    "        return dataset_info\n",
    "\n",
    "    def train(self, train_loader, val_loader, model, optimizer, lr_scheduler,\n",
    "              num_epochs, device, config):\n",
    "        \"\"\"\n",
    "        Train Faster R-CNN model.\n",
    "\n",
    "        Args:\n",
    "            train_loader: Training data loader\n",
    "            val_loader: Validation data loader\n",
    "            model: Faster R-CNN model\n",
    "            optimizer: Optimizer\n",
    "            lr_scheduler: Learning rate scheduler\n",
    "            num_epochs: Number of epochs\n",
    "            device: Device to train on\n",
    "            config: Experiment configuration dict\n",
    "        \"\"\"\n",
    "        print(f\"[INFO] Starting training for {num_epochs} epochs...\")\n",
    "        print(f\"[INFO] Device: {device}\")\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        # Training history\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'learning_rate': []\n",
    "        }\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_epoch = 0\n",
    "        patience_counter = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_start = time.time()\n",
    "\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            print(f\"\\n[EPOCH {epoch+1}/{num_epochs}]\")\n",
    "\n",
    "            for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "                # Move to device\n",
    "                images = [img.to(device) for img in images]\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "                # Forward pass\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += losses.item()\n",
    "\n",
    "                if (batch_idx + 1) % 10 == 0:\n",
    "                    print(f\"  Batch [{batch_idx+1}/{len(train_loader)}] - Loss: {losses.item():.4f}\")\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            # Validation phase\n",
    "            # Note: Faster R-CNN requires training mode to compute losses\n",
    "            # but we use no_grad() to prevent gradient computation\n",
    "            model.train()  # Keep in train mode to get loss_dict\n",
    "            val_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, targets in val_loader:\n",
    "                    images = [img.to(device) for img in images]\n",
    "                    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "                    # Forward pass - model returns loss_dict when in train mode\n",
    "                    loss_dict = model(images, targets)\n",
    "                    losses = sum(loss for loss in loss_dict.values())\n",
    "                    val_loss += losses.item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            history['val_loss'].append(val_loss)\n",
    "\n",
    "            epoch_time = time.time() - epoch_start\n",
    "\n",
    "            print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"  Time: {epoch_time:.2f}s\")\n",
    "\n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), self.weights_dir / 'best.pt')\n",
    "                print(f\"  ✓ Best model saved (val_loss: {val_loss:.4f})\")\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            # Save last model\n",
    "            torch.save(model.state_dict(), self.weights_dir / 'last.pt')\n",
    "\n",
    "            # Step learning rate scheduler\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            # Early stopping\n",
    "            if config.get('patience', 0) > 0 and patience_counter >= config['patience']:\n",
    "                print(f\"\\n[EARLY STOPPING] No improvement for {config['patience']} epochs\")\n",
    "                break\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        self.training_time = total_time  # Save as instance attribute for later use\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"  TRAINING COMPLETED\")\n",
    "        print(f\"  Best Epoch: {best_epoch}\")\n",
    "        print(f\"  Best Val Loss: {best_val_loss:.4f}\")\n",
    "        print(f\"  Total Time: {total_time/60:.2f} minutes\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "        # Save training history\n",
    "        self._save_history(history, best_epoch, total_time, config)\n",
    "\n",
    "        return history, best_val_loss, best_epoch\n",
    "\n",
    "    def _save_history(self, history, best_epoch, training_time, config):\n",
    "        \"\"\"Save training history and plots with unified style\"\"\"\n",
    "        # Unified plot configuration (matching YOLOv8)\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 10))\n",
    "\n",
    "        # Add suptitle\n",
    "        fig.suptitle(f'Training Results - {self.experiment_id}',\n",
    "                     fontsize=16, fontweight='bold')\n",
    "\n",
    "        # Loss plot (using YOLOv8 color scheme)\n",
    "        axes[0].plot(history['train_loss'], label='Train Loss',\n",
    "                     linewidth=2, color='#3498db')  # Blue\n",
    "        axes[0].plot(history['val_loss'], label='Val Loss',\n",
    "                     linewidth=2, color='#e74c3c')  # Red\n",
    "        axes[0].axvline(x=best_epoch-1, color='#e74c3c', linestyle='--',\n",
    "                       label=f'Best Epoch ({best_epoch})')\n",
    "        axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[0].set_ylabel('Loss', fontsize=12)\n",
    "        axes[0].set_title('Training & Validation Loss', fontsize=14)\n",
    "        axes[0].legend(fontsize=10)\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "        # Learning rate plot (using YOLOv8 color scheme)\n",
    "        axes[1].plot(history['learning_rate'], linewidth=2,\n",
    "                     color='#16a085')  # Teal\n",
    "        axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[1].set_ylabel('Learning Rate', fontsize=12)\n",
    "        axes[1].set_title('Learning Rate Schedule', fontsize=14)\n",
    "        axes[1].set_yscale('log')  # Log scale for LR\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])  # Leave space for suptitle\n",
    "        plt.savefig(self.plots_dir / 'training_history.png',\n",
    "                    dpi=300, bbox_inches='tight')  # High DPI\n",
    "        plt.close()\n",
    "\n",
    "        # Save experiment log (with history for plots)\n",
    "        log = {\n",
    "            'experiment_id': self.experiment_id,\n",
    "            'experiment_name': self.experiment_name,\n",
    "            'best_epoch': best_epoch,\n",
    "            'best_val_loss': history['val_loss'][best_epoch-1],\n",
    "            'final_train_loss': history['train_loss'][-1],\n",
    "            'final_val_loss': history['val_loss'][-1],\n",
    "            'training_time_minutes': training_time / 60,\n",
    "            'config': config,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            # Add history for comprehensive plots in SECTION 6\n",
    "            'train_loss': history['train_loss'],\n",
    "            'val_loss': history['val_loss'],\n",
    "            'learning_rate': history['learning_rate']\n",
    "        }\n",
    "\n",
    "        with open(self.experiment_dir / 'experiment_log.json', 'w') as f:\n",
    "            json.dump(log, f, indent=2)\n",
    "\n",
    "        print(f\"[OK] Training history saved to {self.plots_dir}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Evaluation Functions (COCO Metrics)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import tempfile\n",
    "\n",
    "def evaluate_model_coco(model, data_loader, device, ann_file):\n",
    "    \"\"\"\n",
    "    Evaluate Faster R-CNN model using COCO metrics.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Faster R-CNN model\n",
    "        data_loader: DataLoader for evaluation\n",
    "        device: Device to run evaluation on\n",
    "        ann_file: Path to COCO annotation file\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with mAP metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Collect all predictions\n",
    "    coco_results = []\n",
    "\n",
    "    print(\"[INFO] Running inference for COCO evaluation...\")\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            predictions = model(images)\n",
    "\n",
    "            # Convert predictions to COCO format\n",
    "            for pred, target in zip(predictions, targets):\n",
    "                image_id = target['image_id'].item()\n",
    "                boxes = pred['boxes'].cpu().numpy()\n",
    "                scores = pred['scores'].cpu().numpy()\n",
    "                labels = pred['labels'].cpu().numpy()\n",
    "\n",
    "                # Convert boxes from [x1, y1, x2, y2] to COCO format [x, y, w, h]\n",
    "                for box, score, label in zip(boxes, scores, labels):\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    coco_results.append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': int(label),\n",
    "                        'bbox': [float(x1), float(y1), float(x2 - x1), float(y2 - y1)],\n",
    "                        'score': float(score)\n",
    "                    })\n",
    "\n",
    "    print(f\"[OK] Generated {len(coco_results)} predictions\")\n",
    "\n",
    "    # Load COCO ground truth and evaluate\n",
    "    coco_gt = COCO(str(ann_file))\n",
    "\n",
    "    # Save predictions to temporary file\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:\n",
    "        json.dump(coco_results, f)\n",
    "        results_file = f.name\n",
    "\n",
    "    coco_dt = coco_gt.loadRes(results_file)\n",
    "\n",
    "    # Run COCO evaluation\n",
    "    print(\"\\n[INFO] Running COCO evaluation...\")\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    # Extract metrics\n",
    "    metrics = {\n",
    "        'mAP_50_95': coco_eval.stats[0],\n",
    "        'mAP_50': coco_eval.stats[1],\n",
    "        'mAP_75': coco_eval.stats[2],\n",
    "        'precision': coco_eval.stats[1],  # Use mAP@50 as precision proxy\n",
    "        'recall': coco_eval.stats[8],     # Use AR@100 as recall proxy\n",
    "        'f1_score': 2 * (coco_eval.stats[1] * coco_eval.stats[8]) / (coco_eval.stats[1] + coco_eval.stats[8] + 1e-6)\n",
    "    }\n",
    "\n",
    "    # Measure inference time\n",
    "    print(\"\\n[INFO] Measuring inference time...\")\n",
    "    import time\n",
    "    inference_times = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Warm-up\n",
    "        for images, _ in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            _ = model(images)\n",
    "            break\n",
    "\n",
    "        # Measure\n",
    "        for images, _ in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            start = time.time()\n",
    "            _ = model(images)\n",
    "            end = time.time()\n",
    "            inference_times.append((end - start) * 1000 / len(images))  # ms per image\n",
    "\n",
    "    metrics['inference_time_ms'] = sum(inference_times) / len(inference_times) if inference_times else 0.0\n",
    "\n",
    "    # Calculate total parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    metrics['total_params_M'] = total_params / 1e6\n",
    "\n",
    "    print(f\"[OK] Inference time: {metrics['inference_time_ms']:.2f} ms/image\")\n",
    "    print(f\"[OK] Total parameters: {metrics['total_params_M']:.2f}M\")\n",
    "\n",
    "    # Clean up\n",
    "    import os\n",
    "    os.unlink(results_file)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def save_metrics_to_csv(experiment_dir, experiment_id, experiment_name, config,\n",
    "                        metrics, dataset_info, training_time, best_epoch):\n",
    "    \"\"\"Save experiment metrics to CSV files (master + family).\"\"\"\n",
    "\n",
    "    # Prepare row data (aligned with YOLOv8 format)\n",
    "    row_data = {\n",
    "        'experiment_id': experiment_id,\n",
    "        'experiment_name': experiment_name,  # Renamed from 'name' for consistency\n",
    "        'model_family': '02_faster_rcnn',\n",
    "        'model_variant': config.get('backbone', 'resnet50'),  # Renamed from 'backbone'\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'dataset_version': 'v1',  # Added for consistency\n",
    "        'num_train_images': dataset_info.get('num_train_images', 0),\n",
    "        'num_val_images': dataset_info.get('num_val_images', 0),\n",
    "        'num_train_boxes': dataset_info.get('num_train_boxes', 0),\n",
    "        'num_val_boxes': dataset_info.get('num_val_boxes', 0),\n",
    "        'num_epochs': config.get('num_epochs', 50),\n",
    "        'batch_size': config.get('batch_size', 4),\n",
    "        'img_size': 800,  # Faster R-CNN default input size\n",
    "        'mAP_50': metrics.get('mAP_50', 0.0),\n",
    "        'mAP_50_95': metrics.get('mAP_50_95', 0.0),\n",
    "        'mAP_75': metrics.get('mAP_75', 0.0),\n",
    "        'precision': metrics.get('precision', 0.0),\n",
    "        'recall': metrics.get('recall', 0.0),\n",
    "        'f1_score': metrics.get('f1_score', 0.0),\n",
    "        'best_epoch': best_epoch,  # Added for tracking\n",
    "        'inference_time_ms': metrics.get('inference_time_ms', 0.0),  # Added\n",
    "        'training_time_hours': training_time / 3600,  # Changed from minutes to hours\n",
    "        'total_params_M': metrics.get('total_params_M', 0.0),  # Added\n",
    "        # Hyperparameters (extra info for Faster R-CNN)\n",
    "        'pretrained': config.get('pretrained', True),\n",
    "        'learning_rate': config.get('learning_rate', 0.005),\n",
    "        'momentum': config.get('momentum', 0.9),\n",
    "        'weight_decay': config.get('weight_decay', 0.0005),\n",
    "        'step_size': config.get('step_size', 10),\n",
    "        'gamma': config.get('gamma', 0.1),\n",
    "        'patience': config.get('patience', 10),\n",
    "        # Augmentation params\n",
    "        'hsv_h': config.get('hsv_h', 0.0),\n",
    "        'hsv_s': config.get('hsv_s', 0.0),\n",
    "        'hsv_v': config.get('hsv_v', 0.0),\n",
    "        'degrees': config.get('degrees', 0.0),\n",
    "        'translate': config.get('translate', 0.0),\n",
    "        'scale': config.get('scale', 0.0),\n",
    "        'horizontal_flip': config.get('horizontal_flip', 0.0),\n",
    "        'vertical_flip': config.get('vertical_flip', 0.0),\n",
    "        'blur': config.get('blur', False),\n",
    "        'brightness_contrast': config.get('brightness_contrast', False),\n",
    "        # Architecture params (Opción A)\n",
    "        'box_score_thresh': config.get('box_score_thresh', 0.05),\n",
    "        'box_nms_thresh': config.get('box_nms_thresh', 0.5),\n",
    "        'box_detections_per_img': config.get('box_detections_per_img', 100),\n",
    "        'rpn_fg_iou_thresh': config.get('rpn_fg_iou_thresh', 0.7),\n",
    "        'rpn_bg_iou_thresh': config.get('rpn_bg_iou_thresh', 0.3),\n",
    "        'box_positive_fraction': config.get('box_positive_fraction', 0.25)\n",
    "    }\n",
    "\n",
    "    # Save to family CSV\n",
    "    family_csv = Path(EXPERIMENTS_PATH) / '02_faster_rcnn' / '02_faster_rcnn_experiments.csv'\n",
    "    df_row = pd.DataFrame([row_data])\n",
    "\n",
    "    if family_csv.exists():\n",
    "        df_existing = pd.read_csv(family_csv)\n",
    "        df_combined = pd.concat([df_existing, df_row], ignore_index=True)\n",
    "        df_combined.to_csv(family_csv, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(family_csv, index=False)\n",
    "\n",
    "    print(f\"[OK] Metrics saved to: {family_csv}\")\n",
    "\n",
    "    # Save to master CSV\n",
    "    master_csv = Path(EXPERIMENTS_PATH) / 'all_experiments_log.csv'\n",
    "\n",
    "    if master_csv.exists():\n",
    "        df_existing = pd.read_csv(master_csv)\n",
    "        df_combined = pd.concat([df_existing, df_row], ignore_index=True)\n",
    "        df_combined.to_csv(master_csv, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(master_csv, index=False)\n",
    "\n",
    "    print(f\"[OK] Metrics saved to: {master_csv}\")\n",
    "\n",
    "\n",
    "def update_best_model_tracker(experiment_id, experiment_name, metrics, config):\n",
    "    \"\"\"\n",
    "    Update best model JSON files (overall + family).\n",
    "\n",
    "    Uses mAP@0.5:0.95 as criterion (standard COCO metric), same as YOLOv8.\n",
    "    \"\"\"\n",
    "\n",
    "    family_best = Path(EXPERIMENTS_PATH) / '02_faster_rcnn' / '02_faster_rcnn_best_model.json'\n",
    "\n",
    "    best_data = {\n",
    "        'experiment_id': experiment_id,\n",
    "        'experiment_name': experiment_name,\n",
    "        'mAP_50': metrics['mAP_50'],\n",
    "        'mAP_50_95': metrics['mAP_50_95'],\n",
    "        'config': config,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "    # Update family best (using mAP@0.5:0.95 as criterion)\n",
    "    update_family = True\n",
    "    if family_best.exists():\n",
    "        with open(family_best, 'r') as f:\n",
    "            current_best = json.load(f)\n",
    "        if current_best.get('mAP_50_95', 0.0) >= metrics['mAP_50_95']:\n",
    "            update_family = False\n",
    "\n",
    "    if update_family:\n",
    "        with open(family_best, 'w') as f:\n",
    "            json.dump(best_data, f, indent=2)\n",
    "        print(f\"[OK] Updated best model for 02_faster_rcnn: {experiment_id} (mAP@0.5:0.95 = {metrics['mAP_50_95']:.4f})\")\n",
    "\n",
    "    # Update overall best (using mAP@0.5:0.95 as criterion, same as YOLOv8)\n",
    "    overall_best = Path(EXPERIMENTS_PATH) / 'best_model_overall.json'\n",
    "\n",
    "    update_overall = True\n",
    "    if overall_best.exists():\n",
    "        with open(overall_best, 'r') as f:\n",
    "            current_best = json.load(f)\n",
    "        if current_best.get('mAP_50_95', 0.0) >= metrics['mAP_50_95']:\n",
    "            update_overall = False\n",
    "\n",
    "    if update_overall:\n",
    "        with open(overall_best, 'w') as f:\n",
    "            json.dump(best_data, f, indent=2)\n",
    "        print(f\"[OK] Updated overall best model: {experiment_id} (mAP@0.5:0.95 = {metrics['mAP_50_95']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dJMbU6CpZBAJ"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 4: Helper Functions for Evaluation & Plotting\n",
    "# ==============================================================================\n",
    "\n",
    "def create_comprehensive_plots(experiment_dir, history, metrics, best_epoch, experiment_id):\n",
    "    \"\"\"\n",
    "    Create comprehensive training plots (6 subplots like YOLOv8).\n",
    "\n",
    "    Args:\n",
    "        experiment_dir: Path to experiment directory\n",
    "        history: Training history dict\n",
    "        metrics: Evaluation metrics dict\n",
    "        best_epoch: Best epoch number\n",
    "        experiment_id: Experiment ID string\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Suptitle\n",
    "    fig.suptitle(f'Comprehensive Training Results - {experiment_id}',\n",
    "                 fontsize=16, fontweight='bold')\n",
    "\n",
    "    # 1. Loss curves\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    axes[0].plot(epochs, history['train_loss'], label='Train Loss',\n",
    "                 linewidth=2, color='#3498db')\n",
    "    axes[0].plot(epochs, history['val_loss'], label='Val Loss',\n",
    "                 linewidth=2, color='#e74c3c')\n",
    "    axes[0].axvline(x=best_epoch, color='#e74c3c', linestyle='--',\n",
    "                   label=f'Best Epoch ({best_epoch})', alpha=0.7)\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].set_title('Training & Validation Loss', fontsize=14)\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. mAP metrics (final values as bars)\n",
    "    map_metrics = ['mAP@0.5', 'mAP@0.5:0.95', 'mAP@0.75']\n",
    "    map_values = [metrics.get('mAP_50', 0), metrics.get('mAP_50_95', 0),\n",
    "                  metrics.get('mAP_75', 0)]\n",
    "    colors_map = ['#2ecc71', '#3498db', '#9b59b6']\n",
    "    axes[1].bar(map_metrics, map_values, color=colors_map, alpha=0.8, edgecolor='black')\n",
    "    axes[1].set_ylabel('Score', fontsize=12)\n",
    "    axes[1].set_title('mAP Metrics', fontsize=14)\n",
    "    axes[1].set_ylim([0, 1])\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(map_values):\n",
    "        axes[1].text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # 3. Precision & Recall\n",
    "    pr_metrics = ['Precision', 'Recall']\n",
    "    pr_values = [metrics.get('precision', 0), metrics.get('recall', 0)]\n",
    "    colors_pr = ['#e74c3c', '#9b59b6']\n",
    "    axes[2].bar(pr_metrics, pr_values, color=colors_pr, alpha=0.8, edgecolor='black')\n",
    "    axes[2].set_ylabel('Score', fontsize=12)\n",
    "    axes[2].set_title('Precision & Recall', fontsize=14)\n",
    "    axes[2].set_ylim([0, 1])\n",
    "    axes[2].grid(True, alpha=0.3, axis='y')\n",
    "    for i, v in enumerate(pr_values):\n",
    "        axes[2].text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # 4. F1-Score\n",
    "    f1_score = metrics.get('f1_score', 0)\n",
    "    axes[3].bar(['F1-Score'], [f1_score], color='#f39c12', alpha=0.8, edgecolor='black')\n",
    "    axes[3].set_ylabel('Score', fontsize=12)\n",
    "    axes[3].set_title('F1-Score', fontsize=14)\n",
    "    axes[3].set_ylim([0, 1])\n",
    "    axes[3].grid(True, alpha=0.3, axis='y')\n",
    "    axes[3].text(0, f1_score + 0.02, f'{f1_score:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # 5. Learning Rate Schedule\n",
    "    axes[4].plot(epochs, history['learning_rate'], linewidth=2, color='#16a085')\n",
    "    axes[4].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[4].set_ylabel('Learning Rate', fontsize=12)\n",
    "    axes[4].set_title('Learning Rate Schedule', fontsize=14)\n",
    "    axes[4].set_yscale('log')\n",
    "    axes[4].grid(True, alpha=0.3)\n",
    "\n",
    "    # 6. Summary text\n",
    "    axes[5].axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "EXPERIMENT SUMMARY\n",
    "{'='*35}\n",
    "\n",
    "Model Family: Faster R-CNN\n",
    "Best Epoch: {best_epoch}\n",
    "Best Val Loss: {min(history['val_loss']):.4f}\n",
    "\n",
    "METRICS\n",
    "{'='*35}\n",
    "mAP@0.5:      {metrics.get('mAP_50', 0):.4f}\n",
    "mAP@0.5:0.95: {metrics.get('mAP_50_95', 0):.4f}\n",
    "mAP@0.75:     {metrics.get('mAP_75', 0):.4f}\n",
    "Precision:    {metrics.get('precision', 0):.4f}\n",
    "Recall:       {metrics.get('recall', 0):.4f}\n",
    "F1-Score:     {metrics.get('f1_score', 0):.4f}\n",
    "\n",
    "PERFORMANCE\n",
    "{'='*35}\n",
    "Inference:    {metrics.get('inference_time_ms', 0):.2f} ms/img\n",
    "Parameters:   {metrics.get('total_params_M', 0):.2f}M\n",
    "\"\"\"\n",
    "    axes[5].text(0.1, 0.5, summary_text, fontsize=11, family='monospace',\n",
    "                verticalalignment='center', bbox=dict(boxstyle='round',\n",
    "                facecolor='wheat', alpha=0.3))\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "    # Create plots directory if it doesn't exist\n",
    "    plots_dir = experiment_dir / 'plots'\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plt.savefig(plots_dir / 'comprehensive_results.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"[OK] Comprehensive plots saved to: {plots_dir / 'comprehensive_results.png'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/cv_project\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49E7Gg2dZWuZ",
    "outputId": "81401bfc-27b7-4f3c-92d1-48cbed0fc496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset verification:\n",
      "  Train images: True - /home/jupyter-st124895/cv_project/03_datasets/oil_palm_coco_v2/train\n",
      "  Val images: True - /home/jupyter-st124895/cv_project/03_datasets/oil_palm_coco_v2/valid\n",
      "  Train annotations: True - /home/jupyter-st124895/cv_project/03_datasets/oil_palm_coco_v2/train/_annotations.coco.json\n",
      "  Val annotations: True - /home/jupyter-st124895/cv_project/03_datasets/oil_palm_coco_v2/valid/_annotations.coco.json\n",
      "\n",
      "[OK] Dataset ready!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 5: Dataset Paths & Configuration\n",
    "# ==============================================================================\n",
    "\n",
    "# Google Drive paths\n",
    "# EXPERIMENTS_PATH = '/content/drive/MyDrive/cv_project/04_experiments'\n",
    "# DATASET_PATH = '/content/drive/MyDrive/cv_project/03_datasets/oil_palm_coco_v1'\n",
    "# Puffer Paths\n",
    "EXPERIMENTS_PATH = '/home/jupyter-st124895/cv_project/04_experiments'\n",
    "DATASET_PATH =     '/home/jupyter-st124895/cv_project/03_datasets/oil_palm_coco_v2'\n",
    "\n",
    "# Create experiments directory\n",
    "Path(EXPERIMENTS_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Verify dataset paths\n",
    "dataset_path = Path(DATASET_PATH)\n",
    "train_images_dir = dataset_path / 'train'\n",
    "val_images_dir = dataset_path / 'valid'\n",
    "# train_ann_file = dataset_path / 'annotations' / 'instances_train.json'\n",
    "# val_ann_file = dataset_path / 'annotations' / 'instances_val.json'\n",
    "\n",
    "train_ann_file = dataset_path / 'train' / '_annotations.coco.json'\n",
    "val_ann_file = dataset_path / 'valid' /  '_annotations.coco.json'\n",
    "\n",
    "\n",
    "print(f\"[INFO] Dataset verification:\")\n",
    "print(f\"  Train images: {train_images_dir.exists()} - {train_images_dir}\")\n",
    "print(f\"  Val images: {val_images_dir.exists()} - {val_images_dir}\")\n",
    "print(f\"  Train annotations: {train_ann_file.exists()} - {train_ann_file}\")\n",
    "print(f\"  Val annotations: {val_ann_file.exists()} - {val_ann_file}\")\n",
    "\n",
    "if not all([train_images_dir.exists(), val_images_dir.exists(),\n",
    "            train_ann_file.exists(), val_ann_file.exists()]):\n",
    "    print(\"\\n[ERROR] Dataset not found! Please upload dataset to Google Drive.\")\n",
    "else:\n",
    "    print(\"\\n[OK] Dataset ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "DnT3c-fQ2Ydo",
    "outputId": "f693f0e6-f7fc-4aa3-b83f-25a0dd330d6c",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Using device: cuda\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: resnet101_baseline\n",
      "  ResNet101 con configuración baseline para comparación\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_074_resnet101_baseline\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_074_resnet101_baseline\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded 306 images\n",
      "[OK] Loaded 39465 annotations\n",
      "[OK] Loaded 153 images\n",
      "[OK] Loaded 19666 annotations\n",
      "[INFO] Starting training for 110 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/110]\n",
      "  Batch [10/77] - Loss: 1.5123\n",
      "  Batch [20/77] - Loss: 1.1444\n",
      "  Batch [30/77] - Loss: 1.0704\n",
      "  Batch [40/77] - Loss: 0.8621\n",
      "  Batch [50/77] - Loss: 0.7592\n",
      "  Batch [60/77] - Loss: 0.6721\n",
      "  Batch [70/77] - Loss: 0.6700\n",
      "  Train Loss: 1.0183\n",
      "  Val Loss: 0.6762\n",
      "  Time: 51.60s\n",
      "  ✓ Best model saved (val_loss: 0.6762)\n",
      "\n",
      "[EPOCH 2/110]\n",
      "  Batch [10/77] - Loss: 0.6456\n",
      "  Batch [20/77] - Loss: 0.5969\n",
      "  Batch [30/77] - Loss: 0.6148\n",
      "  Batch [40/77] - Loss: 0.6458\n",
      "  Batch [50/77] - Loss: 0.6389\n",
      "  Batch [60/77] - Loss: 0.7468\n",
      "  Batch [70/77] - Loss: 0.6070\n",
      "  Train Loss: 0.6778\n",
      "  Val Loss: 0.6263\n",
      "  Time: 51.29s\n",
      "  ✓ Best model saved (val_loss: 0.6263)\n",
      "\n",
      "[EPOCH 3/110]\n",
      "  Batch [10/77] - Loss: 0.7109\n",
      "  Batch [20/77] - Loss: 0.6782\n",
      "  Batch [30/77] - Loss: 0.6019\n",
      "  Batch [40/77] - Loss: 0.5992\n",
      "  Batch [50/77] - Loss: 0.6959\n",
      "  Batch [60/77] - Loss: 0.6372\n",
      "  Batch [70/77] - Loss: 0.5276\n",
      "  Train Loss: 0.6382\n",
      "  Val Loss: 0.5903\n",
      "  Time: 50.71s\n",
      "  ✓ Best model saved (val_loss: 0.5903)\n",
      "\n",
      "[EPOCH 4/110]\n",
      "  Batch [10/77] - Loss: 0.5460\n",
      "  Batch [20/77] - Loss: 0.5978\n",
      "  Batch [30/77] - Loss: 0.5568\n",
      "  Batch [40/77] - Loss: 0.5193\n",
      "  Batch [50/77] - Loss: 0.5956\n",
      "  Batch [60/77] - Loss: 0.5784\n",
      "  Batch [70/77] - Loss: 0.6184\n",
      "  Train Loss: 0.5838\n",
      "  Val Loss: 0.5180\n",
      "  Time: 50.47s\n",
      "  ✓ Best model saved (val_loss: 0.5180)\n",
      "\n",
      "[EPOCH 5/110]\n",
      "  Batch [10/77] - Loss: 0.5656\n",
      "  Batch [20/77] - Loss: 0.5854\n",
      "  Batch [30/77] - Loss: 0.4773\n",
      "  Batch [40/77] - Loss: 0.5645\n",
      "  Batch [50/77] - Loss: 0.5273\n",
      "  Batch [60/77] - Loss: 0.4973\n",
      "  Batch [70/77] - Loss: 0.5120\n",
      "  Train Loss: 0.5370\n",
      "  Val Loss: 0.5054\n",
      "  Time: 50.42s\n",
      "  ✓ Best model saved (val_loss: 0.5054)\n",
      "\n",
      "[EPOCH 6/110]\n",
      "  Batch [10/77] - Loss: 0.5482\n",
      "  Batch [20/77] - Loss: 0.4908\n",
      "  Batch [30/77] - Loss: 0.4843\n",
      "  Batch [40/77] - Loss: 0.4972\n",
      "  Batch [50/77] - Loss: 0.4900\n",
      "  Batch [60/77] - Loss: 0.5724\n",
      "  Batch [70/77] - Loss: 0.4947\n",
      "  Train Loss: 0.5236\n",
      "  Val Loss: 0.4783\n",
      "  Time: 50.54s\n",
      "  ✓ Best model saved (val_loss: 0.4783)\n",
      "\n",
      "[EPOCH 7/110]\n",
      "  Batch [10/77] - Loss: 0.4528\n",
      "  Batch [20/77] - Loss: 0.5098\n",
      "  Batch [30/77] - Loss: 0.5390\n",
      "  Batch [40/77] - Loss: 0.5466\n",
      "  Batch [50/77] - Loss: 0.5236\n",
      "  Batch [60/77] - Loss: 0.4680\n",
      "  Batch [70/77] - Loss: 0.4510\n",
      "  Train Loss: 0.4986\n",
      "  Val Loss: 0.4515\n",
      "  Time: 50.90s\n",
      "  ✓ Best model saved (val_loss: 0.4515)\n",
      "\n",
      "[EPOCH 8/110]\n",
      "  Batch [10/77] - Loss: 0.4708\n",
      "  Batch [20/77] - Loss: 0.4704\n",
      "  Batch [30/77] - Loss: 0.4332\n",
      "  Batch [40/77] - Loss: 0.4397\n",
      "  Batch [50/77] - Loss: 0.5250\n",
      "  Batch [60/77] - Loss: 0.5736\n",
      "  Batch [70/77] - Loss: 0.4942\n",
      "  Train Loss: 0.4827\n",
      "  Val Loss: 0.4274\n",
      "  Time: 50.82s\n",
      "  ✓ Best model saved (val_loss: 0.4274)\n",
      "\n",
      "[EPOCH 9/110]\n",
      "  Batch [10/77] - Loss: 0.5066\n",
      "  Batch [20/77] - Loss: 0.4634\n",
      "  Batch [30/77] - Loss: 0.4598\n",
      "  Batch [40/77] - Loss: 0.4323\n",
      "  Batch [50/77] - Loss: 0.4822\n",
      "  Batch [60/77] - Loss: 0.4637\n",
      "  Batch [70/77] - Loss: 0.4407\n",
      "  Train Loss: 0.4729\n",
      "  Val Loss: 0.4478\n",
      "  Time: 50.67s\n",
      "\n",
      "[EPOCH 10/110]\n",
      "  Batch [10/77] - Loss: 0.5141\n",
      "  Batch [20/77] - Loss: 0.4917\n",
      "  Batch [30/77] - Loss: 0.5409\n",
      "  Batch [40/77] - Loss: 0.4601\n",
      "  Batch [50/77] - Loss: 0.5083\n",
      "  Batch [60/77] - Loss: 0.4435\n",
      "  Batch [70/77] - Loss: 0.4603\n",
      "  Train Loss: 0.4711\n",
      "  Val Loss: 0.4502\n",
      "  Time: 50.84s\n",
      "\n",
      "[EPOCH 11/110]\n",
      "  Batch [10/77] - Loss: 0.4794\n",
      "  Batch [20/77] - Loss: 0.4862\n",
      "  Batch [30/77] - Loss: 0.4224\n",
      "  Batch [40/77] - Loss: 0.3942\n",
      "  Batch [50/77] - Loss: 0.3836\n",
      "  Batch [60/77] - Loss: 0.4454\n",
      "  Batch [70/77] - Loss: 0.4150\n",
      "  Train Loss: 0.4538\n",
      "  Val Loss: 0.4283\n",
      "  Time: 51.10s\n",
      "\n",
      "[EPOCH 12/110]\n",
      "  Batch [10/77] - Loss: 0.4623\n",
      "  Batch [20/77] - Loss: 0.4335\n",
      "  Batch [30/77] - Loss: 0.4580\n",
      "  Batch [40/77] - Loss: 0.4130\n",
      "  Batch [50/77] - Loss: 0.4165\n",
      "  Batch [60/77] - Loss: 0.4644\n",
      "  Batch [70/77] - Loss: 0.4654\n",
      "  Train Loss: 0.4474\n",
      "  Val Loss: 0.4351\n",
      "  Time: 51.10s\n",
      "\n",
      "[EPOCH 13/110]\n",
      "  Batch [10/77] - Loss: 0.4405\n",
      "  Batch [20/77] - Loss: 0.4762\n",
      "  Batch [30/77] - Loss: 0.3745\n",
      "  Batch [40/77] - Loss: 0.3920\n",
      "  Batch [50/77] - Loss: 0.3812\n",
      "  Batch [60/77] - Loss: 0.4838\n",
      "  Batch [70/77] - Loss: 0.4004\n",
      "  Train Loss: 0.4454\n",
      "  Val Loss: 0.4223\n",
      "  Time: 50.89s\n",
      "  ✓ Best model saved (val_loss: 0.4223)\n",
      "\n",
      "[EPOCH 14/110]\n",
      "  Batch [10/77] - Loss: 0.3879\n",
      "  Batch [20/77] - Loss: 0.4432\n",
      "  Batch [30/77] - Loss: 0.4609\n",
      "  Batch [40/77] - Loss: 0.4086\n",
      "  Batch [50/77] - Loss: 0.4475\n",
      "  Batch [60/77] - Loss: 0.4494\n",
      "  Batch [70/77] - Loss: 0.4819\n",
      "  Train Loss: 0.4347\n",
      "  Val Loss: 0.4274\n",
      "  Time: 51.03s\n",
      "\n",
      "[EPOCH 15/110]\n",
      "  Batch [10/77] - Loss: 0.4463\n",
      "  Batch [20/77] - Loss: 0.4633\n",
      "  Batch [30/77] - Loss: 0.4018\n",
      "  Batch [40/77] - Loss: 0.4421\n",
      "  Batch [50/77] - Loss: 0.4911\n",
      "  Batch [60/77] - Loss: 0.4413\n",
      "  Batch [70/77] - Loss: 0.4131\n",
      "  Train Loss: 0.4415\n",
      "  Val Loss: 0.4071\n",
      "  Time: 51.26s\n",
      "  ✓ Best model saved (val_loss: 0.4071)\n",
      "\n",
      "[EPOCH 16/110]\n",
      "  Batch [10/77] - Loss: 0.4113\n",
      "  Batch [20/77] - Loss: 0.4332\n",
      "  Batch [30/77] - Loss: 0.3969\n",
      "  Batch [40/77] - Loss: 0.4842\n",
      "  Batch [50/77] - Loss: 0.3963\n",
      "  Batch [60/77] - Loss: 0.4367\n",
      "  Batch [70/77] - Loss: 0.4540\n",
      "  Train Loss: 0.4305\n",
      "  Val Loss: 0.3993\n",
      "  Time: 51.26s\n",
      "  ✓ Best model saved (val_loss: 0.3993)\n",
      "\n",
      "[EPOCH 17/110]\n",
      "  Batch [10/77] - Loss: 0.4623\n",
      "  Batch [20/77] - Loss: 0.4340\n",
      "  Batch [30/77] - Loss: 0.4194\n",
      "  Batch [40/77] - Loss: 0.3871\n",
      "  Batch [50/77] - Loss: 0.4902\n",
      "  Batch [60/77] - Loss: 0.4290\n",
      "  Batch [70/77] - Loss: 0.4100\n",
      "  Train Loss: 0.4321\n",
      "  Val Loss: 0.4069\n",
      "  Time: 50.75s\n",
      "\n",
      "[EPOCH 18/110]\n",
      "  Batch [10/77] - Loss: 0.3823\n",
      "  Batch [20/77] - Loss: 0.4330\n",
      "  Batch [30/77] - Loss: 0.3854\n",
      "  Batch [40/77] - Loss: 0.4132\n",
      "  Batch [50/77] - Loss: 0.4306\n",
      "  Batch [60/77] - Loss: 0.4498\n",
      "  Batch [70/77] - Loss: 0.4073\n",
      "  Train Loss: 0.4224\n",
      "  Val Loss: 0.4153\n",
      "  Time: 51.18s\n",
      "\n",
      "[EPOCH 19/110]\n",
      "  Batch [10/77] - Loss: 0.4092\n",
      "  Batch [20/77] - Loss: 0.3948\n",
      "  Batch [30/77] - Loss: 0.3607\n",
      "  Batch [40/77] - Loss: 0.3979\n",
      "  Batch [50/77] - Loss: 0.3381\n",
      "  Batch [60/77] - Loss: 0.5128\n",
      "  Batch [70/77] - Loss: 0.4255\n",
      "  Train Loss: 0.4068\n",
      "  Val Loss: 0.3905\n",
      "  Time: 50.67s\n",
      "  ✓ Best model saved (val_loss: 0.3905)\n",
      "\n",
      "[EPOCH 20/110]\n",
      "  Batch [10/77] - Loss: 0.4221\n",
      "  Batch [20/77] - Loss: 0.4470\n",
      "  Batch [30/77] - Loss: 0.3618\n",
      "  Batch [40/77] - Loss: 0.4068\n",
      "  Batch [50/77] - Loss: 0.3926\n",
      "  Batch [60/77] - Loss: 0.4443\n",
      "  Batch [70/77] - Loss: 0.4065\n",
      "  Train Loss: 0.4189\n",
      "  Val Loss: 0.4081\n",
      "  Time: 51.09s\n",
      "\n",
      "[EPOCH 21/110]\n",
      "  Batch [10/77] - Loss: 0.4165\n",
      "  Batch [20/77] - Loss: 0.3636\n",
      "  Batch [30/77] - Loss: 0.4248\n",
      "  Batch [40/77] - Loss: 0.4065\n",
      "  Batch [50/77] - Loss: 0.3475\n",
      "  Batch [60/77] - Loss: 0.3806\n",
      "  Batch [70/77] - Loss: 0.4096\n",
      "  Train Loss: 0.3928\n",
      "  Val Loss: 0.3758\n",
      "  Time: 51.04s\n",
      "  ✓ Best model saved (val_loss: 0.3758)\n",
      "\n",
      "[EPOCH 22/110]\n",
      "  Batch [10/77] - Loss: 0.3827\n",
      "  Batch [20/77] - Loss: 0.4067\n",
      "  Batch [30/77] - Loss: 0.3340\n",
      "  Batch [40/77] - Loss: 0.3975\n",
      "  Batch [50/77] - Loss: 0.3685\n",
      "  Batch [60/77] - Loss: 0.3788\n",
      "  Batch [70/77] - Loss: 0.3396\n",
      "  Train Loss: 0.3901\n",
      "  Val Loss: 0.3722\n",
      "  Time: 50.30s\n",
      "  ✓ Best model saved (val_loss: 0.3722)\n",
      "\n",
      "[EPOCH 23/110]\n",
      "  Batch [10/77] - Loss: 0.4568\n",
      "  Batch [20/77] - Loss: 0.4443\n",
      "  Batch [30/77] - Loss: 0.3617\n",
      "  Batch [40/77] - Loss: 0.4030\n",
      "  Batch [50/77] - Loss: 0.4255\n",
      "  Batch [60/77] - Loss: 0.3858\n",
      "  Batch [70/77] - Loss: 0.3591\n",
      "  Train Loss: 0.3860\n",
      "  Val Loss: 0.3700\n",
      "  Time: 50.43s\n",
      "  ✓ Best model saved (val_loss: 0.3700)\n",
      "\n",
      "[EPOCH 24/110]\n",
      "  Batch [10/77] - Loss: 0.3475\n",
      "  Batch [20/77] - Loss: 0.4416\n",
      "  Batch [30/77] - Loss: 0.4874\n",
      "  Batch [40/77] - Loss: 0.3807\n",
      "  Batch [50/77] - Loss: 0.4074\n",
      "  Batch [60/77] - Loss: 0.3765\n",
      "  Batch [70/77] - Loss: 0.4316\n",
      "  Train Loss: 0.3833\n",
      "  Val Loss: 0.3680\n",
      "  Time: 50.67s\n",
      "  ✓ Best model saved (val_loss: 0.3680)\n",
      "\n",
      "[EPOCH 25/110]\n",
      "  Batch [10/77] - Loss: 0.3493\n",
      "  Batch [20/77] - Loss: 0.3567\n",
      "  Batch [30/77] - Loss: 0.3345\n",
      "  Batch [40/77] - Loss: 0.3854\n",
      "  Batch [50/77] - Loss: 0.3807\n",
      "  Batch [60/77] - Loss: 0.4108\n",
      "  Batch [70/77] - Loss: 0.3619\n",
      "  Train Loss: 0.3798\n",
      "  Val Loss: 0.3633\n",
      "  Time: 50.56s\n",
      "  ✓ Best model saved (val_loss: 0.3633)\n",
      "\n",
      "[EPOCH 26/110]\n",
      "  Batch [10/77] - Loss: 0.4560\n",
      "  Batch [20/77] - Loss: 0.3980\n",
      "  Batch [30/77] - Loss: 0.3610\n",
      "  Batch [40/77] - Loss: 0.3827\n",
      "  Batch [50/77] - Loss: 0.3423\n",
      "  Batch [60/77] - Loss: 0.4128\n",
      "  Batch [70/77] - Loss: 0.3093\n",
      "  Train Loss: 0.3786\n",
      "  Val Loss: 0.3679\n",
      "  Time: 50.58s\n",
      "\n",
      "[EPOCH 27/110]\n",
      "  Batch [10/77] - Loss: 0.3621\n",
      "  Batch [20/77] - Loss: 0.3730\n",
      "  Batch [30/77] - Loss: 0.3691\n",
      "  Batch [40/77] - Loss: 0.3602\n",
      "  Batch [50/77] - Loss: 0.3727\n",
      "  Batch [60/77] - Loss: 0.4211\n",
      "  Batch [70/77] - Loss: 0.3819\n",
      "  Train Loss: 0.3764\n",
      "  Val Loss: 0.3660\n",
      "  Time: 50.88s\n",
      "\n",
      "[EPOCH 28/110]\n",
      "  Batch [10/77] - Loss: 0.3927\n",
      "  Batch [20/77] - Loss: 0.4363\n",
      "  Batch [30/77] - Loss: 0.3533\n",
      "  Batch [40/77] - Loss: 0.3817\n",
      "  Batch [50/77] - Loss: 0.3532\n",
      "  Batch [60/77] - Loss: 0.3738\n",
      "  Batch [70/77] - Loss: 0.3229\n",
      "  Train Loss: 0.3776\n",
      "  Val Loss: 0.3635\n",
      "  Time: 50.46s\n",
      "\n",
      "[EPOCH 29/110]\n",
      "  Batch [10/77] - Loss: 0.4013\n",
      "  Batch [20/77] - Loss: 0.3767\n",
      "  Batch [30/77] - Loss: 0.3961\n",
      "  Batch [40/77] - Loss: 0.4460\n",
      "  Batch [50/77] - Loss: 0.3506\n",
      "  Batch [60/77] - Loss: 0.4296\n",
      "  Batch [70/77] - Loss: 0.3640\n",
      "  Train Loss: 0.3776\n",
      "  Val Loss: 0.3622\n",
      "  Time: 50.71s\n",
      "  ✓ Best model saved (val_loss: 0.3622)\n",
      "\n",
      "[EPOCH 30/110]\n",
      "  Batch [10/77] - Loss: 0.3515\n",
      "  Batch [20/77] - Loss: 0.4381\n",
      "  Batch [30/77] - Loss: 0.4418\n",
      "  Batch [40/77] - Loss: 0.3906\n",
      "  Batch [50/77] - Loss: 0.3347\n",
      "  Batch [60/77] - Loss: 0.4163\n",
      "  Batch [70/77] - Loss: 0.3624\n",
      "  Train Loss: 0.3777\n",
      "  Val Loss: 0.3628\n",
      "  Time: 50.31s\n",
      "\n",
      "[EPOCH 31/110]\n",
      "  Batch [10/77] - Loss: 0.4109\n",
      "  Batch [20/77] - Loss: 0.3620\n",
      "  Batch [30/77] - Loss: 0.3769\n",
      "  Batch [40/77] - Loss: 0.3677\n",
      "  Batch [50/77] - Loss: 0.3555\n",
      "  Batch [60/77] - Loss: 0.3641\n",
      "  Batch [70/77] - Loss: 0.4162\n",
      "  Train Loss: 0.3731\n",
      "  Val Loss: 0.3606\n",
      "  Time: 50.68s\n",
      "  ✓ Best model saved (val_loss: 0.3606)\n",
      "\n",
      "[EPOCH 32/110]\n",
      "  Batch [10/77] - Loss: 0.3647\n",
      "  Batch [20/77] - Loss: 0.3414\n",
      "  Batch [30/77] - Loss: 0.4059\n",
      "  Batch [40/77] - Loss: 0.3241\n",
      "  Batch [50/77] - Loss: 0.3281\n",
      "  Batch [60/77] - Loss: 0.3895\n",
      "  Batch [70/77] - Loss: 0.3544\n",
      "  Train Loss: 0.3752\n",
      "  Val Loss: 0.3596\n",
      "  Time: 50.51s\n",
      "  ✓ Best model saved (val_loss: 0.3596)\n",
      "\n",
      "[EPOCH 33/110]\n",
      "  Batch [10/77] - Loss: 0.3699\n",
      "  Batch [20/77] - Loss: 0.3815\n",
      "  Batch [30/77] - Loss: 0.3801\n",
      "  Batch [40/77] - Loss: 0.3939\n",
      "  Batch [50/77] - Loss: 0.3948\n",
      "  Batch [60/77] - Loss: 0.4543\n",
      "  Batch [70/77] - Loss: 0.3682\n",
      "  Train Loss: 0.3746\n",
      "  Val Loss: 0.3636\n",
      "  Time: 50.56s\n",
      "\n",
      "[EPOCH 34/110]\n",
      "  Batch [10/77] - Loss: 0.3755\n",
      "  Batch [20/77] - Loss: 0.3244\n",
      "  Batch [30/77] - Loss: 0.3826\n",
      "  Batch [40/77] - Loss: 0.3576\n",
      "  Batch [50/77] - Loss: 0.3108\n",
      "  Batch [60/77] - Loss: 0.3685\n",
      "  Batch [70/77] - Loss: 0.3411\n",
      "  Train Loss: 0.3720\n",
      "  Val Loss: 0.3593\n",
      "  Time: 50.64s\n",
      "  ✓ Best model saved (val_loss: 0.3593)\n",
      "\n",
      "[EPOCH 35/110]\n",
      "  Batch [10/77] - Loss: 0.3398\n",
      "  Batch [20/77] - Loss: 0.3556\n",
      "  Batch [30/77] - Loss: 0.3403\n",
      "  Batch [40/77] - Loss: 0.3605\n",
      "  Batch [50/77] - Loss: 0.3423\n",
      "  Batch [60/77] - Loss: 0.3312\n",
      "  Batch [70/77] - Loss: 0.3571\n",
      "  Train Loss: 0.3736\n",
      "  Val Loss: 0.3584\n",
      "  Time: 50.30s\n",
      "  ✓ Best model saved (val_loss: 0.3584)\n",
      "\n",
      "[EPOCH 36/110]\n",
      "  Batch [10/77] - Loss: 0.3985\n",
      "  Batch [20/77] - Loss: 0.3596\n",
      "  Batch [30/77] - Loss: 0.3462\n",
      "  Batch [40/77] - Loss: 0.3118\n",
      "  Batch [50/77] - Loss: 0.3289\n",
      "  Batch [60/77] - Loss: 0.4036\n",
      "  Batch [70/77] - Loss: 0.3377\n",
      "  Train Loss: 0.3715\n",
      "  Val Loss: 0.3606\n",
      "  Time: 50.59s\n",
      "\n",
      "[EPOCH 37/110]\n",
      "  Batch [10/77] - Loss: 0.3559\n",
      "  Batch [20/77] - Loss: 0.4032\n",
      "  Batch [30/77] - Loss: 0.3809\n",
      "  Batch [40/77] - Loss: 0.3620\n",
      "  Batch [50/77] - Loss: 0.3729\n",
      "  Batch [60/77] - Loss: 0.3532\n",
      "  Batch [70/77] - Loss: 0.3532\n",
      "  Train Loss: 0.3710\n",
      "  Val Loss: 0.3594\n",
      "  Time: 50.51s\n",
      "\n",
      "[EPOCH 38/110]\n",
      "  Batch [10/77] - Loss: 0.4121\n",
      "  Batch [20/77] - Loss: 0.3560\n",
      "  Batch [30/77] - Loss: 0.3268\n",
      "  Batch [40/77] - Loss: 0.4155\n",
      "  Batch [50/77] - Loss: 0.3576\n",
      "  Batch [60/77] - Loss: 0.4368\n",
      "  Batch [70/77] - Loss: 0.3817\n",
      "  Train Loss: 0.3698\n",
      "  Val Loss: 0.3615\n",
      "  Time: 51.02s\n",
      "\n",
      "[EPOCH 39/110]\n",
      "  Batch [10/77] - Loss: 0.4293\n",
      "  Batch [20/77] - Loss: 0.4272\n",
      "  Batch [30/77] - Loss: 0.3678\n",
      "  Batch [40/77] - Loss: 0.3686\n",
      "  Batch [50/77] - Loss: 0.3638\n",
      "  Batch [60/77] - Loss: 0.3863\n",
      "  Batch [70/77] - Loss: 0.3298\n",
      "  Train Loss: 0.3703\n",
      "  Val Loss: 0.3595\n",
      "  Time: 50.40s\n",
      "\n",
      "[EPOCH 40/110]\n",
      "  Batch [10/77] - Loss: 0.3989\n",
      "  Batch [20/77] - Loss: 0.3800\n",
      "  Batch [30/77] - Loss: 0.3786\n",
      "  Batch [40/77] - Loss: 0.3720\n",
      "  Batch [50/77] - Loss: 0.3574\n",
      "  Batch [60/77] - Loss: 0.4767\n",
      "  Batch [70/77] - Loss: 0.3602\n",
      "  Train Loss: 0.3672\n",
      "  Val Loss: 0.3595\n",
      "  Time: 50.60s\n",
      "\n",
      "[EPOCH 41/110]\n",
      "  Batch [10/77] - Loss: 0.3742\n",
      "  Batch [20/77] - Loss: 0.3301\n",
      "  Batch [30/77] - Loss: 0.3396\n",
      "  Batch [40/77] - Loss: 0.4111\n",
      "  Batch [50/77] - Loss: 0.3797\n",
      "  Batch [60/77] - Loss: 0.4552\n",
      "  Batch [70/77] - Loss: 0.3799\n",
      "  Train Loss: 0.3707\n",
      "  Val Loss: 0.3577\n",
      "  Time: 50.97s\n",
      "  ✓ Best model saved (val_loss: 0.3577)\n",
      "\n",
      "[EPOCH 42/110]\n",
      "  Batch [10/77] - Loss: 0.3456\n",
      "  Batch [20/77] - Loss: 0.3758\n",
      "  Batch [30/77] - Loss: 0.3473\n",
      "  Batch [40/77] - Loss: 0.3142\n",
      "  Batch [50/77] - Loss: 0.3492\n",
      "  Batch [60/77] - Loss: 0.3413\n",
      "  Batch [70/77] - Loss: 0.2999\n",
      "  Train Loss: 0.3648\n",
      "  Val Loss: 0.3578\n",
      "  Time: 51.05s\n",
      "\n",
      "[EPOCH 43/110]\n",
      "  Batch [10/77] - Loss: 0.3616\n",
      "  Batch [20/77] - Loss: 0.3251\n",
      "  Batch [30/77] - Loss: 0.3810\n",
      "  Batch [40/77] - Loss: 0.3811\n",
      "  Batch [50/77] - Loss: 0.3901\n",
      "  Batch [60/77] - Loss: 0.3882\n",
      "  Batch [70/77] - Loss: 0.4094\n",
      "  Train Loss: 0.3665\n",
      "  Val Loss: 0.3565\n",
      "  Time: 52.43s\n",
      "  ✓ Best model saved (val_loss: 0.3565)\n",
      "\n",
      "[EPOCH 44/110]\n",
      "  Batch [10/77] - Loss: 0.3428\n",
      "  Batch [20/77] - Loss: 0.4066\n",
      "  Batch [30/77] - Loss: 0.3493\n",
      "  Batch [40/77] - Loss: 0.3962\n",
      "  Batch [50/77] - Loss: 0.3813\n",
      "  Batch [60/77] - Loss: 0.3711\n",
      "  Batch [70/77] - Loss: 0.3248\n",
      "  Train Loss: 0.3640\n",
      "  Val Loss: 0.3572\n",
      "  Time: 50.35s\n",
      "\n",
      "[EPOCH 45/110]\n",
      "  Batch [10/77] - Loss: 0.3601\n",
      "  Batch [20/77] - Loss: 0.3418\n",
      "  Batch [30/77] - Loss: 0.3637\n",
      "  Batch [40/77] - Loss: 0.3667\n",
      "  Batch [50/77] - Loss: 0.3859\n",
      "  Batch [60/77] - Loss: 0.4235\n",
      "  Batch [70/77] - Loss: 0.3793\n",
      "  Train Loss: 0.3665\n",
      "  Val Loss: 0.3562\n",
      "  Time: 50.55s\n",
      "  ✓ Best model saved (val_loss: 0.3562)\n",
      "\n",
      "[EPOCH 46/110]\n",
      "  Batch [10/77] - Loss: 0.3031\n",
      "  Batch [20/77] - Loss: 0.3294\n",
      "  Batch [30/77] - Loss: 0.3913\n",
      "  Batch [40/77] - Loss: 0.3509\n",
      "  Batch [50/77] - Loss: 0.3637\n",
      "  Batch [60/77] - Loss: 0.3359\n",
      "  Batch [70/77] - Loss: 0.3769\n",
      "  Train Loss: 0.3673\n",
      "  Val Loss: 0.3606\n",
      "  Time: 57.41s\n",
      "\n",
      "[EPOCH 47/110]\n",
      "  Batch [10/77] - Loss: 0.4245\n",
      "  Batch [20/77] - Loss: 0.3875\n",
      "  Batch [30/77] - Loss: 0.3399\n",
      "  Batch [40/77] - Loss: 0.3524\n",
      "  Batch [50/77] - Loss: 0.3822\n",
      "  Batch [60/77] - Loss: 0.4112\n",
      "  Batch [70/77] - Loss: 0.3657\n",
      "  Train Loss: 0.3669\n",
      "  Val Loss: 0.3586\n",
      "  Time: 50.50s\n",
      "\n",
      "[EPOCH 48/110]\n",
      "  Batch [10/77] - Loss: 0.3800\n",
      "  Batch [20/77] - Loss: 0.3476\n",
      "  Batch [30/77] - Loss: 0.4018\n",
      "  Batch [40/77] - Loss: 0.3131\n",
      "  Batch [50/77] - Loss: 0.3486\n",
      "  Batch [60/77] - Loss: 0.4066\n",
      "  Batch [70/77] - Loss: 0.3165\n",
      "  Train Loss: 0.3677\n",
      "  Val Loss: 0.3542\n",
      "  Time: 53.30s\n",
      "  ✓ Best model saved (val_loss: 0.3542)\n",
      "\n",
      "[EPOCH 49/110]\n",
      "  Batch [10/77] - Loss: 0.3655\n",
      "  Batch [20/77] - Loss: 0.4076\n",
      "  Batch [30/77] - Loss: 0.3293\n",
      "  Batch [40/77] - Loss: 0.3874\n",
      "  Batch [50/77] - Loss: 0.3974\n",
      "  Batch [60/77] - Loss: 0.3552\n",
      "  Batch [70/77] - Loss: 0.3482\n",
      "  Train Loss: 0.3696\n",
      "  Val Loss: 0.3560\n",
      "  Time: 50.65s\n",
      "\n",
      "[EPOCH 50/110]\n",
      "  Batch [10/77] - Loss: 0.3904\n",
      "  Batch [20/77] - Loss: 0.3617\n",
      "  Batch [30/77] - Loss: 0.3425\n",
      "  Batch [40/77] - Loss: 0.3644\n",
      "  Batch [50/77] - Loss: 0.3877\n",
      "  Batch [60/77] - Loss: 0.3486\n",
      "  Batch [70/77] - Loss: 0.3765\n",
      "  Train Loss: 0.3679\n",
      "  Val Loss: 0.3579\n",
      "  Time: 50.77s\n",
      "\n",
      "[EPOCH 51/110]\n",
      "  Batch [10/77] - Loss: 0.3717\n",
      "  Batch [20/77] - Loss: 0.3648\n",
      "  Batch [30/77] - Loss: 0.3192\n",
      "  Batch [40/77] - Loss: 0.3333\n",
      "  Batch [50/77] - Loss: 0.3932\n",
      "  Batch [60/77] - Loss: 0.4112\n",
      "  Batch [70/77] - Loss: 0.3736\n",
      "  Train Loss: 0.3639\n",
      "  Val Loss: 0.3582\n",
      "  Time: 50.87s\n",
      "\n",
      "[EPOCH 52/110]\n",
      "  Batch [10/77] - Loss: 0.4012\n",
      "  Batch [20/77] - Loss: 0.3149\n",
      "  Batch [30/77] - Loss: 0.3749\n",
      "  Batch [40/77] - Loss: 0.3673\n",
      "  Batch [50/77] - Loss: 0.3414\n",
      "  Batch [60/77] - Loss: 0.3895\n",
      "  Batch [70/77] - Loss: 0.3130\n",
      "  Train Loss: 0.3645\n",
      "  Val Loss: 0.3604\n",
      "  Time: 51.03s\n",
      "\n",
      "[EPOCH 53/110]\n",
      "  Batch [10/77] - Loss: 0.4166\n",
      "  Batch [20/77] - Loss: 0.3378\n",
      "  Batch [30/77] - Loss: 0.3582\n",
      "  Batch [40/77] - Loss: 0.3284\n",
      "  Batch [50/77] - Loss: 0.3235\n",
      "  Batch [60/77] - Loss: 0.4543\n",
      "  Batch [70/77] - Loss: 0.3300\n",
      "  Train Loss: 0.3693\n",
      "  Val Loss: 0.3583\n",
      "  Time: 50.96s\n",
      "\n",
      "[EPOCH 54/110]\n",
      "  Batch [10/77] - Loss: 0.3507\n",
      "  Batch [20/77] - Loss: 0.3310\n",
      "  Batch [30/77] - Loss: 0.3745\n",
      "  Batch [40/77] - Loss: 0.3315\n",
      "  Batch [50/77] - Loss: 0.3665\n",
      "  Batch [60/77] - Loss: 0.3711\n",
      "  Batch [70/77] - Loss: 0.3703\n",
      "  Train Loss: 0.3640\n",
      "  Val Loss: 0.3568\n",
      "  Time: 53.18s\n",
      "\n",
      "[EPOCH 55/110]\n",
      "  Batch [10/77] - Loss: 0.3790\n",
      "  Batch [20/77] - Loss: 0.3752\n",
      "  Batch [30/77] - Loss: 0.4099\n",
      "  Batch [40/77] - Loss: 0.3708\n",
      "  Batch [50/77] - Loss: 0.4050\n",
      "  Batch [60/77] - Loss: 0.3995\n",
      "  Batch [70/77] - Loss: 0.3726\n",
      "  Train Loss: 0.3622\n",
      "  Val Loss: 0.3532\n",
      "  Time: 50.78s\n",
      "  ✓ Best model saved (val_loss: 0.3532)\n",
      "\n",
      "[EPOCH 56/110]\n",
      "  Batch [10/77] - Loss: 0.3231\n",
      "  Batch [20/77] - Loss: 0.3599\n",
      "  Batch [30/77] - Loss: 0.3518\n",
      "  Batch [40/77] - Loss: 0.3234\n",
      "  Batch [50/77] - Loss: 0.3544\n",
      "  Batch [60/77] - Loss: 0.3981\n",
      "  Batch [70/77] - Loss: 0.3271\n",
      "  Train Loss: 0.3616\n",
      "  Val Loss: 0.3542\n",
      "  Time: 51.65s\n",
      "\n",
      "[EPOCH 57/110]\n",
      "  Batch [10/77] - Loss: 0.4166\n",
      "  Batch [20/77] - Loss: 0.4224\n",
      "  Batch [30/77] - Loss: 0.4280\n",
      "  Batch [40/77] - Loss: 0.3807\n",
      "  Batch [50/77] - Loss: 0.3697\n",
      "  Batch [60/77] - Loss: 0.3760\n",
      "  Batch [70/77] - Loss: 0.3447\n",
      "  Train Loss: 0.3632\n",
      "  Val Loss: 0.3549\n",
      "  Time: 53.75s\n",
      "\n",
      "[EPOCH 58/110]\n",
      "  Batch [10/77] - Loss: 0.3964\n",
      "  Batch [20/77] - Loss: 0.3222\n",
      "  Batch [30/77] - Loss: 0.3586\n",
      "  Batch [40/77] - Loss: 0.3416\n",
      "  Batch [50/77] - Loss: 0.3496\n",
      "  Batch [60/77] - Loss: 0.4033\n",
      "  Batch [70/77] - Loss: 0.3199\n",
      "  Train Loss: 0.3614\n",
      "  Val Loss: 0.3530\n",
      "  Time: 52.69s\n",
      "  ✓ Best model saved (val_loss: 0.3530)\n",
      "\n",
      "[EPOCH 59/110]\n",
      "  Batch [10/77] - Loss: 0.3899\n",
      "  Batch [20/77] - Loss: 0.3503\n",
      "  Batch [30/77] - Loss: 0.3552\n",
      "  Batch [40/77] - Loss: 0.3383\n",
      "  Batch [50/77] - Loss: 0.3831\n",
      "  Batch [60/77] - Loss: 0.3849\n",
      "  Batch [70/77] - Loss: 0.2980\n",
      "  Train Loss: 0.3650\n",
      "  Val Loss: 0.3517\n",
      "  Time: 56.37s\n",
      "  ✓ Best model saved (val_loss: 0.3517)\n",
      "\n",
      "[EPOCH 60/110]\n",
      "  Batch [10/77] - Loss: 0.3175\n",
      "  Batch [20/77] - Loss: 0.3700\n",
      "  Batch [30/77] - Loss: 0.3255\n",
      "  Batch [40/77] - Loss: 0.3762\n",
      "  Batch [50/77] - Loss: 0.4013\n",
      "  Batch [60/77] - Loss: 0.3765\n",
      "  Batch [70/77] - Loss: 0.3896\n",
      "  Train Loss: 0.3650\n",
      "  Val Loss: 0.3514\n",
      "  Time: 65.87s\n",
      "  ✓ Best model saved (val_loss: 0.3514)\n",
      "\n",
      "[EPOCH 61/110]\n",
      "  Batch [10/77] - Loss: 0.4134\n",
      "  Batch [20/77] - Loss: 0.3205\n",
      "  Batch [30/77] - Loss: 0.3738\n",
      "  Batch [40/77] - Loss: 0.3863\n",
      "  Batch [50/77] - Loss: 0.3142\n",
      "  Batch [60/77] - Loss: 0.3586\n",
      "  Batch [70/77] - Loss: 0.3497\n",
      "  Train Loss: 0.3601\n",
      "  Val Loss: 0.3560\n",
      "  Time: 57.50s\n",
      "\n",
      "[EPOCH 62/110]\n",
      "  Batch [10/77] - Loss: 0.4121\n",
      "  Batch [20/77] - Loss: 0.3560\n",
      "  Batch [30/77] - Loss: 0.3715\n",
      "  Batch [40/77] - Loss: 0.3829\n",
      "  Batch [50/77] - Loss: 0.3700\n",
      "  Batch [60/77] - Loss: 0.4126\n",
      "  Batch [70/77] - Loss: 0.3273\n",
      "  Train Loss: 0.3639\n",
      "  Val Loss: 0.3570\n",
      "  Time: 57.59s\n",
      "\n",
      "[EPOCH 63/110]\n",
      "  Batch [10/77] - Loss: 0.3553\n",
      "  Batch [20/77] - Loss: 0.3510\n",
      "  Batch [30/77] - Loss: 0.3094\n",
      "  Batch [40/77] - Loss: 0.3543\n",
      "  Batch [50/77] - Loss: 0.4209\n",
      "  Batch [60/77] - Loss: 0.3743\n",
      "  Batch [70/77] - Loss: 0.3391\n",
      "  Train Loss: 0.3631\n",
      "  Val Loss: 0.3546\n",
      "  Time: 57.64s\n",
      "\n",
      "[EPOCH 64/110]\n",
      "  Batch [10/77] - Loss: 0.4091\n",
      "  Batch [20/77] - Loss: 0.3817\n",
      "  Batch [30/77] - Loss: 0.3227\n",
      "  Batch [40/77] - Loss: 0.3660\n",
      "  Batch [50/77] - Loss: 0.3773\n",
      "  Batch [60/77] - Loss: 0.3823\n",
      "  Batch [70/77] - Loss: 0.3450\n",
      "  Train Loss: 0.3621\n",
      "  Val Loss: 0.3531\n",
      "  Time: 57.34s\n",
      "\n",
      "[EPOCH 65/110]\n",
      "  Batch [10/77] - Loss: 0.4109\n",
      "  Batch [20/77] - Loss: 0.3542\n",
      "  Batch [30/77] - Loss: 0.3488\n",
      "  Batch [40/77] - Loss: 0.3275\n",
      "  Batch [50/77] - Loss: 0.3227\n",
      "  Batch [60/77] - Loss: 0.3730\n",
      "  Batch [70/77] - Loss: 0.3651\n",
      "  Train Loss: 0.3609\n",
      "  Val Loss: 0.3564\n",
      "  Time: 52.03s\n",
      "\n",
      "[EPOCH 66/110]\n",
      "  Batch [10/77] - Loss: 0.3270\n",
      "  Batch [20/77] - Loss: 0.4256\n",
      "  Batch [30/77] - Loss: 0.3959\n",
      "  Batch [40/77] - Loss: 0.4188\n",
      "  Batch [50/77] - Loss: 0.4250\n",
      "  Batch [60/77] - Loss: 0.4212\n",
      "  Batch [70/77] - Loss: 0.3248\n",
      "  Train Loss: 0.3643\n",
      "  Val Loss: 0.3544\n",
      "  Time: 50.81s\n",
      "\n",
      "[EPOCH 67/110]\n",
      "  Batch [10/77] - Loss: 0.4119\n",
      "  Batch [20/77] - Loss: 0.3865\n",
      "  Batch [30/77] - Loss: 0.3670\n",
      "  Batch [40/77] - Loss: 0.3460\n",
      "  Batch [50/77] - Loss: 0.3687\n",
      "  Batch [60/77] - Loss: 0.3794\n",
      "  Batch [70/77] - Loss: 0.3436\n",
      "  Train Loss: 0.3657\n",
      "  Val Loss: 0.3530\n",
      "  Time: 50.39s\n",
      "\n",
      "[EPOCH 68/110]\n",
      "  Batch [10/77] - Loss: 0.3257\n",
      "  Batch [20/77] - Loss: 0.3986\n",
      "  Batch [30/77] - Loss: 0.3283\n",
      "  Batch [40/77] - Loss: 0.3689\n",
      "  Batch [50/77] - Loss: 0.3780\n",
      "  Batch [60/77] - Loss: 0.4524\n",
      "  Batch [70/77] - Loss: 0.3425\n",
      "  Train Loss: 0.3643\n",
      "  Val Loss: 0.3553\n",
      "  Time: 50.99s\n",
      "\n",
      "[EPOCH 69/110]\n",
      "  Batch [10/77] - Loss: 0.3541\n",
      "  Batch [20/77] - Loss: 0.3426\n",
      "  Batch [30/77] - Loss: 0.3946\n",
      "  Batch [40/77] - Loss: 0.4533\n",
      "  Batch [50/77] - Loss: 0.3290\n",
      "  Batch [60/77] - Loss: 0.3786\n",
      "  Batch [70/77] - Loss: 0.3664\n",
      "  Train Loss: 0.3642\n",
      "  Val Loss: 0.3571\n",
      "  Time: 50.90s\n",
      "\n",
      "[EPOCH 70/110]\n",
      "  Batch [10/77] - Loss: 0.3677\n",
      "  Batch [20/77] - Loss: 0.3449\n",
      "  Batch [30/77] - Loss: 0.3061\n",
      "  Batch [40/77] - Loss: 0.3381\n",
      "  Batch [50/77] - Loss: 0.4209\n",
      "  Batch [60/77] - Loss: 0.3795\n",
      "  Batch [70/77] - Loss: 0.3381\n",
      "  Train Loss: 0.3619\n",
      "  Val Loss: 0.3547\n",
      "  Time: 50.72s\n",
      "\n",
      "[EPOCH 71/110]\n",
      "  Batch [10/77] - Loss: 0.3077\n",
      "  Batch [20/77] - Loss: 0.4196\n",
      "  Batch [30/77] - Loss: 0.3794\n",
      "  Batch [40/77] - Loss: 0.3729\n",
      "  Batch [50/77] - Loss: 0.3796\n",
      "  Batch [60/77] - Loss: 0.3794\n",
      "  Batch [70/77] - Loss: 0.3302\n",
      "  Train Loss: 0.3686\n",
      "  Val Loss: 0.3578\n",
      "  Time: 51.06s\n",
      "\n",
      "[EPOCH 72/110]\n",
      "  Batch [10/77] - Loss: 0.3437\n",
      "  Batch [20/77] - Loss: 0.3403\n",
      "  Batch [30/77] - Loss: 0.3767\n",
      "  Batch [40/77] - Loss: 0.3468\n",
      "  Batch [50/77] - Loss: 0.3561\n",
      "  Batch [60/77] - Loss: 0.3431\n",
      "  Batch [70/77] - Loss: 0.4006\n",
      "  Train Loss: 0.3637\n",
      "  Val Loss: 0.3493\n",
      "  Time: 50.40s\n",
      "  ✓ Best model saved (val_loss: 0.3493)\n",
      "\n",
      "[EPOCH 73/110]\n",
      "  Batch [10/77] - Loss: 0.3323\n",
      "  Batch [20/77] - Loss: 0.3681\n",
      "  Batch [30/77] - Loss: 0.3550\n",
      "  Batch [40/77] - Loss: 0.3897\n",
      "  Batch [50/77] - Loss: 0.3226\n",
      "  Batch [60/77] - Loss: 0.3977\n",
      "  Batch [70/77] - Loss: 0.3409\n",
      "  Train Loss: 0.3646\n",
      "  Val Loss: 0.3556\n",
      "  Time: 50.65s\n",
      "\n",
      "[EPOCH 74/110]\n",
      "  Batch [10/77] - Loss: 0.3990\n",
      "  Batch [20/77] - Loss: 0.3610\n",
      "  Batch [30/77] - Loss: 0.3941\n",
      "  Batch [40/77] - Loss: 0.4018\n",
      "  Batch [50/77] - Loss: 0.4040\n",
      "  Batch [60/77] - Loss: 0.3910\n",
      "  Batch [70/77] - Loss: 0.3713\n",
      "  Train Loss: 0.3612\n",
      "  Val Loss: 0.3531\n",
      "  Time: 50.57s\n",
      "\n",
      "[EPOCH 75/110]\n",
      "  Batch [10/77] - Loss: 0.3509\n",
      "  Batch [20/77] - Loss: 0.3414\n",
      "  Batch [30/77] - Loss: 0.2986\n",
      "  Batch [40/77] - Loss: 0.3726\n",
      "  Batch [50/77] - Loss: 0.3510\n",
      "  Batch [60/77] - Loss: 0.3726\n",
      "  Batch [70/77] - Loss: 0.3296\n",
      "  Train Loss: 0.3620\n",
      "  Val Loss: 0.3557\n",
      "  Time: 50.45s\n",
      "\n",
      "[EPOCH 76/110]\n",
      "  Batch [10/77] - Loss: 0.3194\n",
      "  Batch [20/77] - Loss: 0.3347\n",
      "  Batch [30/77] - Loss: 0.3529\n",
      "  Batch [40/77] - Loss: 0.3269\n",
      "  Batch [50/77] - Loss: 0.3298\n",
      "  Batch [60/77] - Loss: 0.3973\n",
      "  Batch [70/77] - Loss: 0.3448\n",
      "  Train Loss: 0.3620\n",
      "  Val Loss: 0.3538\n",
      "  Time: 50.50s\n",
      "\n",
      "[EPOCH 77/110]\n",
      "  Batch [10/77] - Loss: 0.3269\n",
      "  Batch [20/77] - Loss: 0.3065\n",
      "  Batch [30/77] - Loss: 0.3283\n",
      "  Batch [40/77] - Loss: 0.3487\n",
      "  Batch [50/77] - Loss: 0.3414\n",
      "  Batch [60/77] - Loss: 0.4064\n",
      "  Batch [70/77] - Loss: 0.3917\n",
      "  Train Loss: 0.3634\n",
      "  Val Loss: 0.3559\n",
      "  Time: 50.90s\n",
      "\n",
      "[EPOCH 78/110]\n",
      "  Batch [10/77] - Loss: 0.3773\n",
      "  Batch [20/77] - Loss: 0.3095\n",
      "  Batch [30/77] - Loss: 0.4230\n",
      "  Batch [40/77] - Loss: 0.3652\n",
      "  Batch [50/77] - Loss: 0.3606\n",
      "  Batch [60/77] - Loss: 0.4107\n",
      "  Batch [70/77] - Loss: 0.3129\n",
      "  Train Loss: 0.3641\n",
      "  Val Loss: 0.3550\n",
      "  Time: 50.90s\n",
      "\n",
      "[EPOCH 79/110]\n",
      "  Batch [10/77] - Loss: 0.3748\n",
      "  Batch [20/77] - Loss: 0.3996\n",
      "  Batch [30/77] - Loss: 0.3110\n",
      "  Batch [40/77] - Loss: 0.4127\n",
      "  Batch [50/77] - Loss: 0.4567\n",
      "  Batch [60/77] - Loss: 0.4344\n",
      "  Batch [70/77] - Loss: 0.3546\n",
      "  Train Loss: 0.3650\n",
      "  Val Loss: 0.3556\n",
      "  Time: 51.47s\n",
      "\n",
      "[EPOCH 80/110]\n",
      "  Batch [10/77] - Loss: 0.3518\n",
      "  Batch [20/77] - Loss: 0.3548\n",
      "  Batch [30/77] - Loss: 0.3533\n",
      "  Batch [40/77] - Loss: 0.3118\n",
      "  Batch [50/77] - Loss: 0.3207\n",
      "  Batch [60/77] - Loss: 0.4016\n",
      "  Batch [70/77] - Loss: 0.3478\n",
      "  Train Loss: 0.3643\n",
      "  Val Loss: 0.3560\n",
      "  Time: 52.22s\n",
      "\n",
      "[EPOCH 81/110]\n",
      "  Batch [10/77] - Loss: 0.3550\n",
      "  Batch [20/77] - Loss: 0.4068\n",
      "  Batch [30/77] - Loss: 0.3872\n",
      "  Batch [40/77] - Loss: 0.3337\n",
      "  Batch [50/77] - Loss: 0.3234\n",
      "  Batch [60/77] - Loss: 0.3570\n",
      "  Batch [70/77] - Loss: 0.3557\n",
      "  Train Loss: 0.3638\n",
      "  Val Loss: 0.3536\n",
      "  Time: 59.33s\n",
      "\n",
      "[EPOCH 82/110]\n",
      "  Batch [10/77] - Loss: 0.3852\n",
      "  Batch [20/77] - Loss: 0.3388\n",
      "  Batch [30/77] - Loss: 0.3166\n",
      "  Batch [40/77] - Loss: 0.4095\n",
      "  Batch [50/77] - Loss: 0.3356\n",
      "  Batch [60/77] - Loss: 0.4369\n",
      "  Batch [70/77] - Loss: 0.4123\n",
      "  Train Loss: 0.3634\n",
      "  Val Loss: 0.3512\n",
      "  Time: 50.83s\n",
      "\n",
      "[EPOCH 83/110]\n",
      "  Batch [10/77] - Loss: 0.3374\n",
      "  Batch [20/77] - Loss: 0.3016\n",
      "  Batch [30/77] - Loss: 0.3796\n",
      "  Batch [40/77] - Loss: 0.3275\n",
      "  Batch [50/77] - Loss: 0.3395\n",
      "  Batch [60/77] - Loss: 0.3838\n",
      "  Batch [70/77] - Loss: 0.3535\n",
      "  Train Loss: 0.3663\n",
      "  Val Loss: 0.3572\n",
      "  Time: 51.01s\n",
      "\n",
      "[EPOCH 84/110]\n",
      "  Batch [10/77] - Loss: 0.3481\n",
      "  Batch [20/77] - Loss: 0.3253\n",
      "  Batch [30/77] - Loss: 0.3591\n",
      "  Batch [40/77] - Loss: 0.4251\n",
      "  Batch [50/77] - Loss: 0.4014\n",
      "  Batch [60/77] - Loss: 0.4559\n",
      "  Batch [70/77] - Loss: 0.3154\n",
      "  Train Loss: 0.3624\n",
      "  Val Loss: 0.3587\n",
      "  Time: 50.83s\n",
      "\n",
      "[EPOCH 85/110]\n",
      "  Batch [10/77] - Loss: 0.3297\n",
      "  Batch [20/77] - Loss: 0.3531\n",
      "  Batch [30/77] - Loss: 0.3596\n",
      "  Batch [40/77] - Loss: 0.3329\n",
      "  Batch [50/77] - Loss: 0.3508\n",
      "  Batch [60/77] - Loss: 0.3520\n",
      "  Batch [70/77] - Loss: 0.3416\n",
      "  Train Loss: 0.3620\n",
      "  Val Loss: 0.3583\n",
      "  Time: 50.75s\n",
      "\n",
      "[EPOCH 86/110]\n",
      "  Batch [10/77] - Loss: 0.3791\n",
      "  Batch [20/77] - Loss: 0.3622\n",
      "  Batch [30/77] - Loss: 0.3233\n",
      "  Batch [40/77] - Loss: 0.3770\n",
      "  Batch [50/77] - Loss: 0.3266\n",
      "  Batch [60/77] - Loss: 0.3413\n",
      "  Batch [70/77] - Loss: 0.3426\n",
      "  Train Loss: 0.3620\n",
      "  Val Loss: 0.3572\n",
      "  Time: 51.07s\n",
      "\n",
      "[EPOCH 87/110]\n",
      "  Batch [10/77] - Loss: 0.3958\n",
      "  Batch [20/77] - Loss: 0.3548\n",
      "  Batch [30/77] - Loss: 0.3599\n",
      "  Batch [40/77] - Loss: 0.3805\n",
      "  Batch [50/77] - Loss: 0.3379\n",
      "  Batch [60/77] - Loss: 0.3862\n",
      "  Batch [70/77] - Loss: 0.3477\n",
      "  Train Loss: 0.3618\n",
      "  Val Loss: 0.3518\n",
      "  Time: 50.55s\n",
      "\n",
      "[EPOCH 88/110]\n",
      "  Batch [10/77] - Loss: 0.3879\n",
      "  Batch [20/77] - Loss: 0.3237\n",
      "  Batch [30/77] - Loss: 0.3375\n",
      "  Batch [40/77] - Loss: 0.3585\n",
      "  Batch [50/77] - Loss: 0.3505\n",
      "  Batch [60/77] - Loss: 0.3857\n",
      "  Batch [70/77] - Loss: 0.3361\n",
      "  Train Loss: 0.3626\n",
      "  Val Loss: 0.3550\n",
      "  Time: 59.51s\n",
      "\n",
      "[EPOCH 89/110]\n",
      "  Batch [10/77] - Loss: 0.3679\n",
      "  Batch [20/77] - Loss: 0.3428\n",
      "  Batch [30/77] - Loss: 0.3401\n",
      "  Batch [40/77] - Loss: 0.3296\n",
      "  Batch [50/77] - Loss: 0.3639\n",
      "  Batch [60/77] - Loss: 0.3683\n",
      "  Batch [70/77] - Loss: 0.3294\n",
      "  Train Loss: 0.3649\n",
      "  Val Loss: 0.3573\n",
      "  Time: 55.89s\n",
      "\n",
      "[EPOCH 90/110]\n",
      "  Batch [10/77] - Loss: 0.3521\n",
      "  Batch [20/77] - Loss: 0.3533\n",
      "  Batch [30/77] - Loss: 0.3563\n",
      "  Batch [40/77] - Loss: 0.3789\n",
      "  Batch [50/77] - Loss: 0.3455\n",
      "  Batch [60/77] - Loss: 0.3642\n",
      "  Batch [70/77] - Loss: 0.3848\n",
      "  Train Loss: 0.3646\n",
      "  Val Loss: 0.3526\n",
      "  Time: 52.53s\n",
      "\n",
      "[EPOCH 91/110]\n",
      "  Batch [10/77] - Loss: 0.3540\n",
      "  Batch [20/77] - Loss: 0.3897\n",
      "  Batch [30/77] - Loss: 0.4075\n",
      "  Batch [40/77] - Loss: 0.3518\n",
      "  Batch [50/77] - Loss: 0.3565\n",
      "  Batch [60/77] - Loss: 0.3836\n",
      "  Batch [70/77] - Loss: 0.3461\n",
      "  Train Loss: 0.3642\n",
      "  Val Loss: 0.3556\n",
      "  Time: 59.36s\n",
      "\n",
      "[EPOCH 92/110]\n",
      "  Batch [10/77] - Loss: 0.3853\n",
      "  Batch [20/77] - Loss: 0.4054\n",
      "  Batch [30/77] - Loss: 0.3794\n",
      "  Batch [40/77] - Loss: 0.3601\n",
      "  Batch [50/77] - Loss: 0.3096\n",
      "  Batch [60/77] - Loss: 0.4148\n",
      "  Batch [70/77] - Loss: 0.3927\n",
      "  Train Loss: 0.3644\n",
      "  Val Loss: 0.3519\n",
      "  Time: 53.54s\n",
      "\n",
      "[EPOCH 93/110]\n",
      "  Batch [10/77] - Loss: 0.3826\n",
      "  Batch [20/77] - Loss: 0.3733\n",
      "  Batch [30/77] - Loss: 0.3485\n",
      "  Batch [40/77] - Loss: 0.3022\n",
      "  Batch [50/77] - Loss: 0.3857\n",
      "  Batch [60/77] - Loss: 0.4397\n",
      "  Batch [70/77] - Loss: 0.4207\n",
      "  Train Loss: 0.3639\n",
      "  Val Loss: 0.3523\n",
      "  Time: 50.67s\n",
      "\n",
      "[EPOCH 94/110]\n",
      "  Batch [10/77] - Loss: 0.3752\n",
      "  Batch [20/77] - Loss: 0.4162\n",
      "  Batch [30/77] - Loss: 0.3472\n",
      "  Batch [40/77] - Loss: 0.3758\n",
      "  Batch [50/77] - Loss: 0.3708\n",
      "  Batch [60/77] - Loss: 0.4302\n",
      "  Batch [70/77] - Loss: 0.3459\n",
      "  Train Loss: 0.3604\n",
      "  Val Loss: 0.3544\n",
      "  Time: 50.73s\n",
      "\n",
      "[EPOCH 95/110]\n",
      "  Batch [10/77] - Loss: 0.4057\n",
      "  Batch [20/77] - Loss: 0.3335\n",
      "  Batch [30/77] - Loss: 0.3551\n",
      "  Batch [40/77] - Loss: 0.3435\n",
      "  Batch [50/77] - Loss: 0.3313\n",
      "  Batch [60/77] - Loss: 0.3832\n",
      "  Batch [70/77] - Loss: 0.3471\n",
      "  Train Loss: 0.3653\n",
      "  Val Loss: 0.3555\n",
      "  Time: 51.75s\n",
      "\n",
      "[EPOCH 96/110]\n",
      "  Batch [10/77] - Loss: 0.3340\n",
      "  Batch [20/77] - Loss: 0.3467\n",
      "  Batch [30/77] - Loss: 0.3356\n",
      "  Batch [40/77] - Loss: 0.3773\n",
      "  Batch [50/77] - Loss: 0.3634\n",
      "  Batch [60/77] - Loss: 0.3920\n",
      "  Batch [70/77] - Loss: 0.3756\n",
      "  Train Loss: 0.3661\n",
      "  Val Loss: 0.3504\n",
      "  Time: 59.03s\n",
      "\n",
      "[EPOCH 97/110]\n",
      "  Batch [10/77] - Loss: 0.3705\n",
      "  Batch [20/77] - Loss: 0.4091\n",
      "  Batch [30/77] - Loss: 0.3941\n",
      "  Batch [40/77] - Loss: 0.3190\n",
      "  Batch [50/77] - Loss: 0.3448\n",
      "  Batch [60/77] - Loss: 0.4927\n",
      "  Batch [70/77] - Loss: 0.3574\n",
      "  Train Loss: 0.3654\n",
      "  Val Loss: 0.3560\n",
      "  Time: 57.94s\n",
      "\n",
      "[EPOCH 98/110]\n",
      "  Batch [10/77] - Loss: 0.3758\n",
      "  Batch [20/77] - Loss: 0.3246\n",
      "  Batch [30/77] - Loss: 0.3853\n",
      "  Batch [40/77] - Loss: 0.3416\n",
      "  Batch [50/77] - Loss: 0.3714\n",
      "  Batch [60/77] - Loss: 0.4250\n",
      "  Batch [70/77] - Loss: 0.3758\n",
      "  Train Loss: 0.3668\n",
      "  Val Loss: 0.3594\n",
      "  Time: 50.93s\n",
      "\n",
      "[EPOCH 99/110]\n",
      "  Batch [10/77] - Loss: 0.4158\n",
      "  Batch [20/77] - Loss: 0.3703\n",
      "  Batch [30/77] - Loss: 0.3484\n",
      "  Batch [40/77] - Loss: 0.3208\n",
      "  Batch [50/77] - Loss: 0.3353\n",
      "  Batch [60/77] - Loss: 0.3653\n",
      "  Batch [70/77] - Loss: 0.3045\n",
      "  Train Loss: 0.3639\n",
      "  Val Loss: 0.3551\n",
      "  Time: 59.61s\n",
      "\n",
      "[EPOCH 100/110]\n",
      "  Batch [10/77] - Loss: 0.3474\n",
      "  Batch [20/77] - Loss: 0.2885\n",
      "  Batch [30/77] - Loss: 0.3567\n",
      "  Batch [40/77] - Loss: 0.3201\n",
      "  Batch [50/77] - Loss: 0.3926\n",
      "  Batch [60/77] - Loss: 0.3610\n",
      "  Batch [70/77] - Loss: 0.3246\n",
      "  Train Loss: 0.3645\n",
      "  Val Loss: 0.3541\n",
      "  Time: 60.82s\n",
      "\n",
      "[EPOCH 101/110]\n",
      "  Batch [10/77] - Loss: 0.4486\n",
      "  Batch [20/77] - Loss: 0.3843\n",
      "  Batch [30/77] - Loss: 0.3465\n",
      "  Batch [40/77] - Loss: 0.3752\n",
      "  Batch [50/77] - Loss: 0.3018\n",
      "  Batch [60/77] - Loss: 0.4219\n",
      "  Batch [70/77] - Loss: 0.3458\n",
      "  Train Loss: 0.3664\n",
      "  Val Loss: 0.3529\n",
      "  Time: 50.81s\n",
      "\n",
      "[EPOCH 102/110]\n",
      "  Batch [10/77] - Loss: 0.3597\n",
      "  Batch [20/77] - Loss: 0.3321\n",
      "  Batch [30/77] - Loss: 0.3597\n",
      "  Batch [40/77] - Loss: 0.3908\n",
      "  Batch [50/77] - Loss: 0.3233\n",
      "  Batch [60/77] - Loss: 0.4289\n",
      "  Batch [70/77] - Loss: 0.3506\n",
      "  Train Loss: 0.3661\n",
      "  Val Loss: 0.3541\n",
      "  Time: 50.76s\n",
      "\n",
      "[EPOCH 103/110]\n",
      "  Batch [10/77] - Loss: 0.3405\n",
      "  Batch [20/77] - Loss: 0.3876\n",
      "  Batch [30/77] - Loss: 0.3755\n",
      "  Batch [40/77] - Loss: 0.3514\n",
      "  Batch [50/77] - Loss: 0.3689\n",
      "  Batch [60/77] - Loss: 0.4213\n",
      "  Batch [70/77] - Loss: 0.4205\n",
      "  Train Loss: 0.3656\n",
      "  Val Loss: 0.3527\n",
      "  Time: 50.92s\n",
      "\n",
      "[EPOCH 104/110]\n",
      "  Batch [10/77] - Loss: 0.3589\n",
      "  Batch [20/77] - Loss: 0.3742\n",
      "  Batch [30/77] - Loss: 0.3890\n",
      "  Batch [40/77] - Loss: 0.3506\n",
      "  Batch [50/77] - Loss: 0.3506\n",
      "  Batch [60/77] - Loss: 0.3637\n",
      "  Batch [70/77] - Loss: 0.3334\n",
      "  Train Loss: 0.3627\n",
      "  Val Loss: 0.3569\n",
      "  Time: 50.50s\n",
      "\n",
      "[EPOCH 105/110]\n",
      "  Batch [10/77] - Loss: 0.4109\n",
      "  Batch [20/77] - Loss: 0.3186\n",
      "  Batch [30/77] - Loss: 0.3791\n",
      "  Batch [40/77] - Loss: 0.3194\n",
      "  Batch [50/77] - Loss: 0.4061\n",
      "  Batch [60/77] - Loss: 0.3817\n",
      "  Batch [70/77] - Loss: 0.3630\n",
      "  Train Loss: 0.3612\n",
      "  Val Loss: 0.3529\n",
      "  Time: 57.34s\n",
      "\n",
      "[EPOCH 106/110]\n",
      "  Batch [10/77] - Loss: 0.3901\n",
      "  Batch [20/77] - Loss: 0.3603\n",
      "  Batch [30/77] - Loss: 0.3731\n",
      "  Batch [40/77] - Loss: 0.3761\n",
      "  Batch [50/77] - Loss: 0.3869\n",
      "  Batch [60/77] - Loss: 0.4071\n",
      "  Batch [70/77] - Loss: 0.3315\n",
      "  Train Loss: 0.3662\n",
      "  Val Loss: 0.3543\n",
      "  Time: 59.38s\n",
      "\n",
      "[EPOCH 107/110]\n",
      "  Batch [10/77] - Loss: 0.3611\n",
      "  Batch [20/77] - Loss: 0.3742\n",
      "  Batch [30/77] - Loss: 0.3448\n",
      "  Batch [40/77] - Loss: 0.3391\n",
      "  Batch [50/77] - Loss: 0.3509\n",
      "  Batch [60/77] - Loss: 0.4066\n",
      "  Batch [70/77] - Loss: 0.3418\n",
      "  Train Loss: 0.3628\n",
      "  Val Loss: 0.3536\n",
      "  Time: 50.45s\n",
      "\n",
      "[EARLY STOPPING] No improvement for 35 epochs\n",
      "\n",
      "======================================================================\n",
      "  TRAINING COMPLETED\n",
      "  Best Epoch: 72\n",
      "  Best Val Loss: 0.3493\n",
      "  Total Time: 111.89 minutes\n",
      "======================================================================\n",
      "\n",
      "[OK] Training history saved to /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_074_resnet101_baseline/plots\n",
      "\n",
      "[OK] Training completed for resnet101_baseline!\n",
      "  Results saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_074_resnet101_baseline\n",
      "\n",
      "[INFO] Evaluating model and saving metrics...\n",
      "[INFO] Running inference for COCO evaluation...\n",
      "[OK] Generated 15292 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=38.28s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.580\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.724\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.712\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 48.21 ms/image\n",
      "[OK] Total parameters: 60.24M\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /home/jupyter-st124895/cv_project/04_experiments/all_experiments_log.csv\n",
      "[OK] Updated best model for 02_faster_rcnn: exp_074_resnet101_baseline (mAP@0.5:0.95 = 0.5801)\n",
      "[OK] Updated overall best model: exp_074_resnet101_baseline (mAP@0.5:0.95 = 0.5801)\n",
      "[OK] Comprehensive plots saved to: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_074_resnet101_baseline/plots/comprehensive_results.png\n",
      "\n",
      "[OK] Metrics saved to CSVs and best model tracker updated!\n",
      "  mAP@0.5:      0.7240\n",
      "  mAP@0.5:0.95: 0.5801\n",
      "\n",
      "================================================================================\n",
      "  STARTING EXPERIMENT: resnet101_best_params\n",
      "  ResNet101 + score 0.10 + pos_frac 0.30 (mejor de ResNet50)\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  EXPERIMENT: exp_075_resnet101_best_params\n",
      "  Family: 02_faster_rcnn\n",
      "  Directory: /home/jupyter-st124895/cv_project/04_experiments/02_faster_rcnn/exp_075_resnet101_best_params\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[INFO] Data augmentation settings:\n",
      "  HSV: h=0.015, s=0.08, v=0.08\n",
      "  Geometric: degrees=4.0, translate=0.04, scale=0.08\n",
      "  Flip: horizontal=0.5, vertical=0.0\n",
      "  Other: blur=False, brightness_contrast=True\n",
      "[OK] Loaded 306 images\n",
      "[OK] Loaded 39465 annotations\n",
      "[OK] Loaded 153 images\n",
      "[OK] Loaded 19666 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/jupyter-st124895/.local/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training for 110 epochs...\n",
      "[INFO] Device: cuda\n",
      "\n",
      "[EPOCH 1/110]\n",
      "  Batch [10/77] - Loss: 1.8788\n",
      "  Batch [20/77] - Loss: 1.2573\n",
      "  Batch [30/77] - Loss: 1.1755\n",
      "  Batch [40/77] - Loss: 0.8892\n",
      "  Batch [50/77] - Loss: 0.7640\n",
      "  Batch [60/77] - Loss: 0.6898\n",
      "  Batch [70/77] - Loss: 0.6480\n",
      "  Train Loss: 1.1087\n",
      "  Val Loss: 0.6086\n",
      "  Time: 51.01s\n",
      "  ✓ Best model saved (val_loss: 0.6086)\n",
      "\n",
      "[EPOCH 2/110]\n",
      "  Batch [10/77] - Loss: 0.6406\n",
      "  Batch [20/77] - Loss: 0.7107\n",
      "  Batch [30/77] - Loss: 0.6623\n",
      "  Batch [40/77] - Loss: 0.6476\n",
      "  Batch [50/77] - Loss: 0.6494\n",
      "  Batch [60/77] - Loss: 0.5553\n",
      "  Batch [70/77] - Loss: 0.6684\n",
      "  Train Loss: 0.6588\n",
      "  Val Loss: 0.6244\n",
      "  Time: 50.50s\n",
      "\n",
      "[EPOCH 3/110]\n",
      "  Batch [10/77] - Loss: 0.6419\n",
      "  Batch [20/77] - Loss: 0.6968\n",
      "  Batch [30/77] - Loss: 0.6994\n",
      "  Batch [40/77] - Loss: 0.6125\n",
      "  Batch [50/77] - Loss: 0.6638\n",
      "  Batch [60/77] - Loss: 0.5918\n",
      "  Batch [70/77] - Loss: 0.5851\n",
      "  Train Loss: 0.6307\n",
      "  Val Loss: 0.5423\n",
      "  Time: 51.06s\n",
      "  ✓ Best model saved (val_loss: 0.5423)\n",
      "\n",
      "[EPOCH 4/110]\n",
      "  Batch [10/77] - Loss: 0.5955\n",
      "  Batch [20/77] - Loss: 0.6036\n",
      "  Batch [30/77] - Loss: 0.6586\n",
      "  Batch [40/77] - Loss: 0.5309\n",
      "  Batch [50/77] - Loss: 0.5801\n",
      "  Batch [60/77] - Loss: 0.5221\n",
      "  Batch [70/77] - Loss: 0.5711\n",
      "  Train Loss: 0.5922\n",
      "  Val Loss: 0.5563\n",
      "  Time: 50.61s\n",
      "\n",
      "[EPOCH 5/110]\n",
      "  Batch [10/77] - Loss: 0.6134\n",
      "  Batch [20/77] - Loss: 0.5156\n",
      "  Batch [30/77] - Loss: 0.5264\n",
      "  Batch [40/77] - Loss: 0.4404\n",
      "  Batch [50/77] - Loss: 0.5106\n",
      "  Batch [60/77] - Loss: 0.4134\n",
      "  Batch [70/77] - Loss: 0.5666\n",
      "  Train Loss: 0.5500\n",
      "  Val Loss: 0.5678\n",
      "  Time: 50.62s\n",
      "\n",
      "[EPOCH 6/110]\n",
      "  Batch [10/77] - Loss: 0.5403\n",
      "  Batch [20/77] - Loss: 0.5219\n",
      "  Batch [30/77] - Loss: 0.5251\n",
      "  Batch [40/77] - Loss: 0.5648\n",
      "  Batch [50/77] - Loss: 0.4792\n",
      "  Batch [60/77] - Loss: 0.4627\n",
      "  Batch [70/77] - Loss: 0.4472\n",
      "  Train Loss: 0.5311\n",
      "  Val Loss: 0.4893\n",
      "  Time: 50.67s\n",
      "  ✓ Best model saved (val_loss: 0.4893)\n",
      "\n",
      "[EPOCH 7/110]\n",
      "  Batch [10/77] - Loss: 0.5104\n",
      "  Batch [20/77] - Loss: 0.4952\n",
      "  Batch [30/77] - Loss: 0.4875\n",
      "  Batch [40/77] - Loss: 0.5213\n",
      "  Batch [50/77] - Loss: 0.5720\n",
      "  Batch [60/77] - Loss: 0.4539\n",
      "  Batch [70/77] - Loss: 0.4600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 355\u001b[0m\n\u001b[1;32m    348\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(\n\u001b[1;32m    349\u001b[0m     optimizer,\n\u001b[1;32m    350\u001b[0m     step_size\u001b[38;5;241m=\u001b[39mexp_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    351\u001b[0m     gamma\u001b[38;5;241m=\u001b[39mexp_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    352\u001b[0m )\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m history, best_val_loss, best_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_config\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[OK] Training completed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Results saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mexperiment_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 157\u001b[0m, in \u001b[0;36mFasterRCNNTrainer.train\u001b[0;34m(self, train_loader, val_loader, model, optimizer, lr_scheduler, num_epochs, device, config)\u001b[0m\n\u001b[1;32m    154\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 157\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    740\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1492\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1492\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1454\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1454\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1455\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1456\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1285\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:541\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[0;32m--> 541\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    543\u001b[0m         storage \u001b[38;5;241m=\u001b[39m storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction\u001b[38;5;241m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/multiprocessing/resource_sharer.py:86\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     85\u001b[0m address, key \u001b[38;5;241m=\u001b[39m ident\n\u001b[0;32m---> 86\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m c\u001b[38;5;241m.\u001b[39msend((key, os\u001b[38;5;241m.\u001b[39mgetpid()))\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/multiprocessing/connection.py:526\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m     answer_challenge(c, authkey)\n\u001b[0;32m--> 526\u001b[0m     \u001b[43mdeliver_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/multiprocessing/connection.py:939\u001b[0m, in \u001b[0;36mdeliver_challenge\u001b[0;34m(connection, authkey, digest_name)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;66;03m# Even when sending a challenge to a legacy client that does not support\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;66;03m# digest prefixes, they'll take the entire thing as a challenge and\u001b[39;00m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# respond to it with a raw HMAC-MD5.\u001b[39;00m\n\u001b[1;32m    938\u001b[0m connection\u001b[38;5;241m.\u001b[39msend_bytes(_CHALLENGE \u001b[38;5;241m+\u001b[39m message)\n\u001b[0;32m--> 939\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m        \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m     _verify_challenge(authkey, message, response)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/multiprocessing/connection.py:430\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 430\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/multiprocessing/connection.py:395\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 6: Run Experiments\n",
    "# ==============================================================================\n",
    "\"\"\"\n",
    "CONFIGURABLE ARCHITECTURE PARAMETERS (Opción A):\n",
    "\n",
    "You can now configure these architecture parameters directly in experiments_config:\n",
    "\n",
    "- box_score_thresh (float, default 0.05): Minimum confidence threshold for detections\n",
    "  * Higher values (0.10-0.15) reduce false positives but may miss low-confidence objects\n",
    "  * Recommended range: 0.05-0.20\n",
    "\n",
    "- box_nms_thresh (float, default 0.5): NMS IoU threshold\n",
    "  * Lower values (0.4-0.45) allow closer boxes (good for dense scenes)\n",
    "  * Higher values (0.5-0.6) suppress more overlapping boxes\n",
    "  * Recommended range: 0.4-0.6\n",
    "\n",
    "- box_detections_per_img (int, default 100): Maximum detections per image\n",
    "  * Your dataset averages 44 objects/image, so 80-120 is reasonable\n",
    "  * Recommended range: 60-150\n",
    "\n",
    "- rpn_fg_iou_thresh (float, default 0.7): RPN foreground IoU threshold\n",
    "  * Lower values (0.6) are more lenient for dense/overlapping objects\n",
    "  * Recommended range: 0.6-0.7\n",
    "\n",
    "- rpn_bg_iou_thresh (float, default 0.3): RPN background IoU threshold\n",
    "  * Higher values (0.4) are more strict about background classification\n",
    "  * Recommended range: 0.3-0.5\n",
    "\n",
    "- box_positive_fraction (float, default 0.25): Ratio of positive samples in ROI head\n",
    "  * Higher values (0.30-0.35) provide more positive examples for dense scenes\n",
    "  * Recommended range: 0.20-0.35\n",
    "\n",
    "EXAMPLE USAGE in experiments_config:\n",
    "{\n",
    "    'name': 'optimized_score_thresh',\n",
    "    'description': 'Test higher confidence threshold',\n",
    "    'backbone': 'resnet50',\n",
    "    'pretrained': True,\n",
    "    'num_epochs': 50,\n",
    "    'batch_size': 4,\n",
    "    'learning_rate': 0.005,\n",
    "    ... (standard params) ...\n",
    "\n",
    "    # NEW: Architecture parameters\n",
    "    'box_score_thresh': 0.10,        # Higher confidence\n",
    "    'box_nms_thresh': 0.5,           # Keep default\n",
    "    'rpn_fg_iou_thresh': 0.6,        # More lenient\n",
    "    'box_positive_fraction': 0.30,   # More positive samples\n",
    "}\n",
    "\n",
    "NOTE: If parameter is not specified, torchvision defaults are used.\n",
    "All parameters are tracked in CSV for analysis.\n",
    "\"\"\"\n",
    "\n",
    "# Device detection\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"\\n[INFO] Using device: {device}\")\n",
    "\n",
    "# Experiment configuration with data augmentation\n",
    "experiments_config = [\n",
    "    # ==========================================================================\n",
    "    # FASE 1: ResNet101 - Validación inicial\n",
    "    # ==========================================================================\n",
    "    {\n",
    "        'name': 'resnet101_baseline',\n",
    "        'description': 'ResNet101 con configuración baseline para comparación',\n",
    "        'backbone': 'resnet101',\n",
    "        'pretrained': True,\n",
    "        'num_epochs': 110,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 0.004,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 0.0005,\n",
    "        'step_size': 20,\n",
    "        'gamma': 0.1,\n",
    "        'patience': 35,\n",
    "        # Augmentation probada que funciona bien\n",
    "        'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "        'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "        'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "        'blur': False, 'brightness_contrast': True\n",
    "        # NO architecture params = defaults\n",
    "    },\n",
    "\n",
    "    # # ==========================================================================\n",
    "    # # FASE 2: ResNet101 + Mejores parámetros encontrados\n",
    "    # # ==========================================================================\n",
    "    # {\n",
    "    #     'name': 'resnet101_best_params',\n",
    "    #     'description': 'ResNet101 + score 0.10 + pos_frac 0.30 (mejor de ResNet50)',\n",
    "    #     'backbone': 'resnet101',\n",
    "    #     'pretrained': True,\n",
    "    #     'num_epochs': 110,\n",
    "    #     'batch_size': 4,\n",
    "    #     'learning_rate': 0.004,\n",
    "    #     'momentum': 0.9,\n",
    "    #     'weight_decay': 0.0005,\n",
    "    #     'step_size': 20,\n",
    "    #     'gamma': 0.1,\n",
    "    #     'patience': 35,\n",
    "    #     'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "    #     'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "    #     'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "    #     'blur': False, 'brightness_contrast': True,\n",
    "    #     # ARCHITECTURE - Best params from ResNet50:\n",
    "    #     'box_score_thresh': 0.10,\n",
    "    #     'box_positive_fraction': 0.30\n",
    "    # },\n",
    "\n",
    "    # # ==========================================================================\n",
    "    # # FASE 3: ResNet101 + Longer Training\n",
    "    # # ==========================================================================\n",
    "    # {\n",
    "    #     'name': 'resnet101_long_training',\n",
    "    #     'description': 'ResNet101 + 200 epochs + decay suave + best params',\n",
    "    #     'backbone': 'resnet101',\n",
    "    #     'pretrained': True,\n",
    "    #     'num_epochs': 200,\n",
    "    #     'batch_size': 4,\n",
    "    #     'learning_rate': 0.004,\n",
    "    #     'momentum': 0.9,\n",
    "    #     'weight_decay': 0.0005,\n",
    "    #     'step_size': 30,  # Decay más lento\n",
    "    #     'gamma': 0.2,     # Menos agresivo\n",
    "    #     'patience': 60,   # Más paciencia\n",
    "    #     'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "    #     'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "    #     'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "    #     'blur': False, 'brightness_contrast': True,\n",
    "    #     # ARCHITECTURE:\n",
    "    #     'box_score_thresh': 0.10,\n",
    "    #     'box_positive_fraction': 0.30\n",
    "    # },\n",
    "\n",
    "    # # ==========================================================================\n",
    "    # # FASE 4: ResNet101 + Strong Augmentation\n",
    "    # # ==========================================================================\n",
    "    # {\n",
    "    #     'name': 'resnet101_strong_aug',\n",
    "    #     'description': 'ResNet101 + augmentation más fuerte para mejor generalización',\n",
    "    #     'backbone': 'resnet101',\n",
    "    #     'pretrained': True,\n",
    "    #     'num_epochs': 150,\n",
    "    #     'batch_size': 4,\n",
    "    #     'learning_rate': 0.004,\n",
    "    #     'momentum': 0.9,\n",
    "    #     'weight_decay': 0.0005,\n",
    "    #     'step_size': 25,\n",
    "    #     'gamma': 0.1,\n",
    "    #     'patience': 45,\n",
    "    #     # STRONG AUGMENTATION:\n",
    "    #     'hsv_h': 0.03, 'hsv_s': 0.15, 'hsv_v': 0.15,\n",
    "    #     'degrees': 8.0, 'translate': 0.1, 'scale': 0.15,\n",
    "    #     'horizontal_flip': 0.5, 'vertical_flip': 0.3,\n",
    "    #     'blur': True, 'brightness_contrast': True,\n",
    "    #     # ARCHITECTURE:\n",
    "    #     'box_score_thresh': 0.10,\n",
    "    #     'box_positive_fraction': 0.30\n",
    "    # },\n",
    "\n",
    "    # # ==========================================================================\n",
    "    # # FASE 5: ResNet101 + NMS Tuning\n",
    "    # # ==========================================================================\n",
    "    # {\n",
    "    #     'name': 'resnet101_nms_06',\n",
    "    #     'description': 'ResNet101 + NMS 0.6 (más tolerante para dense objects)',\n",
    "    #     'backbone': 'resnet101',\n",
    "    #     'pretrained': True,\n",
    "    #     'num_epochs': 120,\n",
    "    #     'batch_size': 4,\n",
    "    #     'learning_rate': 0.004,\n",
    "    #     'momentum': 0.9,\n",
    "    #     'weight_decay': 0.0005,\n",
    "    #     'step_size': 25,\n",
    "    #     'gamma': 0.1,\n",
    "    #     'patience': 40,\n",
    "    #     'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "    #     'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "    #     'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "    #     'blur': False, 'brightness_contrast': True,\n",
    "    #     # ARCHITECTURE:\n",
    "    #     'box_score_thresh': 0.10,\n",
    "    #     'box_nms_thresh': 0.6,  # Más tolerante\n",
    "    #     'box_positive_fraction': 0.30\n",
    "    # },\n",
    "\n",
    "    # {\n",
    "    #     'name': 'resnet101_nms_065',\n",
    "    #     'description': 'ResNet101 + NMS 0.65 (balance)',\n",
    "    #     'backbone': 'resnet101',\n",
    "    #     'pretrained': True,\n",
    "    #     'num_epochs': 120,\n",
    "    #     'batch_size': 4,\n",
    "    #     'learning_rate': 0.004,\n",
    "    #     'momentum': 0.9,\n",
    "    #     'weight_decay': 0.0005,\n",
    "    #     'step_size': 25,\n",
    "    #     'gamma': 0.1,\n",
    "    #     'patience': 40,\n",
    "    #     'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "    #     'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "    #     'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "    #     'blur': False, 'brightness_contrast': True,\n",
    "    #     # ARCHITECTURE:\n",
    "    #     'box_score_thresh': 0.10,\n",
    "    #     'box_nms_thresh': 0.65,\n",
    "    #     'box_positive_fraction': 0.30\n",
    "    # },\n",
    "\n",
    "    # # ==========================================================================\n",
    "    # # FASE 6: ResNet101 + All Optimizations\n",
    "    # # ==========================================================================\n",
    "    # {\n",
    "    #     'name': 'resnet101_all_optimizations',\n",
    "    #     'description': 'ResNet101 + TODO lo mejor encontrado',\n",
    "    #     'backbone': 'resnet101',\n",
    "    #     'pretrained': True,\n",
    "    #     'num_epochs': 200,\n",
    "    #     'batch_size': 4,\n",
    "    #     'learning_rate': 0.004,\n",
    "    #     'momentum': 0.9,\n",
    "    #     'weight_decay': 0.0005,\n",
    "    #     'step_size': 30,\n",
    "    #     'gamma': 0.2,\n",
    "    #     'patience': 60,\n",
    "    #     # Moderate augmentation (balance)\n",
    "    #     'hsv_h': 0.02, 'hsv_s': 0.1, 'hsv_v': 0.1,\n",
    "    #     'degrees': 6.0, 'translate': 0.06, 'scale': 0.12,\n",
    "    #     'horizontal_flip': 0.5, 'vertical_flip': 0.2,\n",
    "    #     'blur': False, 'brightness_contrast': True,\n",
    "    #     # ALL ARCHITECTURE OPTIMIZATIONS:\n",
    "    #     'box_score_thresh': 0.10,\n",
    "    #     'box_nms_thresh': 0.6,\n",
    "    #     'box_positive_fraction': 0.30\n",
    "    # },\n",
    "\n",
    "    # # ==========================================================================\n",
    "    # # BONUS: ResNet101 + Cosine-like LR Schedule\n",
    "    # # ==========================================================================\n",
    "    # {\n",
    "    #     'name': 'resnet101_cosine_lr',\n",
    "    #     'description': 'ResNet101 + cosine-like learning rate (smooth decay)',\n",
    "    #     'backbone': 'resnet101',\n",
    "    #     'pretrained': True,\n",
    "    #     'num_epochs': 150,\n",
    "    #     'batch_size': 4,\n",
    "    #     'learning_rate': 0.004,\n",
    "    #     'momentum': 0.9,\n",
    "    #     'weight_decay': 0.0005,\n",
    "    #     'step_size': 5,   # Pequeño step\n",
    "    #     'gamma': 0.95,    # Decay suave (simula cosine)\n",
    "    #     'patience': 50,\n",
    "    #     'hsv_h': 0.015, 'hsv_s': 0.08, 'hsv_v': 0.08,\n",
    "    #     'degrees': 4.0, 'translate': 0.04, 'scale': 0.08,\n",
    "    #     'horizontal_flip': 0.5, 'vertical_flip': 0.0,\n",
    "    #     'blur': False, 'brightness_contrast': True,\n",
    "    #     # ARCHITECTURE:\n",
    "    #     'box_score_thresh': 0.10,\n",
    "    #     'box_positive_fraction': 0.30\n",
    "    # },\n",
    "]\n",
    "\n",
    "\n",
    "# Run experiments\n",
    "for exp_config in experiments_config:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"  STARTING EXPERIMENT: {exp_config['name']}\")\n",
    "    print(f\"  {exp_config['description']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = FasterRCNNTrainer(\n",
    "        experiment_name=exp_config['name'],\n",
    "        model_family_dir='02_faster_rcnn'\n",
    "    )\n",
    "\n",
    "    # Create transforms with augmentation\n",
    "    train_transforms = get_train_transforms(exp_config)\n",
    "    val_transforms = get_val_transforms()\n",
    "\n",
    "    print(f\"\\n[INFO] Data augmentation settings:\")\n",
    "    print(f\"  HSV: h={exp_config.get('hsv_h', 0)}, s={exp_config.get('hsv_s', 0)}, v={exp_config.get('hsv_v', 0)}\")\n",
    "    print(f\"  Geometric: degrees={exp_config.get('degrees', 0)}, translate={exp_config.get('translate', 0)}, scale={exp_config.get('scale', 0)}\")\n",
    "    print(f\"  Flip: horizontal={exp_config.get('horizontal_flip', 0)}, vertical={exp_config.get('vertical_flip', 0)}\")\n",
    "    print(f\"  Other: blur={exp_config.get('blur', False)}, brightness_contrast={exp_config.get('brightness_contrast', False)}\")\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = COCODataset(\n",
    "        root_dir=train_images_dir,\n",
    "        annotation_file=train_ann_file,\n",
    "        transforms=train_transforms\n",
    "    )\n",
    "\n",
    "    val_dataset = COCODataset(\n",
    "        root_dir=val_images_dir,\n",
    "        annotation_file=val_ann_file,\n",
    "        transforms=val_transforms\n",
    "    )\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=exp_config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        collate_fn=lambda x: tuple(zip(*x))\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=exp_config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        collate_fn=lambda x: tuple(zip(*x))\n",
    "    )\n",
    "\n",
    "    # Create model (num_classes = 1 (palm) + 1 (background) = 2)\n",
    "    model = get_model(\n",
    "        num_classes=2,\n",
    "        backbone=exp_config['backbone'],\n",
    "        pretrained=exp_config['pretrained'],\n",
    "        # Configurable architecture parameters (Opción A)\n",
    "        box_score_thresh=exp_config.get('box_score_thresh'),\n",
    "        box_nms_thresh=exp_config.get('box_nms_thresh'),\n",
    "        box_detections_per_img=exp_config.get('box_detections_per_img'),\n",
    "        rpn_fg_iou_thresh=exp_config.get('rpn_fg_iou_thresh'),\n",
    "        rpn_bg_iou_thresh=exp_config.get('rpn_bg_iou_thresh'),\n",
    "        box_positive_fraction=exp_config.get('box_positive_fraction')\n",
    "    )\n",
    "\n",
    "    # Create optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(\n",
    "        params,\n",
    "        lr=exp_config['learning_rate'],\n",
    "        momentum=exp_config['momentum'],\n",
    "        weight_decay=exp_config['weight_decay']\n",
    "    )\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=exp_config['step_size'],\n",
    "        gamma=exp_config['gamma']\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    history, best_val_loss, best_epoch = trainer.train(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        num_epochs=exp_config['num_epochs'],\n",
    "        device=device,\n",
    "        config=exp_config\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[OK] Training completed for {exp_config['name']}!\")\n",
    "    print(f\"  Results saved to: {trainer.experiment_dir}\")\n",
    "\n",
    "    # Automatic evaluation and CSV logging (same as YOLOv8)\n",
    "    print(f\"\\n[INFO] Evaluating model and saving metrics...\")\n",
    "\n",
    "    # Load best model for evaluation (must match training config)\n",
    "    model_eval = get_model(\n",
    "        num_classes=2,\n",
    "        backbone=exp_config['backbone'],\n",
    "        pretrained=False,\n",
    "        # Must use same architecture parameters as training\n",
    "        box_score_thresh=exp_config.get('box_score_thresh'),\n",
    "        box_nms_thresh=exp_config.get('box_nms_thresh'),\n",
    "        box_detections_per_img=exp_config.get('box_detections_per_img'),\n",
    "        rpn_fg_iou_thresh=exp_config.get('rpn_fg_iou_thresh'),\n",
    "        rpn_bg_iou_thresh=exp_config.get('rpn_bg_iou_thresh'),\n",
    "        box_positive_fraction=exp_config.get('box_positive_fraction')\n",
    "    )\n",
    "    model_eval.load_state_dict(torch.load(trainer.weights_dir / 'best.pt'))\n",
    "    model_eval.to(device)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    metrics = evaluate_model_coco(model_eval, val_loader, device, val_ann_file)\n",
    "\n",
    "    # Get dataset info\n",
    "    with open(train_ann_file, 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    with open(val_ann_file, 'r') as f:\n",
    "        val_data = json.load(f)\n",
    "\n",
    "    dataset_info = {\n",
    "        'num_train_images': len(train_data['images']),\n",
    "        'num_val_images': len(val_data['images']),\n",
    "        'num_train_boxes': len(train_data['annotations']),\n",
    "        'num_val_boxes': len(val_data['annotations'])\n",
    "    }\n",
    "\n",
    "    # Save metrics to CSV (master + family)\n",
    "    training_time_seconds = trainer.training_time\n",
    "    save_metrics_to_csv(\n",
    "        experiment_dir=trainer.experiment_dir,\n",
    "        experiment_id=trainer.experiment_id,\n",
    "        experiment_name=exp_config['name'],\n",
    "        config=exp_config,\n",
    "        metrics=metrics,\n",
    "        dataset_info=dataset_info,\n",
    "        training_time=training_time_seconds,\n",
    "        best_epoch=best_epoch\n",
    "    )\n",
    "\n",
    "    # Update best model tracker (overall + family)\n",
    "    update_best_model_tracker(\n",
    "        experiment_id=trainer.experiment_id,\n",
    "        experiment_name=exp_config['name'],\n",
    "        metrics=metrics,\n",
    "        config=exp_config\n",
    "    )\n",
    "\n",
    "    # Create comprehensive plots\n",
    "    history_plots = {\n",
    "        'train_loss': history['train_loss'],\n",
    "        'val_loss': history['val_loss'],\n",
    "        'learning_rate': history['learning_rate']\n",
    "    }\n",
    "    create_comprehensive_plots(\n",
    "        experiment_dir=trainer.experiment_dir,\n",
    "        history=history_plots,\n",
    "        metrics=metrics,\n",
    "        best_epoch=best_epoch,\n",
    "        experiment_id=trainer.experiment_id\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[OK] Metrics saved to CSVs and best model tracker updated!\")\n",
    "    print(f\"  mAP@0.5:      {metrics['mAP_50']:.4f}\")\n",
    "    print(f\"  mAP@0.5:0.95: {metrics['mAP_50_95']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 20 16:14:01 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:84:00.0 Off |                  N/A |\n",
      "| 43%   59C    P8             37W /  250W |   10764MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:85:00.0 Off |                  N/A |\n",
      "| 52%   83C    P2            209W /  250W |    2482MiB /  11264MiB |     78%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:88:00.0 Off |                  N/A |\n",
      "| 52%   85C    P2            194W /  250W |    7178MiB /  11264MiB |     94%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:89:00.0 Off |                  N/A |\n",
      "| 22%   32C    P8              5W /  250W |       4MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   2708195      C   ....conda/envs/env-ait-dlcv/bin/python        948MiB |\n",
      "|    0   N/A  N/A   2731093      C   /opt/tljh/user/bin/python                    9810MiB |\n",
      "|    1   N/A  N/A   2785953      C   ....conda/envs/env-ait-dlcv/bin/python       2478MiB |\n",
      "|    2   N/A  N/A   2995962      C   /opt/tljh/user/bin/python                    7174MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "kCSrFovUHD0I",
    "outputId": "dd2a6201-ff20-4797-bfeb-16b62f084f42",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] SECTION 7 loaded (OPTIONAL)\n",
      "Use: evaluate_experiment('exp_001_baseline_resnet50') to re-evaluate a trained model\n",
      "\n",
      "================================================================================\n",
      "  Oil Palm Detection - Faster R-CNN Training System\n",
      "  All sections loaded successfully!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 7: Re-evaluate Trained Models (OPTIONAL)\n",
    "# ==============================================================================\n",
    "# NOTE: Evaluation is now done automatically after training in SECTION 6.\n",
    "# This section is OPTIONAL and only needed if you want to re-evaluate\n",
    "# an already trained model (e.g., after changing evaluation parameters).\n",
    "\n",
    "def evaluate_experiment(experiment_id, backbone='resnet50'):\n",
    "    \"\"\"\n",
    "    Evaluate a trained Faster R-CNN experiment and save metrics to CSV.\n",
    "\n",
    "    Args:\n",
    "        experiment_id: Experiment ID (e.g., 'exp_001_baseline_resnet50')\n",
    "        backbone: Model backbone used ('resnet50' or 'resnet101')\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "\n",
    "    Note: Architecture parameters are loaded from experiment_log.json config\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  EVALUATING: {experiment_id}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    experiment_dir = Path(EXPERIMENTS_PATH) / '02_faster_rcnn' / experiment_id\n",
    "\n",
    "    # Check if experiment exists\n",
    "    if not experiment_dir.exists():\n",
    "        print(f\"[ERROR] Experiment not found: {experiment_dir}\")\n",
    "        return None\n",
    "\n",
    "    # Load experiment config first to get architecture parameters\n",
    "    print(\"[INFO] Loading experiment config...\")\n",
    "    with open(experiment_dir / 'experiment_log.json', 'r') as f:\n",
    "        exp_log = json.load(f)\n",
    "\n",
    "    exp_config = exp_log.get('config', {})\n",
    "\n",
    "    # Load best model with same architecture parameters as training\n",
    "    print(\"[INFO] Loading best model...\")\n",
    "    model = get_model(\n",
    "        num_classes=2,\n",
    "        backbone=backbone,\n",
    "        pretrained=False,\n",
    "        # Use same architecture parameters as training\n",
    "        box_score_thresh=exp_config.get('box_score_thresh'),\n",
    "        box_nms_thresh=exp_config.get('box_nms_thresh'),\n",
    "        box_detections_per_img=exp_config.get('box_detections_per_img'),\n",
    "        rpn_fg_iou_thresh=exp_config.get('rpn_fg_iou_thresh'),\n",
    "        rpn_bg_iou_thresh=exp_config.get('rpn_bg_iou_thresh'),\n",
    "        box_positive_fraction=exp_config.get('box_positive_fraction')\n",
    "    )\n",
    "    model.load_state_dict(torch.load(experiment_dir / 'weights' / 'best.pt'))\n",
    "    model.to(device)\n",
    "\n",
    "    # Create validation loader\n",
    "    print(\"[INFO] Loading validation dataset...\")\n",
    "    val_dataset = COCODataset(val_images_dir, val_ann_file, get_val_transforms())\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False,\n",
    "                            num_workers=0, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    metrics = evaluate_model_coco(model, val_loader, device, val_ann_file)\n",
    "\n",
    "    # Get dataset info from annotation files\n",
    "    with open(train_ann_file, 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    with open(val_ann_file, 'r') as f:\n",
    "        val_data = json.load(f)\n",
    "\n",
    "    dataset_info = {\n",
    "        'num_train_images': len(train_data['images']),\n",
    "        'num_val_images': len(val_data['images']),\n",
    "        'num_train_boxes': len(train_data['annotations']),\n",
    "        'num_val_boxes': len(val_data['annotations'])\n",
    "    }\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    print(\"\\n[INFO] Saving metrics to CSV...\")\n",
    "    # training_time_minutes from exp_log is already in minutes, multiply by 60 to get seconds\n",
    "    training_time_seconds = exp_log.get('training_time_minutes', 0) * 60\n",
    "    save_metrics_to_csv(\n",
    "        experiment_dir=experiment_dir,\n",
    "        experiment_id=experiment_id,\n",
    "        experiment_name=exp_log['config'].get('name', experiment_id),\n",
    "        config=exp_log['config'],\n",
    "        metrics=metrics,\n",
    "        dataset_info=dataset_info,\n",
    "        training_time=training_time_seconds,  # Now in seconds, will be converted to hours in CSV\n",
    "        best_epoch=exp_log['best_epoch']\n",
    "    )\n",
    "\n",
    "    # Update best model tracker\n",
    "    update_best_model_tracker(\n",
    "        experiment_id=experiment_id,\n",
    "        experiment_name=exp_log['config'].get('name', experiment_id),\n",
    "        metrics=metrics,\n",
    "        config=exp_log['config']\n",
    "    )\n",
    "\n",
    "    # Create comprehensive plots (6 subplots like YOLOv8)\n",
    "    print(\"\\n[INFO] Creating comprehensive plots...\")\n",
    "    history = {\n",
    "        'train_loss': exp_log.get('train_loss', []),\n",
    "        'val_loss': exp_log.get('val_loss', []),\n",
    "        'learning_rate': exp_log.get('learning_rate', [])\n",
    "    }\n",
    "    create_comprehensive_plots(\n",
    "        experiment_dir=experiment_dir,\n",
    "        history=history,\n",
    "        metrics=metrics,\n",
    "        best_epoch=exp_log['best_epoch'],\n",
    "        experiment_id=experiment_id\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  EVALUATION SUMMARY - {experiment_id}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  mAP@0.5:      {metrics['mAP_50']:.4f}\")\n",
    "    print(f\"  mAP@0.5:0.95: {metrics['mAP_50_95']:.4f}\")\n",
    "    print(f\"  mAP@0.75:     {metrics['mAP_75']:.4f}\")\n",
    "    print(f\"  Precision:    {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall:       {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1-Score:     {metrics['f1_score']:.4f}\")\n",
    "    print(f\"  Inference:    {metrics['inference_time_ms']:.2f} ms/image\")\n",
    "    print(f\"  Parameters:   {metrics['total_params_M']:.2f}M\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Example usage (uncomment to evaluate):\n",
    "\"\"\"\n",
    "# Evaluate all completed experiments\n",
    "experiment_ids = [\n",
    "    'exp_001_baseline_resnet50',\n",
    "    'exp_002_augmented_resnet50',\n",
    "    'exp_003_heavy_aug_resnet50'\n",
    "]\n",
    "\n",
    "for exp_id in experiment_ids:\n",
    "    evaluate_experiment(exp_id, backbone='resnet50')\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n[INFO] SECTION 7 loaded (OPTIONAL)\")\n",
    "print(\"Use: evaluate_experiment('exp_001_baseline_resnet50') to re-evaluate a trained model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjt5TZAMFq1I",
    "outputId": "8affba77-86f2-4cad-93a4-2d7a4eb029f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  EVALUATING: exp_001_baseline_resnet50\n",
      "======================================================================\n",
      "\n",
      "[INFO] Loading best model...\n",
      "[INFO] Loading validation dataset...\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n",
      "[INFO] Running inference for COCO evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Generated 1098 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.783\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.686\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.723\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.725\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 99.01 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "\n",
      "[INFO] Saving metrics to CSV...\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/all_experiments_log.csv\n",
      "\n",
      "[INFO] Creating comprehensive plots...\n",
      "[OK] Comprehensive plots saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/exp_001_baseline_resnet50/plots/comprehensive_results.png\n",
      "\n",
      "======================================================================\n",
      "  EVALUATION SUMMARY - exp_001_baseline_resnet50\n",
      "======================================================================\n",
      "  mAP@0.5:      0.7829\n",
      "  mAP@0.5:0.95: 0.5249\n",
      "  mAP@0.75:     0.6864\n",
      "  Precision:    0.7829\n",
      "  Recall:       0.7233\n",
      "  F1-Score:     0.7519\n",
      "  Inference:    99.01 ms/image\n",
      "  Parameters:   41.30M\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "  EVALUATING: exp_002_augmented_resnet50\n",
      "======================================================================\n",
      "\n",
      "[INFO] Loading best model...\n",
      "[INFO] Loading validation dataset...\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n",
      "[INFO] Running inference for COCO evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Generated 1190 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.786\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.653\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.720\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.721\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 98.92 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "\n",
      "[INFO] Saving metrics to CSV...\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/all_experiments_log.csv\n",
      "\n",
      "[INFO] Creating comprehensive plots...\n",
      "[OK] Comprehensive plots saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/exp_002_augmented_resnet50/plots/comprehensive_results.png\n",
      "\n",
      "======================================================================\n",
      "  EVALUATION SUMMARY - exp_002_augmented_resnet50\n",
      "======================================================================\n",
      "  mAP@0.5:      0.7861\n",
      "  mAP@0.5:0.95: 0.5212\n",
      "  mAP@0.75:     0.6535\n",
      "  Precision:    0.7861\n",
      "  Recall:       0.7200\n",
      "  F1-Score:     0.7516\n",
      "  Inference:    98.92 ms/image\n",
      "  Parameters:   41.30M\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "  EVALUATING: exp_003_heavy_aug_resnet50\n",
      "======================================================================\n",
      "\n",
      "[INFO] Loading best model...\n",
      "[INFO] Loading validation dataset...\n",
      "[OK] Loaded 13 images\n",
      "[OK] Loaded 546 annotations\n",
      "[INFO] Running inference for COCO evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Generated 1216 predictions\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "[INFO] Running COCO evaluation...\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.778\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.695\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.731\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "[INFO] Measuring inference time...\n",
      "[OK] Inference time: 100.10 ms/image\n",
      "[OK] Total parameters: 41.30M\n",
      "\n",
      "[INFO] Saving metrics to CSV...\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/02_faster_rcnn_experiments.csv\n",
      "[OK] Metrics saved to: /content/drive/MyDrive/cv_project/04_experiments/all_experiments_log.csv\n",
      "\n",
      "[INFO] Creating comprehensive plots...\n",
      "[OK] Comprehensive plots saved to: /content/drive/MyDrive/cv_project/04_experiments/02_faster_rcnn/exp_003_heavy_aug_resnet50/plots/comprehensive_results.png\n",
      "\n",
      "======================================================================\n",
      "  EVALUATION SUMMARY - exp_003_heavy_aug_resnet50\n",
      "======================================================================\n",
      "  mAP@0.5:      0.7781\n",
      "  mAP@0.5:0.95: 0.5277\n",
      "  mAP@0.75:     0.6953\n",
      "  Precision:    0.7781\n",
      "  Recall:       0.7299\n",
      "  F1-Score:     0.7532\n",
      "  Inference:    100.10 ms/image\n",
      "  Parameters:   41.30M\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all completed experiments\n",
    "experiment_ids = [\n",
    "    'exp_001_baseline_resnet50',\n",
    "    'exp_002_augmented_resnet50',\n",
    "    'exp_003_heavy_aug_resnet50'\n",
    "]\n",
    "\n",
    "for exp_id in experiment_ids:\n",
    "    evaluate_experiment(exp_id, backbone='resnet50')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
